% \documentclass{article}
% \documentclass[]{acmart}
\documentclass[manuscript]{acmart}
% \documentclass[manuscript,screen,review]{acmart}
% \documentclass[manuscript]
\usepackage{mathpartir}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{stmaryrd}
\usepackage{listings}
\usepackage{amsthm}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}{Corollary}[theorem]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\makeatletter % allow us to mention @-commands
\def\arcr{\@arraycr}
\makeatother

\lstset{
    identifierstyle=\color{violet},
    % textcolor=blue,
    % keywordstyle=\color{blue},
    keywordstyle=\text,
    basicstyle=\ttfamily,
    mathescape=true,
    showspaces=false,
    morekeywords={let, fix, in}
}
\usepackage[utf8]{inputenc}
% \usepackage[T1]{fontenc}


%\title{Type-Directed Synthesis for Dynamic Languages}
\title{Guiding Program Synthesis with Relational Types}
\author{Thomas Logan}
\date{October 2022}

\begin{document}

\maketitle

\section{Introduction}
% context: dynamically typed languages   
Some of Today's most popular languages such as JavaScript and Python are considered to be \textbf{dynamically typed}.
One of the hallmarks of such languages, is that they do not require specifications 
that can be verified statically. By not requiring static bounds, dynamically typed languages
enable vast combinations of terms and high reusability of code. 
Although it's not required, many programmers find that
static checks, such as \textbf{linters} and more advanced \textbf{static analysis} tools, 
enable them to find bugs, understand code, and write code more efficiently and reliably. 

In addition to writing programs, programmers can also annotate programs with specifications to
aid static verification. Writing specifications and programs can be tedious and burdensome.  
It addition to verifying correction, static tools can aid programmers by automatically synthesizes
parts of programs or specification implied by the context. Thus, the programmer can simply write
either a partial specification or partial program and allow the synthesis tool to fill in the rest.   

\begin{lstlisting}[language=Python]
def foo(x):
    if isinstance(x, int):
        return x + 1 
    elif isinstance(x, str): 
        return x + "abc"
\end{lstlisting}

% motivation: Specification 
Much of the work on synthesizing specifications from programs has been based on \textbf{ML type inference}.
In contrast to dynamically typed languages, \textbf{ML languages} require that static bounds are prescribed 
in its programs via its \textbf{datatype} mechanism. The design of ML's datatype mechanism is clever, 
such that these static bound prescriptions are only needed at the definitions of types and can be 
inferred when the data of types are used. When a piece of data is seen, an upper static bound 
may be inferred and propagated around the syntax tree to check correct composition of the program.

\begin{lstlisting}[language=ML]
datatype int_or_str = 
    Int of int | 
    Str of string

fun foo(Int x) = x + 1
  | foo(Str x) = x ^ "abc"
\end{lstlisting}

In addition, to intrinsically associating certain terms with upper bounds, many languages require
type annotations that restrict the values used in place of variables or parameters.


% motivation: subtyping 
Since dynamically typed languages do not require prescribed static bounds, 
type inference (or specification synthesis, in more general terms) must balance 
restricting the permissible combinations and reusability in programs with 
catching errors that could result in crashes at runtime.
The flexibility of combinations implies that for the same data, 
the tightest static bounds may differ depending on the context.
Thus, \textbf{subtyping} or a similarly flexible 
static notion is necessary to avoid overly restricting combinations.

% motivation: expressive types 
Mainstream type systems typically merely allow constructing simple types 
by grouping objects together based on their structures or names.
However, to have genuine confidence in the correctness of programs, specifications
need to express relations between data. There are a number of rather esoteric systems that
enable stating and proving propositions that relate objects to each other, 
including ACL2, Twelf, Coq, Lean, HOL, Isabelle, Liquid Haskell, and Synquid.  
Some of these use dependent types to encompass both simple types and propositions, 
and some rely on new syntactic categories for propositions. 

Liquid Haskell and the related Synquid both provide a way to define relations
along with subtyping, by extending ML datatypes with predicate clauses. 

\begin{lstlisting}[keywords={termination, measure, data, where}]
termination measure len :: List $\beta$ $\rightarrow$ Nat 
data List $\beta$ where
  Nil :: {v: List $\beta$ | len v = 0}
  Cons :: $\beta$ $\rightarrow$ xs: List $\beta$ $\rightarrow$ 
    {v: List $\beta$ | len v = len xs + 1}

\end{lstlisting}

However, as discussed above, the ML datatype mechanism breaks our definition of dynamically typed,
as it demands prescribing static bounds with data, so this would not work for our problem wholesale.
Other systems, like Lean or Isabelle, have similar problems with the additional issue of lacking subtyping.
Finally, all of these are rather complex, either by requiring syntactic classes of propositions predicates, 
in addition to types, or complicating the static semantics of types by allowing them 
to be dependent on programs.



% motivation: Programming 
With expressive types, using types to guide the user's programming or automatic program synthesis 
becomes a more realistic endeavor, as there may be enough information in the specification to narrow the field
and guide the generation of useful programs. Lean and Synquid\cite{} (Based on Liquid Haskell) 
are two examples of systems that decompose and propagate type specifications 
to incomplete sections or holes in programs. 
In the case of Lean, users can use this local type specification to help them construct programs and proofs,
while in Synquid this local information is leveraged to efficiently synthesize programs. 

% solution 
This paper introduces the \textbf{relational type system} to provide expressive specifications 
and synthesis capabilities for dynamically typed languages. 
The contributions of the relational type system include:
\begin{enumerate}
  \item A synthesis algorithm capable of generating local constraints for incomplete programs. 
  \item A unification algorithm capable of preserving the flexibility of dynamically typed programming. 
  \item A type level language capable of expressing subtyping of (co)inductive relations. 
\end{enumerate}

% half baked idea: by removing terms from type language,  
% terms may be enhanced with side-effects/concurrency etc,
% without complicating the type system.

% summary 

In section 2, we illustrate the problem and our solution with examples.
In section 3, we define the problem and the syntax, semantics, typing, and subtyping of our language.
In section 4, we present the synthesis and unification algorithms.
In section 5, we evaluate the problem and its solution. 
In section 6, we discuss related work of the past and possible future directions. 

\section{Overview}

This work introduces three cohesive strategies towards making
dynamically typed programs easier to write with fewer errors.  
\begin{enumerate}
  \item propagating types (downward/upward) 
  \item adjusting types (wider/narrower) 
  \item constraining types (inductive/coinductive) 
\end{enumerate}
We introduce a programming language with a specification language to indicate static bounds. 
As is common these days, the static bounds are represented in a language of types.

\subsection{Propagated types}
Writing type annotations can be burdensome, so the first step 
towards making static checks feasible is to infer types from terms.

\begin{lstlisting}
cons;(hello;(),cons;(world;(),nil;())) : 

cons*(hello*unit $\times$ 
cons*(world*unit $\times$ 
nil*unit
))
\end{lstlisting}

\noindent The example above illustrates a type inferred from a term.
The part left of the colon is the term and the part right of the colon is the type.
The unit term is represented as \lstinline{()}, and it belongs to type \lstinline{unit}. 
A tagged term is constructed from a literal sequence of characters and a term separated
by a semicolon. A tagged term is constructed from a literal sequence of characters
and a type separated by a star.
So the type of \lstinline{hello;()} is \lstinline{hello*unit}.

The reason for inferring types is the check for errors statically or 
provide hints on how to complete missing parts of a program. To this end,
types propagate back up the syntax tree and down siblings' trees in order
to facilitate type checking and type hinting.
Depending on a programming languages requirements of static specification, 
whether types are propagated up or down may vary. 
In the case dynamically typed programs, no static specification or type annotations
are required, so types are propagated in both directions for every syntax rule
of the language.


\subsection{Propagated to widen}
Since annotations are not required, it is important to propagate types up to check
that a term fits its context.
For example, a function abstraction is not required to be annotated 
with either an input type or an output type. 
\noindent By propagating up the input type we can check the composition of the application.
By propagating up the type of the body, we can check the result of the function application 
with its surrounding context. 

\begin{lstlisting}
let f = ($\lambda$ x $\Rightarrow$ 
  let g : nat -> str = $\hdots$
  hello ; (g x)
) 
let y : world * str = f 4
\end{lstlisting}

The type of \lstinline{f} is inferred to be \lstinline{nat $\rightarrow$ hello*str}, 
by propagating up the types inferred for its parameter and body.
The application is satisfactory since applied to the term \lstinline{4}, 
but it fails when checked against the function application's context,
which expects \lstinline{world*str}.
\begin{lstlisting}
hello*str $\leq$ world*str
\end{lstlisting}

\subsection{Propagated to narrow}
By propagating down and decomposing types, 
it is possible to guide the completion of programs with type hints.
To maintain the spirit of dynamic types, type annotations must remain optional.
Previous work has demonstrated the utility of downward propagating types 
in theorem proving systems, local type checking, 
and synthesis of ML-family programs.

For example, in a program that extracts 
the first element of a pair of a particular type, 
it's possible to detect an error before knowing the second element.

\begin{lstlisting}
$\lambda$ n : nat $\Rightarrow$
  let first = ($\lambda$ (x,y) : (str $\times$ str) $\Rightarrow$ x) .
  first (n, _) 
\end{lstlisting}

\noindent The  applications' argument type \lstinline{(nat $\times$ ?)} 
is propagated and decomposed such that the subtyping constraint 
\lstinline{nat $\subseteq$ str} is decided. 

\subsection{Adjustable types}

In a dynamically typed language, since types are not necessarily prescribed
for terms of particular constructions (as they are in ML datatypes), 
the optimal type for a term will depend on how terms and parameters are used in context. 
When inferring a type that may be associated with various terms throughout a program,  
The optimal type may depend on widening a type as new use cases are discovered,
or narrowing a type as new restrictions are discovered. 

\subsection{Adjustable with widening}

In parametric types where a generic input type must be the same as a generic output type,
The dynamic nature of terms is seemingly at odds with inferring types.

In the case of a function with generic types, 
the types can be specialized based on the terms that are witnessed as inputs. 

Since there's no particular upper bound type associated with 
a term other than top ($\top$), 
The parameter type must accommodate types of unforeseen arguments, 
while the return type should be widened with each successive
argument's type.
widening is achieved with the introduction of the union type operator ($\vee$).

\begin{lstlisting}
($\lambda$ pair : $\forall$ $\alpha$ . $\alpha$ $\rightarrow$ $\alpha$ $\rightarrow$ ($\alpha$ $\times$ $\alpha$) $\Rightarrow$ 
($\lambda$ n : int $\Rightarrow$ ($\lambda$ s : str $\Rightarrow$ 
  pair n s
)))
\end{lstlisting}

Let \lstinline{?} stand for a fresh type variable.
Once \lstinline{pair} is applied to an integer its generic type is specialized to 
\lstinline{(int $\vee$ ?)}, 
in which union with the dynamic type behaves like the top type $\top$, 
accommodating receiving a string as a the subsequent input.
Thus, the generic type is specialized to 
\newline
\lstinline{(int $\vee$ str $\vee$ ?)}.
The type variable always passes type checking, 
thus behaving like bottom for term types
and behaving like top for parameter types.
As such, the parameters' union types behave like top,
and the type variable simply falls away in the union of the result type. 
The result type for \lstinline{(pair n s)} ends up as 
\newline
\lstinline{(int $\vee$ string) $\times$ (int $\vee$ string)}. 

\subsection{Adjustable with narrowing}

In functions where a parameter has an unknown type and that parameter is 
internally used as an argument to an application, the dynamically typed 
nature of terms adds some complications to type inference.

The argument type must be amenable to parameter types 
of unforeseen compositions,
while the external parameter type should be narrowed 
to the smallest type necessary for internal compositions to
succeed.

\begin{lstlisting}
($\lambda$ i2n : int $\rightarrow$ nat $\Rightarrow$ 
($\lambda$ s2n : str $\rightarrow$ nat $\Rightarrow$ 
  $\lambda$ x $\Rightarrow$ (i2n x, s2n x)
))

\end{lstlisting}

Once \lstinline{i2n} is applied to \lstinline{x}, 
the type for \lstinline{x} is specialized to \lstinline{(int $\wedge$ ?)}, 
in which intersection with the dynamic type behaves like the bottom type $\bot$,
availing itself to be used in subsequent applications. 
Thus, the dynamic type is inferred to be \lstinline{(int $\wedge$ str $\wedge$ ?)}.

The type variable always passes type checking, 
thus behaving like bottom for term types
and behaving like top for parameter types.
As such, the intersections of argument types behave like bottom,
and the type variable simply falls away in the intersection type of a parameter.
The external parameter type for ends up as \lstinline{(int $\wedge$ str)}. 


\subsection{Constrained types}
In order to thoroughly catch errors and guide programming, 
the specification language must be able to describe the semantic relation
between structures. Rather than adding a second syntactic layer 
of predicates and propositions to our specification language,
we build on the notions of type abstraction -  
union/intersection types, second order quantified types, and (co)inductive types 
- already prevalent in type systems, yielding a novel system of relational types.

\hfill \\
Consider the type for a list.

% \begin{lstlisting}[]
% $\mu$ list .
%   nil*unit $\vee$
%   $\exists$ $\alpha$ . cons*($\alpha$ $\times$ list)
% \end{lstlisting} 

\[
\begin{array}[t]{@{} l}
  \exists\ \text{X}\ .\ \mu\ \text{XS}\ .\ 
  \arcr
  \hspace{4mm}\text{nil}*\text{unit}\ \vee
  \arcr
  \hspace{4mm}\text{cons}*(\text{X} \times \text{XS})
\end{array}
\]

\hfill \\
This list type contains three kinds of type abstraction: 
union, existential quantification, and induction.
Using these three forms of type abstraction, we are able to define 
a set of lists of arbitrary length with arbitrary items. 

We abbreviate the inductive part of the list type.
\[
list(\alpha) = 
\begin{array}[t]{@{} l}
  \mu\ \text{XS}\ .\ 
  \arcr
  \hspace{4mm}\text{nil}*\text{unit}\ \vee
  \arcr
  \hspace{4mm}\text{cons}*(\alpha \times \text{XS})
\end{array}
\]

Now suppose we wish to validate a function that expects $list$ to an argument. 
\[
  \begin{array}[]{@{} l}
  \text{let}\ \text{foo} : (\exists\ \text{X}\ .\ list(\text{X})) \rightarrow \text{unit} = \_\ \text{in}
  \arcr
  (\text{foo}\ (\text{cons};((),\text{nil};())))
  \end{array}
\]

This function application generates a subtyping constraint which we decide by unrolling
the the inductive types. The successful trace of the decision algorithm corresponds To
the following derivation. 

\[
  \Delta_l = \bullet, \text{X} \mapsto \text{unit}
\]

\begin{mathpar}
\inferrule* {
  \inferrule* {
    \inferrule* {
      \inferrule* {
        \inferrule* {
          \Delta_l(\text{X}) = \text{unit}
        } { 
          \Delta_l \vdash
          \text{unit}
          \leq
          \text{X}
        }
        \\
        \inferrule* {
          \inferrule* {
            \inferrule* {
              \vdots
            } { 
              \Delta_l \vdash
              \text{nil}*\text{unit}
              \leq
              \text{nil}*\text{unit}
            }
          } { 
            \Delta_l \vdash
            \text{nil}*\text{unit}
            \leq
            \begin{array}[]{@{} l}
              \text{nil}*\text{unit}\ \vee
              \arcr
              \text{cons}*(\text{X} \times list(\text{X}))
            \end{array}
          }
        } { 
          \Delta_l \vdash
          (\text{nil}*\text{unit})
          \leq
          list
        }
      } { 
        \Delta_l \vdash
        (\text{unit} \times \text{nil}*\text{unit})
        \leq
        (\text{X} \times list(\text{X}))
      }
    } { 
      \Delta_l \vdash
      (\text{cons}*(\text{unit} \times \text{nil}*\text{unit}))
      \leq
      \text{cons}*(\text{X} \times list(\text{X}))
    }
  } { 
    \Delta_l \vdash
    (\text{cons}*(\text{unit} \times \text{nil}*\text{unit}))
    \leq
    \begin{array}[]{@{} l}
      \text{nil}*\text{unit}\ \vee
      \arcr
      \text{cons}*(\text{X} \times list(\text{X}))
    \end{array}
  }
} { 
  \bullet \vdash
  (\text{cons}*(\text{unit} \times \text{nil}*\text{unit}))
  \leq
  \exists\ \text{X}\ .\ list(\text{X})
}
\end{mathpar}

In addition to deciding if a \emph{singleton type}, a type containing exactly one element, 
we can, we can also compare two inductive types. 
Consider the natural numbers and even numbers.
\[
nat = 
\begin{array}[t]{@{} l}
  \mu\ \text{N}\ .\ 
  \text{zero}*\text{unit}\ \vee
  \text{succ}*\text{N}
\end{array}
\]
\[
even = 
\begin{array}[t]{@{} l}
  \mu\ \text{N}\ .\ 
  \text{zero}*\text{unit}\ \vee
  \text{succ}*\text{succ}*\text{N}
\end{array}
\]

We can decide that even numbers are included in the natural numbers, 
by unrolling with the induction hypothesis. 
The successful trace of the decision algorithm corresponds to a subtyping derivation.   

\begin{mathpar}
\inferrule* {
  \inferrule* {
    \inferrule* {
      \inferrule* {
        \vdots
      } { 
        \bullet \vdash
        \text{zero}*\text{unit}
        \leq
        \text{zero}*\text{unit}
      }
    } { 
      \bullet \vdash
      \text{zero}*\text{unit}
      \leq
      \begin{array}[]{@{} l}
        \text{zero}*\text{unit}\ \vee
        \arcr
        \text{succ}*nat
      \end{array}
    }
    \\
    \inferrule* {
      \inferrule* {
        \inferrule* {
          \inferrule* {
            \inferrule* {
              \vdots
            } { 
              \bullet \vdash
              \text{succ}*nat 
              \leq
              \text{succ}*nat 
            }
          } { 
            \bullet \vdash
            \text{succ}*nat 
            \leq
            \begin{array}[]{@{} l}
              \text{zero}*\text{unit}\ \vee
              \arcr
              \text{succ}*nat
            \end{array}
          }
        } { 
          \bullet \vdash
          \text{succ}*nat
          \leq
          nat
        }
      } { 
        \bullet \vdash
        \text{succ}*\text{succ}*nat
        \leq
        \text{succ}*nat
      }
    } { 
      \bullet \vdash
      \text{succ}*\text{succ}*nat
      \leq
      \begin{array}[]{@{} l}
        \text{zero}*\text{unit}\ \vee
        \arcr
        \text{succ}*nat
      \end{array}
    }
  } { 
    \bullet \vdash
    \begin{array}[]{@{} l @{}}
      \text{zero}*\text{unit}\ \vee
      \arcr
      \text{succ}*\text{succ}*nat
    \end{array}
    \leq
    \begin{array}[]{@{} l}
      \text{zero}*\text{unit}\ \vee
      \arcr
      \text{succ}*nat
    \end{array}
  }
} { 
  \bullet \vdash
  even \leq nat
}
\end{mathpar}

Notice that the natural numbers are substituted in for the inductively bound variable  
for both the even number type and the natural number type.
We justify this manipulation by the induction hypothesis $even \leq nat$. 


By augmenting quantified types with fairly general constraints, 
we will be able to express relational types, using the same three forms
of type abstraction.  

\hfill

\subsection{Constrained by widening}

The key insight that enables relations to be defined with existing type constructs,
is to constrain bound variables of quantified types using subtyping constraints,
such that those subtyping constraints may refer to (co)inductive variables.
For example, consider the specification of pairs of a list and a number, such that
the number equals the length of its corresponding list.

\[
nat\_and\_list(\alpha) =  
\begin{array}[t]{@{} l}
\mu\ \text{P}\ . 
\\
\hspace{4mm}\text{zero}*\text{unit} \times \text{nil}*\text{unit}\ \vee\ 
\\
\hspace{4mm}\exists\ \text{N}\ \text{XS} :: \text{N} \times \text{XS} \leq \text{P}\ .\ 
\\
\hspace{8mm}\text{succ}*\text{N} \times \text{cons}*(\alpha \times \text{XS})
\end{array}
\]

Now suppose we have a function that expects a list and number satisfying a list-number relation.
\[
  \begin{array}[]{@{} l}
  \text{let}\ \text{foo} : (\exists\ \text{X}\ .\ nat\_and\_list(\text{X})) \rightarrow \text{unit} = \lambda\ (\text{n}, \text{l})\ .\ \_\ \text{in}
  \arcr
  (\text{foo}\ (\text{succ};\text{zero};(), \text{cons};((),\text{nil};())))
  \end{array}
\]

\noindent
Applying the function that expects the relation between lists and numbers 
to the argument generates a corresponding subtyping constraint, 
which the system attempts to solve. We define the type environment a type environment abbreviation.
\[
\Delta_{nl} = \bullet, 
  \text{X} \mapsto \text{unit},
  \text{N} \mapsto \text{zero}*\text{unit}, 
  \text{XS} \mapsto \text{nil}*\text{unit}
\]
\noindent
A successful trace of the decision algorithm corresponds to the following subtyping derivation.  

\noindent
\begin{mathpar}
\inferrule* {
  \inferrule* { 
    \inferrule* { 
      \inferrule* { 
        \vdots
      } {
        \Delta_{nl} \vdash
        \begin{array}[]{@{} l @{}}
        (\text{succ}*\text{zero}*\text{unit})\ \times 
        \arcr
        (\text{cons}*(\text{unit} \times \text{nil}*\text{unit}))
        \end{array}
        \leq
        \begin{array}[]{@{} l @{}}
        \text{succ}*\text{N}\ \times 
        \arcr
        \text{cons}*(\text{X} \times \text{XS})
        \end{array}
      }
      \\
      \inferrule* { 
        \inferrule* { 
          \vdots
        } {
          \Delta_{nl} \vdash
          \text{N} \times \text{XS} \leq 
          \text{zero}*\text{unit} \times \text{nil}*\text{unit}
        }
      } {
        \Delta_{nl} \vdash
        \text{N} \times \text{XS} \leq nat\_and\_list(\text{X})
      }
    } {
      \bullet, \text{X} \mapsto \text{unit} \vdash
      \begin{array}[]{@{} l @{}}
        (\text{succ}*\text{zero}*\text{unit})\ \times 
        \arcr
        (\text{cons}*(\text{unit} \times \text{nil}*\text{unit}))
      \end{array}
      \leq
      \begin{array}[]{@{} l}
        \exists\ \text{N}\ \text{XS} :: (\text{N} \times \text{XS}) \leq nat\_and\_list(\text{X}) 
        \arcr
        \hspace{4mm}\text{succ}*\text{N} \times \text{cons}*(\text{X} \times \text{XS})
      \end{array}
      }
  } { 
    \bullet, \text{X} \mapsto \text{unit} \vdash
    \begin{array}[]{@{} l @{}}
      (\text{succ}*\text{zero}*\text{unit})\ \times 
      \arcr
      (\text{cons}*(\text{unit} \times \text{nil}*\text{unit}))
    \end{array}
    \leq
    \begin{array}[]{@{} l}
      \text{zero}*\text{unit} \times \text{nil}*\text{unit}\ \vee\ 
      \arcr
      \exists\ \text{N}\ \text{XS} :: (\text{N} \times \text{XS}) \leq nat\_and\_list(\text{X})
      \arcr
      \hspace{4mm}\text{succ}*\text{N} \times \text{cons}*(\text{X} \times \text{XS})
    \end{array}
  }
} { 
  \bullet \vdash
  (\text{succ}*\text{zero}*\text{unit}) \times (\text{cons}*(\text{unit} \times \text{nil}*\text{unit}))
  \leq
  \exists\ \text{X}\ .\ nat\_and\_list(\text{X})
}
\end{mathpar}

We can also specify a relation between even numbers and lists.  

\[
even\_and\_list(\alpha) =  
\begin{array}[t]{@{} l}
  \mu\ \text{P}\ .\ 
  \\
  \hspace{4mm}\text{zero}*\text{unit} \times \text{nil}*\text{unit}\ \vee\ 
  \\
  \hspace{4mm}\exists\ \text{N}\ \text{XS} :: \text{N} \times \text{XS} \leq \text{P}\ .\ 
  \\
  \hspace{8mm}\text{succ}*\text{succ}*\text{N} \times \text{cons}*(\alpha \times \text{cons}*(\alpha \times \text{XS}))
\end{array}
\]

We verify that the even relation is included in the natural number relation to lists.  

\[
\Delta_{enl} = \bullet,\ 
  \text{N} \times \text{XS} \mapsto nat\_and\_list(\text{X}),\ 
  \text{XS'} \mapsto \text{cons}*(\text{X} \times \text{XS}),\ 
  \text{N'} \mapsto \text{succ}*\text{N}
\]

\begin{mathpar}
\inferrule* {
  \inferrule* {
    \vdots
    \\
    \inferrule* {
      \inferrule* {
        \inferrule* {
          \inferrule* {
            \Delta_{enl}(\text{N} \times \text{XS}) = nat\_and\_list(\text{X})
          } {
            \Delta_{enl} \vdash
            \text{N} \times \text{XS} \leq nat\_and\_list(\text{X})
          }
        } {
          \vdots
        }
      } {
        \Delta_{enl} \vdash
        \text{succ}*\text{N} \times \text{cons}*\text{XS} \leq nat\_and\_list(\text{X})
      }
      \\
      \Delta_{enl}(\text{N'}) = \text{succ}*\text{N}
      \\
      \Delta_{enl}(\text{XS'}) = \text{cons}*(\text{X} \times \text{XS})
    } {
      \Delta_{enl} \vdash
      \text{N'} \times \text{XS'} \leq nat\_and\_list(\text{X})
    }
  } {
    \bullet \vdash
    \begin{array}[]{@{} l @{}}
      \text{zero}*\text{unit} \times \text{nil}*\text{unit}\ \vee\ 
      \arcr
      \exists\ \text{N}\ \text{XS} :: \text{N} \times \text{XS} \leq nat\_and\_list(\text{X})\ .\ 
      \arcr
      \hspace{4mm}\text{succ}*\text{succ}*\text{N} \times \text{cons}*(\text{X} \times \text{cons}*(\text{X} \times \text{XS}))
    \end{array}
    \leq
    \begin{array}[]{@{} l @{} }
      \text{zero}*\text{unit} \times \text{nil}*\text{unit}\ \vee\ 
      \arcr
      \exists\ \text{N}\ \text{XS} :: \text{N} \times \text{XS} \leq nat\_and\_list(\text{X})\ .\ 
      \arcr
      \hspace{4mm}\text{succ}*\text{N} \times \text{cons}*(\text{X} \times \text{XS})
    \end{array}
  }
} { 
  \bullet \vdash
  even\_and\_list(\text{X})
  \leq
  nat\_and\_list(\text{X})
}
\end{mathpar}





\subsection{Constrained by narrowing}
The system of type is also expressive enough to precisely specify
sets of functions, where each function's output depends on its input.

Consider the set of functions, where each function takes as input a natural number $n$
and an element, and returns a list of $n$ elements.

\[
  nat\_to\_list = 
  \begin{array}[t]{@{} l}
    \forall\ \text{X}\ .\ \text{X} \rightarrow \nu\ \text{I}\ .\ 
    \arcr
    \hspace*{4mm}\text{zero}*\text{unit} \rightarrow \text{nil}*\text{unit}\ \wedge
    \arcr
    \hspace*{4mm}\forall\ \text{N}\ \text{XS} :: \text{I} \leq \text{N} \rightarrow \text{XS}\ .\ 
    \arcr
    \hspace*{8mm}\text{succ}*\text{N} \rightarrow \text{cons}*(\text{X} \times \text{XS})
  \end{array}
\]


\noindent The type $nat\_to\_list$ uses three forms of type abstraction: 
universal types, intersection types, and co-inductive types. 
These three forms of type abstraction
are respectively the duals of existential types, union types, and inductive types. 

Universal and co-inductive types are ways to specify the infinite intersection
of types indexed by some variable. Although, it is technically possible to specify
the infinite intersection of arbitrary types, it is only the function types
that can represent meaningful non-empty sets of values across infinite intersections.
Thus, in practice, we are only considered with universal and co-inductive types, when
they compose implication types.
In order to propagate types top-down and also reuse mechanisms for the dual concepts of type abstraction,
the decision algorithm rewrites inductive types into \emph{implication-normal-form}.
We define an abbreviation for the natural numbers.
\[
nat = 
\begin{array}[t]{@{} l}
  \mu\ \text{N}\ .\ 
  \arcr
  \hspace{4mm}\text{zero}*\text{unit}\ \vee
  \arcr
  \hspace{4mm}\exists\ \text{X}\ .\ \text{succ}*\text{N}
\end{array}
\]
Using natural numbers and the relation between numbers and lists,
we redefine set of functions from numbers to lists.
\[
  nat\_to\_list' = 
  \begin{array}[t]{@{} l}
    \forall\ \text{X}\ .\ \text{X} \rightarrow \forall\ \text{N}\ :: \text{N} \leq nat\ .\ 
    \arcr
    \hspace*{4mm}\text{N} \rightarrow 
    (\exists\ \text{XS} :: \text{N} \times \text{XS} \leq nat\_and\_list\ .\ \text{XS})
  \end{array}
\]


\noindent The term for \lstinline{replicate} could be represented by a recursive function built using \lstinline{fix} 

\begin{lstlisting}[]
let replicate = 
$\lambda$ x $\Rightarrow$ fix ($\lambda$ self $\Rightarrow$ $\lambda$ [
  (zero;() $\Rightarrow$ nil;()),
  (succ;n $\Rightarrow$ cons;(x, self n))
]) 
\end{lstlisting}


\section{Language}

\begin{definition}[Syntax]
\[
  \begin{array}{l @{} l}
    e 
    &{} ::=
    \begin{array}[t]{@{} l}
      () 
      \ |\ 
      x
      \ |\ 
      l \cdot e
      \ |\ 
      \sigma\ \widebar{l = e}
      \ |\ 
      \lambda\ \widebar{m \Rightarrow e} 
      \ |\ 
      e/l
      \ |\ 
      e\ e 
      \ |\ 
      \text{let } x : \tau = e\ \text{in}\ e
      \ |\ 
      \text{fix}\ e
    \end{array}
    \\
    m 
    &{} ::=
    \begin{array}[t]{@{} l}
      x 
      \ |\ 
      () 
      \ |\ 
      l \cdot m 
      \ |\ 
      \sigma\ \widebar{l = m}
    \end{array}
    \\
    \tau
    &{} ::=
    \begin{array}[t]{@{} l}
      \text{unit} 
      \ |\ 
      \alpha 
      \ |\ 
      \bot 
      \ |\ 
      \top 
      \ |\ 
      l*\tau 
      \ |\ 
      l:\tau 
      \ |\ 
      \tau\rightarrow\tau 
      \ |\ 
      \left<\exists \widebar{\alpha}\ .\ \tau\ |\ \tau \leq \tau\right>
      \ |\ 
      \left<\forall \widebar{\alpha}\ .\ \tau\ |\ \tau \leq \tau\right>
      \ |\ 
      \mu \alpha.\tau 
      \ |\ 
      \nu \alpha.\tau 
      \ |\ 
      \tau \vee \tau
      \ |\ 
      \tau \wedge \tau
    \end{array}
  \end{array}
\]

\end{definition}


  

\begin{definition}(Operational semantics)
\begin{flalign*}
  &\boxed{t \hookrightarrow t}&
\end{flalign*}
\begin{mathpar}
  \inferrule { 
    e \hookrightarrow e' 
  } {
    E[e] \hookrightarrow E[e']  
  }

  \inferrule {
  } {
    (\sigma\ \widebar{l_i = v_i})/l_j \hookrightarrow v_j
  } 

  \inferrule { 
  } {
    (\lambda\ \widebar{m \Rightarrow e})\ v 
    \hookrightarrow 
    (\text{match } v\ \widebar{m \Rightarrow e})
  } 

  \inferrule { 
  } {
    \text{let}\ x : \tau = v\ \text{in}\ e 
    \hookrightarrow 
    t[x \mapsto v]
  } 

  \inferrule { 
  } {
    \text{fix}\ \lambda [x \Rightarrow e]
    \hookrightarrow 
    e[x \mapsto \text{fix}\ \lambda [x \Rightarrow e]]
  } 
\end{mathpar}
\end{definition}

\begin{definition}
\begin{flalign*}
  &\boxed{\text{match}\ v\ (\widebar{m \Rightarrow t}) = H}&
\end{flalign*}
\[
  \begin{array}{l @{} l}
    \text{match}\ v\ ((m \Rightarrow t) :: cs)
    &{} =
    \begin{cases}
      t[H]
      &\text{if }
      (\text{unify}\ v\ p) = H 
      \\
      
      \text{match}\ v\ cs
      &\text{otherwise}
    \end{cases}
  \end{array}
\]
\end{definition}

\begin{definition}
\begin{flalign*}
  &\boxed{\text{unify}\ v\ p = H}&
\end{flalign*}
\[
  \begin{array}{l @{} l}
    \text{unify}\ v\ x 
    &{} =
    \bullet, x \mapsto v
    \\
    \text{unify}\ ()\ () 
    &{} =
    \bullet
    \\
    \text{unify}\ (l \cdot v)\ (l \cdot p) 
    &{} =
    \text{unify}\ v\ p
    \\
    \text{unify}\ (\sigma\ \widebar{l = v})\ (\sigma\ \widebar{l = p}) 
    &{} =
    \text{reduce}\ ;\ \widebar{\text{unify}\ v\ p}
  \end{array}
\]
\end{definition}

\begin{definition}[Operational structures]
\[
  \begin{array}{l @{} l}
    v 
    &{} ::=
    \begin{array}[t]{@{} l}
      () 
      \ |\ 
      l \cdot v
      \ |\ 
      \sigma\ \widebar{l = v}
      \ |\ 
      \lambda\ \widebar{m \Rightarrow t} 
    \end{array}
    \\
    E 
    &{} ::=
    []
    \ |\ 
    l \cdot E 
    \ |\ 
    \sigma\ \widebar{l = E}
    \ |\ 
    E/l
    \ |\ 
    E\ e 
    \ |\ 
    v\ E
    \ |\ 
    \text{let } x : \tau = E\ \text{in}\ e 
    \ |\ 
    \text{fix } E 
    \\
    H 
    &{} ::=
    \bullet
    \ |\ 
    H, x \mapsto v
  \end{array}
\]
\end{definition}
  

\begin{definition}(Transition semantics)
\begin{flalign*}
  &\boxed{\left<\kappa, \rho, e \right> \hookrightarrow \left<\kappa, \rho, e \right>}&
\end{flalign*}
\begin{mathpar}
  \inferrule { 
  } {
    \left<\left<\rho_\kappa, x, e\right> :: \kappa, \rho, w \right> 
    \hookrightarrow 
    \left<\kappa, (\rho_\kappa,x \mapsto \left<\rho,w\right>), e \right>
  } 

  \inferrule { 
    \left< \rho', w \right> = \rho\ x
  } {
    \left<\kappa, \rho, x \right> 
    \hookrightarrow 
    \left<\kappa, \rho', w \right>
  } 

  \inferrule { 
    \text{contify}\ e = (x, e_\kappa, e')
  } {
    \left<\kappa, \rho, e\right> 
    \hookrightarrow 
    \left<
      \left< \rho, x, e_\kappa\right> :: \kappa,
      \rho,
      e'
    \right>
  } 


  \inferrule { 
    \rho\ x' = \left< \rho', (\sigma\ \widebar{l_i = x_i}) \right> 
  } {
    \left<\kappa, \rho, x' / l_j \right> 
    \hookrightarrow 
    \left< \kappa, \rho', x_j \right>
  } 
  

  \inferrule { 
    \rho\ x_1 = \left< \rho_1, \lambda\ \widebar{m \Rightarrow e} \right> 
    \\
    \rho\ x_2 = \left< \rho_2, w \right>
    \\
    \text{match}\ \rho_2\ w\ \rho_1\ (\widebar{m \Rightarrow e}) = \left<\rho', e'\right> 
  } {
    \left< \kappa, \rho, x_1\ x_2 \right> 
    \hookrightarrow 
    \left< \kappa, \rho', e' \right>
  } 

  \inferrule { 
  } {
    \left< \kappa, \rho, \text{let}\ x : \tau = x'\ \text{in}\ e \right> 
    \hookrightarrow 
    \left< \kappa, \rho, e[x \mapsto x'] \right>
  } 

  \inferrule { 
    \rho\ x = \lambda[x' \Rightarrow e]
  } {
    \left< 
      \left< \rho_\kappa, x_\kappa, e_\kappa \right> :: \kappa, 
      \rho, 
      \text{fix}\ x
    \right> 
    \hookrightarrow 
    \left< \kappa, (\rho,x_\kappa \mapsto \text{fix}\ x), e'[x' \mapsto x_\kappa]\right>
  } 
\end{mathpar}
\end{definition}

\begin{definition}(Multistep semantics)
\begin{flalign*}
  &\boxed{\left<\kappa, \rho, e \right> \hookrightarrow^* \left<\kappa, \rho, e \right>}&
\end{flalign*}
\begin{mathpar}
  \inferrule { 
  } {
    \left< \kappa, \rho, e \right> 
    \hookrightarrow 
    \left< \kappa, \rho, e \right> 
  } 

  \inferrule { 
    \left< \kappa, \rho, e \right> 
    \hookrightarrow^*
    \left< \kappa', \rho', e' \right> 
    \\
    \left< \kappa', \rho', e' \right> 
    \hookrightarrow^*
    \left< \kappa'', \rho'', e'' \right> 
  } {
    \left< \kappa, \rho, e \right> 
    \hookrightarrow^* 
    \left< \kappa'', \rho'', e'' \right> 
  } 
\end{mathpar}
\end{definition}

\begin{definition}(State structures)
\[
  \begin{array}{l @{} l}
    \kappa 
    &{} ::=
    \begin{array}[t]{@{} l}
      \left< \rho, x, e \right> :: \kappa 
      \ |\ 
      \circ
    \end{array}
    \\
    \widebar{\left< \rho, x, e \right>}
    &{} ::=
    \begin{array}[t]{@{} l}
      \left< \rho, x, e \right> ::  \widebar{\left< \rho, x, e \right>}
      \ |\ 
      \circ
    \end{array}
    \\
    \rho 
    &{} ::=
    \begin{array}[t]{@{} l}
      \bullet 
      \ |\ 
      \rho, x \mapsto \left< \rho, w \right> 
    \end{array}
    \\
    w 
    &{} ::=
    \begin{array}[t]{@{} l}
      () 
      \ |\ 
      l \cdot x 
      \ |\ 
      \sigma\ \widebar{l = x}
      \ |\ 
      \lambda\ \widebar{m \Rightarrow e} 
    \end{array}
  \end{array}
\]
\end{definition}




\begin{definition}[Typing]
\begin{flalign*}
  &\boxed{\Gamma \vdash e : \tau}&
\end{flalign*}
\begin{mathpar}
  \inferrule { 
  } {
    \Gamma \vdash () 
    : \text{unit}
  } 

  \inferrule { 
    \Gamma(x) = \tau
  } {
    \Gamma \vdash x
    : \tau 
  } 

  \inferrule { 
    \Gamma \vdash t
    : \tau 
  } {
     \Gamma \vdash (l;t) 
    : l*\tau
  }

  \inferrule { 
    \bigwedge
    \Gamma \vdash t_i :  \tau_i  
  } {
    \Gamma \vdash \sigma\ (\widebar{l_i = t_i})
    : (\text{reduce} \wedge \widebar{l_i : \tau_i})
  } 

  \inferrule {
    \bigwedge
    \Gamma_i \vdash p_i
    : \tau_i
    \ \wedge\
    \Gamma;\Gamma_i \vdash t_i
    : \tau'_i
  } {
    \Gamma \vdash \lambda\ (\widebar{m_i \Rightarrow e_i})
    : (\text{reduce} \wedge \widebar{\tau_i \rightarrow \tau'_i })  
  } 

  \inferrule {
    \Gamma \vdash t
    : l:\tau
  } {
    \Gamma \vdash t/l
    : \tau
  } 

  \inferrule { 
    \Gamma \vdash t_1
    : \tau' \rightarrow \tau
    \\
    \Gamma \vdash t_2
    : \tau'
  } {
    \Gamma \vdash (t_1\ t_2)
    : \tau
  } 

  \inferrule { 
    \bullet \Vdash 
    \left<\forall \widebar{\alpha}\ .\ \tau_5\ |\ \tau_3 \leq \tau_4\right>
    : \tau_1
    \\
    \Gamma \vdash t_1
    : \tau_1
    \\\\
    \Gamma,x \mapsto \left<\forall \widebar{\alpha}\ .\ \tau_5\ |\ \tau_3 \leq \tau_4\right>
      \vdash t_2 
    : \tau_2
  } {
    \Gamma \vdash \text{let}\ x : \tau_1 = t_1 \text{ in } t_2 
    : \tau_2
  } 

  \inferrule { 
    \Gamma \vdash t
    : \tau \rightarrow \tau
  } {
    \Gamma \vdash \text{fix}\ t 
    :\tau
  } 

  \inferrule { 
    \Gamma \vdash t 
    : \tau' 
    \\
    \bullet \Vdash \tau' \leq \tau
  } {
    \Gamma \vdash t
    : \tau
  } 
\end{mathpar}
\end{definition}

\begin{definition}[Type environment find]
\begin{flalign*}
  &\boxed{\Gamma\ x = \tau}&
\end{flalign*}
\[
  \begin{array}{l @{} l}
    (\Gamma, x \mapsto \tau)\ x'
    &{} =
    \begin{cases}
      \tau
      &\text{if } x = x' 
      \\
      \Gamma\ x' 
      &\text{otherwise}
    \end{cases}
  \end{array}
\]
\end{definition}

\begin{definition}[Type environment domain]
\begin{flalign*}
  &\boxed{x \in \text{dom}\ \Gamma}&
\end{flalign*}
\begin{mathpar}

  \inferrule { 
  } {
    x \in \text{dom}\ (\Gamma, x \mapsto \tau)
  } 

  \inferrule { 
    x \neq x'
    \\
    x \in \text{dom}\ \Gamma
  } {
    x \in \text{dom}\ (\Gamma, x' \mapsto \tau')
  } 
\end{mathpar}
\end{definition}



\begin{definition}(Subtyping)
\begin{mathpar}
  \inferrule {
  } {
    \Delta \Vdash \bot
    \leq \tau
  }

  \inferrule {
  } {
    \Delta \Vdash \tau
    \leq \top
  } 

  \inferrule {
    \Delta \Vdash \tau_1
    \leq \tau_2
  } {
    \Delta \Vdash l*\tau_1
    \leq l*\tau_2
  } 

  \inferrule {
    \Delta \Vdash \tau_1
    \leq \tau_2
  } {
    \Delta \Vdash l:\tau_1
    \leq l:\tau_2
  } 

  \inferrule {
    \Delta \Vdash \tau_3
    \leq \tau_1
    \\
    \Delta \Vdash \tau_2
    \leq \tau_4
  } {
    \Delta \Vdash \tau_1 \rightarrow \tau_2
    \leq \tau_3 \rightarrow \tau_4
  } 

  \inferrule { 
    (\text{freevars}\ \Delta) \cap \widebar{\alpha_i} \subseteq \emptyset 
    \\\\
    \forall\ \Delta'\ .\
    (\Delta;\Delta' \Vdash \tau_1 \leq \tau_2)
    \longrightarrow
    (\Delta;\Delta' \Vdash \tau_3 \leq \tau_4)
  } { 
    \Delta \Vdash \left<\exists \widebar{\alpha_i}\ .\ \tau_3\ |\ \tau_1 \leq \tau_2\right>
    \leq \tau_4
  }

  \inferrule { 
    (\text{freevars}\ \Delta) \cap \widebar{\alpha_i} \subseteq \emptyset 
    \\\\
    \Delta;\Delta' \Vdash \tau_1
    \leq \tau_4
    \\
    \Delta;\Delta' \Vdash \tau_2
    \leq \tau_3
  } { 
    \Delta \Vdash \tau_1
    \leq \left<\exists \widebar{\alpha_i}\ .\ \tau_4\ |\ \tau_2 \leq \tau_3\right>
  }

  \inferrule { 
    (\text{freevars}\ \Delta) \cap \widebar{\alpha_i} \subseteq \emptyset 
    \\\\
    \forall\ \Delta'\ .\
    (\Delta;\Delta' \Vdash \tau_2 \leq \tau_3)
    \longrightarrow
    (\Delta;\Delta' \Vdash \tau_1 \leq \tau_4)
  } { 
    \Delta \Vdash \tau_1
    \leq \left<\forall \widebar{\alpha_i}\ .\ \tau_4\ |\ \tau_2 \leq \tau_3\right>
  }

  \inferrule { 
    (\text{freevars}\ \Delta) \cap \widebar{\alpha} \subseteq \emptyset 
    \\\\
    \Delta;\Delta' \Vdash \tau_3
    \leq \tau_4
    \\
    \Delta;\Delta' \Vdash \tau_1
    \leq \tau_2
  } { 
    \Delta \Vdash \left<\forall \widebar{\alpha}\ .\ \tau_3\ |\ \tau_1 \leq \tau_2\right>
    \leq \tau_4
  }

  \\\\

  \inferrule { 
    \Delta \Vdash \tau_1[\alpha_1\mapsto\mu\alpha_2.\tau_2]
    \leq \tau_2[\alpha_2\mapsto\mu\alpha_2.\tau_2]
  } { 
    \Delta \Vdash \mu \alpha_1 . \tau_1
    \leq \mu \alpha_2 . \tau_2
  }

  \inferrule {
  } {
    \Delta \Vdash \tau[\alpha\mapsto\mu \alpha . \tau]
    \leq \mu \alpha . \tau
  }

  \inferrule {
  } {
    \Delta \Vdash \mu\alpha.\tau
    \leq \tau[\alpha\mapsto\mu \alpha . \tau]
  }

  \inferrule { 
    \Delta \Vdash \tau_1[\alpha_1\mapsto\nu\alpha_1.\tau_1] 
    \leq \tau_2[\alpha_2\mapsto\nu\alpha_1.\tau_1]
  } {
    \Delta \Vdash \nu \alpha_1 . \tau_1 
    \leq \nu \alpha_2 . \tau_2
  }

  \inferrule {
  } {
    \Delta \Vdash \tau[\alpha\mapsto\nu \alpha . \tau]
    \leq \nu \alpha . \tau
  }

  \inferrule {
  } {
    \Delta \Vdash \nu\alpha.\tau
    \leq \tau[\alpha\mapsto\nu \alpha . \tau]
  }

  \inferrule {
    \Delta \Vdash \tau_1
    \leq \tau_3
    \\
    \Delta \Vdash \tau_2
    \leq \tau_3
  } {
    \Delta \Vdash \tau_1 \vee \tau_2
    \leq \tau_3
  }

  \inferrule {
  } {
    \Delta \Vdash \tau_1
    \leq \tau_1 \vee \tau_2
  }

  \inferrule {
  } {
    \Delta \Vdash \tau_2
    \leq \tau_1 \vee \tau_2
  }

  \inferrule {
    \Delta \Vdash \tau
    \leq \tau_1
    \\
    \Delta \Vdash \tau
    \leq \tau_2
  } {
    \Delta \Vdash \tau
    \leq \tau_1 \wedge \tau_2
  }

  \inferrule {
  } {
    \Delta \Vdash \tau_1 \wedge \tau_2
    \leq \tau_1
  }

  \inferrule {
  } {
    \Delta \Vdash \tau_1 \wedge \tau_2
    \leq \tau_2
  }

  \inferrule {
  } {
    \Delta \Vdash \tau
    \leq \tau
  }
\end{mathpar}
\end{definition}


\begin{theorem}(Typing progress)
\begin{mathpar}
  \inferrule { 
    \bullet \vdash e : \tau
  } {
    e = v \vee e \hookrightarrow e'
  } 
\end{mathpar}
\end{theorem}

\begin{theorem}(Typing preservation)
\begin{mathpar}
  \inferrule { 
    \bullet \vdash e : \tau
    \\
    e \hookrightarrow e'
  } {
    \bullet \vdash e' : \tau 
  } 
\end{mathpar}
\end{theorem}

\begin{definition}[State abstraction]
\begin{flalign*}
  &\boxed{\left< \kappa, \rho, e \right> \rightleftharpoons \left<\Gamma, \tau \right>}&
\end{flalign*}
\begin{mathpar}
  \inferrule { 
    \rho \rightleftharpoons \Gamma
    \\
    \Gamma \vdash e : \tau
    \\
    \kappa \vdash \tau \triangleright \tau' 
  } {
    \left< \kappa, \rho, e \right> 
    \rightleftharpoons 
    \left< \Gamma, \tau' \right>
  } 
\end{mathpar}
\end{definition}


\begin{definition}[Type inference]
\begin{flalign*}
  &\boxed{\Delta \cdot \Gamma \vDash e : \tau}&
\end{flalign*}

\begin{mathpar}
  \inferrule { 
    \Delta \VDash \text{unit} \leq \tau
  } {
    \Delta \cdot \Gamma \cdot \text{unit} \vDash () : \tau
  } 

  \inferrule { 
    \Delta \VDash (\Gamma\ x) \leq \tau
  } {
    \Delta\ \cdot \Gamma \cdot (\Gamma\ x) \vDash x : \tau
  } 

  \inferrule { 
    \text{fresh}\ \alpha
    \\
    \Delta \VDash (l * \alpha) \leq \tau
    \\
    \Delta \cdot \Gamma \cdot \tau' \vDash e : \alpha
  } {
    \Delta\ \cdot \Gamma \cdot (l * \tau') \vDash (l \cdot e) : \tau
  } 

  \inferrule { 
    \bigwedge \text{fresh}\ \alpha_i
    \\
    \Delta \VDash (\wedge\ \widebar{l_i : \alpha_i}) \leq \tau
    \\
    \bigwedge \Delta \cdot \Gamma \cdot \tau_i' \vDash e_i : \alpha_i
  } {
    \Delta\ \cdot \Gamma \cdot (\wedge\ \widebar{l_i : \tau_i'}) \vDash (\sigma\ \widebar{l_i = e_i}) : \tau
  } 

  \inferrule { 
    \bigwedge \text{fresh}\ \alpha_i'
    \\
    \bigwedge \text{fresh}\ \alpha_i''
    \\
    \Delta \VDash (\wedge\ \widebar{\alpha'_i \rightarrow \alpha''_i}) \leq \tau
    \\\\
    \bigwedge (\text{patenv}\ m_i) \sqsubseteq \Gamma
    \\
    \bigwedge \Delta \cdot \Gamma \cdot \tau_i' \vDash m_i : \alpha'_i
    \\
    \bigwedge \Delta \cdot \Gamma \cdot \tau_i'' \vDash e_i : \alpha''_i
  } {
    \Delta\ \cdot \Gamma \cdot (\wedge\ \widebar{\tau_i' \rightarrow \tau_i''}) 
    \vDash 
    (\lambda\ \widebar{m_i \Rightarrow e_i}) : \tau
  } 

  \inferrule { 
    \Delta \cdot \Gamma \cdot \tau' \vDash e : (l : \tau)
    \\
    \text{fresh}\ \alpha
    \\
    \Delta \VDash \tau' \leq (l : \alpha)
  } {
    \Delta\ \cdot \Gamma \cdot \alpha \vDash (e/l) : \tau
  } 
\end{mathpar}

\[
  \begin{array}{l @{} l}
  \end{array}
\]

\end{definition}


%     \text{infer } \iota\ \Delta\ \Gamma \vdash 
%     (t_1\ t_2) : \tau
%     &{} =
%     \begin{array}[t]{@{} l}
%       \text{let } \alpha_1 = \text{typevar}()
%       \\
%       \text{let } \alpha_2 = \text{typevar}()
%       \\
%       \{ \Delta_1;\Delta_2;\Delta_3\ .\ \alpha_1 \ |\
%       \\
%       \ \ \ \ \Delta_1.\tau_1 \in \text{infer } \iota\ \Delta\ \Gamma \vdash t_1 : (\alpha_2 \rightarrow \tau) 
%       \\
%       \ \ \ \ \Delta_2.\tau_2 \in \text{infer } \iota\ \Delta;\Delta_1\ \Gamma \vdash t_2 : \alpha_2
%       \\
%       \ \ \ \ \Delta_3 \in \text{unify } \iota\ \Delta;\Delta_1;\Delta_2 \vdash 
%       \tau_1 \leq (\tau_2 \rightarrow \alpha_1)
%       \\
%       \}
%     \end{array}
%     \\

%     \text{infer } \iota\ \Delta\ \Gamma \vdash 
%     (\text{let}\ x : \tau_1 = t_1 \text{ in } t_2) : \tau_2
%     &{} =
%     \begin{array}[t]{@{} l}
%       \{ \Delta_2\ .\ \tau_2' \ |\ 
%       \\
%       \ \ \ \ \Delta_1.\tau_1' \in \text{infer } \iota\ \Delta;\Delta_1\ \Gamma \vdash t_1 : \tau_1
%       \\ 
%       \ \ \ \ \tau_1'' \in \{\tau_1'[\Delta_1]\}
%       \\ 
%       \ \ \ \ \widebar{\alpha} \in \{\text{freevars}\ \tau_1''\}
%       \\ 
%       \ \ \ \ \Delta_2.\tau_2' \in \Delta\ \Gamma,x \mapsto \forall \widebar{\alpha} . \tau_1''
%         \vdash t_2 : \tau_2 
%       \\
%       \} 
%     \end{array}
%     \\

%     \text{infer } \iota\ \Delta\ \Gamma \vdash 
%     \text{fix } t : \tau      
%     &{} =
%     \begin{array}[t]{@{} l}
%       \text{let } \alpha_1 = \text{typevar}()
%       \\
%       \text{let } \alpha_2 = \text{typevar}()
%       \\
%       \{ \Delta_1;\Delta_2\ .\ \nu\ \alpha_4 \ . \forall\ \widebar{\alpha} ::
%         \alpha_4 \leq \tau_2\ .\ \tau_3
%         \ |\ 
%       \\
%       \ \ \ \ \Delta_1.\tau_1 \in
%       \text{infer } \blacksquare\ \Delta\ \Gamma \vdash t : \tau \rightarrow \tau
%       \\
%       \ \ \ \ \Delta_2 \in \text{unify } \blacksquare\ \Delta;\Delta_1 \vdash 
%       \tau_1 \leq \alpha_1 \rightarrow \alpha_2 
%       \\
%       \ \ \ \ \tau_2 \in \{\alpha_1[\Delta;\Delta_1;\Delta_2]\}
%       \\ 
%       \ \ \ \ \tau_3 \in \{\alpha_2[\Delta;\Delta_1;\Delta_2]\} 
%       \\
%       \ \ \ \ \widebar{\alpha} \in \{ \text{freevars}\ \tau_2 \}
%       \\
%       \} 
%     \end{array}
%   \end{array}
% \]


\begin{theorem}(Abstraction initialization)
\begin{mathpar}
  \inferrule { 
    \Delta \cdot \Gamma \vDash e : \tau
  } {
    \left< \circ, \bullet, e \right>
    \rightleftharpoons
    \left< \Delta, \Gamma, \tau \right>
  } 
\end{mathpar}
\end{theorem}

\begin{theorem}(Abstraction preservation)
\begin{mathpar}
  \inferrule { 
    \Delta \cdot \Gamma \vDash e : \tau
    \\
    \left< \circ, \bullet, e \right> 
    \hookrightarrow^* 
    \left< \kappa, \rho, e' \right>
  } {
    \left< \kappa, \rho, e' \right>
    \rightleftharpoons
    \left< \Delta, \Gamma, \tau \right>
  } 
\end{mathpar}
\end{theorem}

\begin{definition}(Type inference (old))
\[
  \begin{array}{l @{} l}
    \text{infer } \iota\ \Delta\ \Gamma \vdash 
    \_ : \tau
    &{} =
    \{\bullet.\tau\}
    \\

    \text{infer } \iota\ \Delta\ \Gamma \vdash 
    () : \tau
    &{} =
    \begin{array}[t]{@{} l}
      \{\Delta_1.\text{unit}\ |
      \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \text{unit} \leq \tau
      \}
    \end{array}
    \\

    \text{infer } \iota\ \Delta\ \Gamma \vdash 
    x : \tau
    &{} =
    \begin{cases}  
      \{\Delta_1.\tau_1\ |
      \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau
      \}
      &\text{if } \Gamma(x) = \tau_1
      \\
      \emptyset
      &\text{otherwise}
    \end{cases}
    \\

    \text{infer } \iota\ \Delta\ \Gamma \vdash 
    l ; t : \tau
    &{} =
    \begin{array}[t]{@{} l}
      \text{let } \alpha = \text{typevar}() 
      \\
      \{\Delta_1;\Delta_2\ .\ l ; \tau_1 \ |
      \\
      \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash l ; \alpha \leq \tau
      \\
      \ \ \ \ (\Delta_2.\tau_1) \in \text{infer } \iota\ \Delta;\Delta_1\ \Gamma \vdash t : \alpha
      \\
      \}
    \end{array}
    \\

    \text{infer } \iota\ \Delta\ \Gamma \vdash 
    \sigma\ \widebar{l_i = t_i} : \tau
    &{} =
    \begin{array}[t]{@{} l}
      \text{let } \widebar{\alpha_i} = \widebar{\text{typevar}()}
      \\
      \text{let } \tau' = \text{reduce} \wedge \widebar{l_i : \alpha_i}
      \\
      \text{reduce} * \{
      \text{infer } \iota\ \Delta;\Delta_1\ \Gamma \vdash t_i : \alpha_i\ |\ 
      \\
      \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta\ \vdash \tau' \leq \tau
      \\
      \}
      \\
    \end{array}
    \\

    \text{infer } \iota\ \Delta\ \Gamma \vdash 
    \lambda\ \widebar{m_i \Rightarrow t_i} : \tau
    &{} =
    \begin{array}[t]{@{} l}
      \text{let } \widebar{\alpha_i} = \widebar{\text{typevar}()}
      \\
      \text{let } \tau' = \text{reduce} \wedge 
      \widebar{\tau_i \rightarrow \alpha_i }
      \\
      \text{reduce} * \{
      \text{infer } \iota\ \Delta;\Delta_1;\Delta_2\ \Gamma;\Gamma_1 \vdash t_i : \alpha_i\ |\ 
      \\
      \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta\ \vdash \tau' \leq \tau
      \\
      \ \ \ \ \Gamma_1 \in \{\text{patenv } p_i\}
      \\
      \ \ \ \ \Delta_2.\tau' \in \text{infer } \blacksquare\ \Delta;\Delta_1\ \Gamma;\Gamma_1\ \vdash p_i : \tau_i
      \\
      \}
      \\
    \end{array}
    \\

    \text{infer } \iota\ \Delta\ \Gamma \vdash 
    t/l : \tau
    &{} =
    \begin{array}[t]{@{} l}
      \text{let } \alpha = \text{typevar}()
      \\
      \{ \Delta_1;\Delta_2\ .\ \alpha \ |\
      \\
      \ \ \ \ \Delta_1.\tau_1 \in \text{infer } \iota\ \Delta\ \Gamma \vdash t : l : \tau 
      \\
      \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_1 \leq l : \alpha
      \\
      \}
    \end{array}
    \\

    \text{infer } \iota\ \Delta\ \Gamma \vdash 
    (t_1\ t_2) : \tau
    &{} =
    \begin{array}[t]{@{} l}
      \text{let } \alpha_1 = \text{typevar}()
      \\
      \text{let } \alpha_2 = \text{typevar}()
      \\
      \{ \Delta_1;\Delta_2;\Delta_3\ .\ \alpha_1 \ |\
      \\
      \ \ \ \ \Delta_1.\tau_1 \in \text{infer } \iota\ \Delta\ \Gamma \vdash t_1 : (\alpha_2 \rightarrow \tau) 
      \\
      \ \ \ \ \Delta_2.\tau_2 \in \text{infer } \iota\ \Delta;\Delta_1\ \Gamma \vdash t_2 : \alpha_2
      \\
      \ \ \ \ \Delta_3 \in \text{unify } \iota\ \Delta;\Delta_1;\Delta_2 \vdash 
      \tau_1 \leq (\tau_2 \rightarrow \alpha_1)
      \\
      \}
    \end{array}
    \\

    \text{infer } \iota\ \Delta\ \Gamma \vdash 
    (\text{let}\ x : \tau_1 = t_1 \text{ in } t_2) : \tau_2
    &{} =
    \begin{array}[t]{@{} l}
      \{ \Delta_2\ .\ \tau_2' \ |\ 
      \\
      \ \ \ \ \Delta_1.\tau_1' \in \text{infer } \iota\ \Delta;\Delta_1\ \Gamma \vdash t_1 : \tau_1
      \\ 
      \ \ \ \ \tau_1'' \in \{\tau_1'[\Delta_1]\}
      \\ 
      \ \ \ \ \widebar{\alpha} \in \{\text{freevars}\ \tau_1''\}
      \\ 
      \ \ \ \ \Delta_2.\tau_2' \in \Delta\ \Gamma,x \mapsto \forall \widebar{\alpha} . \tau_1''
        \vdash t_2 : \tau_2 
      \\
      \} 
    \end{array}
    \\

    \text{infer } \iota\ \Delta\ \Gamma \vdash 
    \text{fix } t : \tau      
    &{} =
    \begin{array}[t]{@{} l}
      \text{let } \alpha_1 = \text{typevar}()
      \\
      \text{let } \alpha_2 = \text{typevar}()
      \\
      \{ \Delta_1;\Delta_2\ .\ \nu\ \alpha_4 \ . \forall\ \widebar{\alpha} ::
        \alpha_4 \leq \tau_2\ .\ \tau_3
        \ |\ 
      \\
      \ \ \ \ \Delta_1.\tau_1 \in
      \text{infer } \blacksquare\ \Delta\ \Gamma \vdash t : \tau \rightarrow \tau
      \\
      \ \ \ \ \Delta_2 \in \text{unify } \blacksquare\ \Delta;\Delta_1 \vdash 
      \tau_1 \leq \alpha_1 \rightarrow \alpha_2 
      \\
      \ \ \ \ \tau_2 \in \{\alpha_1[\Delta;\Delta_1;\Delta_2]\}
      \\ 
      \ \ \ \ \tau_3 \in \{\alpha_2[\Delta;\Delta_1;\Delta_2]\} 
      \\
      \ \ \ \ \widebar{\alpha} \in \{ \text{freevars}\ \tau_2 \}
      \\
      \} 
    \end{array}
  \end{array}
\]
\end{definition}


\begin{definition}(Subtype unification)
\[
  \begin{array}{l @{} l}

    \text{unify } \blacksquare\ \Delta \vdash \alpha \leq \tau	
    &{} =
    \begin{cases}  
      \{ \bullet,\alpha \mapsto \nu\alpha.\tau \}
      & \text{if } 
      \alpha \not\in \text{dom}(\Delta) \ \wedge\
      \alpha \in \text{freevars}(\tau[\Delta])
      \\
      \{ \bullet,\alpha \mapsto \tau \}
      & \text{if } 
      \alpha \not\in \text{dom}(\Delta) \ \wedge\
      \alpha \notin \text{freevars}(\tau[\Delta])
      \\
      \text{unify } \blacksquare\ \Delta \vdash \tau_1 \leq \tau
      &\text{if }
      \Delta(\alpha) = \tau_1
    \end{cases}
    \\

    \text{unify } \square\ \Delta \vdash \alpha \leq \tau	
    &{} =
    \begin{cases}  
      \{ \bullet,\alpha \mapsto (\nu\alpha.\tau \wedge \beta) \}
      & \text{if } 
      \alpha \not\in \text{dom}(\Delta) \ \wedge\
      \alpha \in \text{freevars}(\tau[\Delta]) \ \wedge\ 
      \text{fresh } \beta
      \\
      \{ \bullet,\alpha \mapsto \tau \wedge \beta \}
      & \text{if } 
      \alpha \not\in \text{dom}(\Delta) \ \wedge\
      \alpha \notin \text{freevars}(\tau[\Delta]) \ \wedge\ 
      \text{fresh } \beta
      \\
      \text{unify } \square\ \Delta \vdash \tau_1 \leq \tau
      &\text{if }
      \Delta(\alpha) = \tau
    \end{cases}
    \\
    \text{unify } \blacksquare\ \Delta \vdash \tau \leq \alpha 	
    &{} =
    \begin{cases}  
      \{ \bullet,\alpha \mapsto \mu\alpha.\tau \}
      & \text{if } 
      \alpha \not\in \text{dom}(\Delta) \ \wedge\
      \alpha \in \text{freevars}(\tau[\Delta])
      \\
      \{ \bullet,\alpha \mapsto \tau \}
      & \text{if } 
      \alpha \not\in \text{dom}(\Delta) \ \wedge\
      \alpha \notin \text{freevars}(\tau[\Delta])
      \\
      \text{unify } \blacksquare\ \Delta \vdash \tau \leq \tau_1
      &\text{if }
      \Delta(\alpha) = \tau_1
    \end{cases}
    \\
    \text{unify } \square\ \Delta \vdash \tau \leq \alpha	
    &{} =
    \begin{cases}  
      \{ \bullet,\alpha \mapsto (\mu\alpha.\tau \vee \beta) \}
      & \text{if } 
      \alpha \not\in \text{dom}(\Delta) \ \wedge\
      \alpha \in \text{freevars}(\tau[\Delta]) \ \wedge\ 
      \text{fresh } \beta
      \\
      \{ \bullet,\alpha \mapsto \tau \vee \beta \}
      & \text{if } 
      \alpha \not\in \text{dom}(\Delta) \ \wedge\
      \alpha \notin \text{freevars}(\tau[\Delta]) \ \wedge\ 
      \text{fresh } \beta
      \\
      \text{unify } \square\ \Delta \vdash \tau \leq \tau_1
      &\text{if }
      \Delta(\alpha) = \tau
    \end{cases}
    \\
    \text{unify } \iota\ \Delta \vdash
    (\exists \widebar{\alpha_i} :: \tau_1 \leq \tau_2\ .\ \tau_3)
    \leq 
    \tau_4
    &{} = 
    \begin{array}[t]{@{} l}
      \text{let } \tau_1, \tau_2, \tau_3 = 
      \text{refresh } \widebar{\alpha_i}\ \tau_1,\ 
      \text{refresh } \widebar{\alpha_i}\ \tau_2,\ 
      \text{refresh } \widebar{\alpha_i}\ \tau_3
      \\
      \text{let } \Delta_1 = \text{reduce}\ , \widebar{\alpha_i \mapsto \top}
      \\
      \{\Delta_1;\Delta_2;\Delta_3\ |
      \\ 
      \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_2
      \\
      \ \ \ \ \Delta_3 \in \text{unify } \iota\ \Delta;\Delta_1;\Delta_2 \vdash \tau_3 \leq \tau_4
      \\
      \}
    \end{array}
    \\
    \text{unify } \iota\ \Delta \vdash
    \tau_1
    \leq 
    (\exists \widebar{\alpha} :: \tau_2 \leq \tau_3\ .\ \tau_4)
    &{} = 
    \begin{array}[t]{@{} l}
      \text{let } \tau_2, \tau_3, \tau_4 = 
      \text{refresh } \widebar{\alpha}\ \tau_2,\ 
      \text{refresh } \widebar{\alpha}\ \tau_3,\ 
      \text{refresh } \widebar{\alpha}\ \tau_4
      \\
      \{\Delta_1;\Delta_2\ |
      \\ 
      \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_4
      \\
      \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_2 \leq \tau_3
      \\
      \}
    \end{array}
    \\
    \text{unify } \iota\ \Delta \vdash
    \tau_1
    \leq 
    (\forall \widebar{\alpha_i} :: \tau_2 \leq \tau_3\ .\ \tau_4)
    &{} = 
    \begin{array}[t]{@{} l}
      \text{let } \tau_2, \tau_3, \tau_4 = 
      \text{refresh } \widebar{\alpha_i}\ \tau_2,\ 
      \text{refresh } \widebar{\alpha_i}\ \tau_3,\ 
      \text{refresh } \widebar{\alpha_i}\ \tau_4
      \\
      \text{let } \Delta_1 = \text{reduce}\ , \widebar{\alpha_i \mapsto \bot}
      \\
      \{\Delta_1;\Delta_2;\Delta_3\ |
      \\ 
      \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta \vdash \tau_2 \leq \tau_3
      \\
      \ \ \ \ \Delta_3 \in \text{unify } \iota\ \Delta;\Delta_1;\Delta_2 \vdash \tau_1 \leq \tau_4
      \\ 
      \}
    \end{array}
    \\
    \text{unify } \iota\ \Delta \vdash
    (\forall \widebar{\alpha} :: \tau_1 \leq \tau_2\ .\ \tau_3)
    \leq 
    \tau_4
    &{} = 
    \begin{array}[t]{@{} l}
      \text{let } \tau_1, \tau_2, \tau_3 = 
      \text{refresh } \widebar{\alpha}\ \tau_1,\ 
      \text{refresh } \widebar{\alpha}\ \tau_2,\ 
      \text{refresh } \widebar{\alpha}\ \tau_3
      \\
      \{\Delta_1;\Delta_2\ |
      \\ 
      \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_3 \leq \tau_4
      \\
      \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_1 \leq \tau_2
      \\
      \}
    \end{array}

  \end{array}
\]
\end{definition}

\begin{definition}
\[
  \begin{array}{l @{} l}
    \text{unify } \iota\ \Delta \vdash \bot \leq \_	
    &{} = 
    \{\bullet\}
    \\
    \text{unify } \iota\ \Delta \vdash \_ \leq \top	
    &{} = 
    \{\bullet\}
    \\
    \text{unify } \iota\ \Delta \vdash \text{unit}  \leq \text{unit}	
    &{} = 
    \{\bullet\}
    \\
    \text{unify } \iota\ \Delta \vdash l*\tau_1 \leq l*\tau_2	
    &{} = 
    \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_2
    \\
    \text{unify } \iota\ \Delta \vdash l:\tau_1 \leq l:\tau_2	
    &{} = 
    \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_2
    \\
    \text{unify } \iota\ \Delta \vdash \tau_1\rightarrow\tau_2 \leq \tau_3\rightarrow\tau_4	
    &{} = 
    \begin{array}[t]{@{} l}
      \{\Delta_1;\Delta_2\ |
      \\ 
      \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_3 \leq \tau_1
      \\
      \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_4 \leq \tau_2
      \\
      \}
    \end{array}
    \\
    \text{unify } \iota\ \Delta \vdash
    \mu \alpha . \tau_1 \leq \mu \alpha . \tau_2
    &{} = 
    \Delta \vdash 
    \tau_1[\alpha_1\mapsto\mu\alpha_2.\tau_2] \leq 
    \tau_2[\alpha_2\mapsto\mu\alpha_2.\tau_2]

    \\
    \text{unify } \iota\ \Delta \vdash
    \tau_1 \leq \mu \alpha . \tau_2
    &{} = 
    \begin{cases}  
      \text{unify } \iota\ \Delta \vdash 
      \tau_1 \leq \tau_2[\alpha\mapsto\mu\alpha.\tau_2]	
      &\text{if }
      \text{unrollform } \Delta \vdash \tau_1
      \\
      \emptyset
      &\text{otherwise}
    \end{cases}

    \\
    \text{unify } \iota\ \Delta \vdash
    \nu \alpha_1 . \tau_1 \leq 
    \nu \alpha_2 . \tau_2	
    &{} = 
    \text{unify } \iota\ \Delta \vdash 
    \tau_1[\alpha_1\mapsto\nu\alpha_1.\tau_1] \leq 
    \tau_2[\alpha_2\mapsto\nu\alpha_1.\tau_1]

    \\
    \text{unify } \iota\ \Delta \vdash
    \nu \alpha . \tau_1 \leq 
    \tau_2 \rightarrow \tau_3
    &{} = 
    \begin{cases}
      \text{unify } \iota\ \Delta \vdash
      \tau_1[\alpha\mapsto\nu\alpha.\tau_1]
      \leq 
      \tau_2 \rightarrow \tau_3
      &\text{if }
      \text{unrollform } \Delta \vdash \tau_2
      \\
      \text{unify } \iota\ \Delta \vdash
      \tau_1[\alpha\mapsto\nu\alpha.\tau_1]
      \leq 
      \tau_2 \rightarrow \tau_3
      &\text{if }
      \text{unrollform } \Delta \vdash \tau_3
      \\
      \text{unify } \iota\ \Delta \vdash
      (\text{rw\_func\_type}\ \nu\alpha.\tau_1)
      \leq 
      \tau_2 \rightarrow \tau_3
      &\text{otherwise }
    \end{cases}

    \\
    \text{unify } \iota\ \Delta \vdash
    \tau_1 \vee \tau_2 \leq \tau_3
    &{} = 
    \begin{array}[t]{@{} l}
      \{\Delta_1;\Delta_2\ |
      \\ 
      \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_3
      \\
      \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_2 \leq \tau_3
      \\
      \}
    \end{array}

    \\
    \text{unify } \iota\ \Delta \vdash
    \tau_1 \leq \tau_2 \vee \tau_3
    &{} = 
    (\text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_2)
    \cup
    (\text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_3)

    \\
    \text{unify } \iota\ \Delta \vdash
    \tau_1 \leq \tau_2 \wedge \tau_3
    &{} = 
    \begin{array}[t]{@{} l}
      \{\Delta_1;\Delta_2\ |
      \\ 
      \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_2
      \\
      \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_1 \leq \tau_3
      \\
      \}
    \end{array}

    \\
    \text{unify } \iota\ \Delta \vdash
    \tau_1 \wedge \tau_2 \leq \tau_3
    &{} = 
    (\text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_3)
    \cup
    (\text{unify } \iota\ \Delta \vdash \tau_2 \leq \tau_3)

  \end{array}
\]
\end{definition}

\begin{definition}
\[
  \begin{array}{l @{} l}
  \Delta\ ;\ \bullet
  &\ = \Delta 
  \\
  \Delta_1;(\Delta_2,\alpha \mapsto \tau) 
  &\ = (\Delta_1;\Delta_2),\alpha \mapsto \tau
  \end{array}
\]
\end{definition}

\begin{definition}
\[
  \begin{array}{l @{} l}
  M_1 * M_2 
  &\ = 
  [\Delta_1 ; \Delta_2 \ |\ 
    \Delta_1 \in M_1
    \ \ \  
    \Delta_2 \in M_2
  ]
  \end{array}
\]
\end{definition}

\begin{definition}
\[
  \begin{array}{l @{} l}
  \text{reduce} \wedge [] 
  &\ = \top
  \\
  \text{reduce} \wedge \tau::\widebar{\tau}
  &\ = \tau\ \wedge (\text{reduce} \wedge \widebar{\tau})
  \end{array}
\]
\end{definition}

\begin{definition}
\[
  \begin{array}{l @{} l}
    N_1 * N_2
    &\ = 
    \begin{array}[t]{l}
      [ \Delta_1 ; \Delta_2 . \tau_1 \wedge \tau_2 \ |\ 
        \Delta_1.\tau_1 \in N_1
        \ \ 
        \Delta_2.\tau_2 \in N_2
      ]
    \end{array}
  \end{array}
\]
\end{definition}

\begin{definition}
\[
  \begin{array}{l @{}l}
  \text{reduce} * \{N\}
  & {}= N
  \\
  \text{reduce} * \widebar{N_i}
  & {}= N_j * (\text{reduce} * \widebar{N_i}\setminus\{N_j\})
  \end{array}
\]
\end{definition}

\section{Evaluation}
\begin{enumerate}
  \item experiments 
  \item adequacy of problem 
  \item adequacy of solution 
\end{enumerate}

\section{Related work}
\begin{enumerate}
  \item past work 
  \item future work 
\end{enumerate}

\section{Conclusion}
\begin{enumerate}
  \item restate context with technical terms 
  \item restate problem with technical terms 
  \item restate solution with technical terms 
  \item restate results 
\end{enumerate}

% \section*{Notes}

% \subsection*{dualities}
% \begin{enumerate}
%   \item \(\bot \leq \top \)
%   \item \(\tau_1\ \&\ \tau_2  \leq \tau_1\ |\ \tau_2 \)
%   \item \(\forall \alpha . \tau \leq \exists \alpha . \tau \)
%   \item \(\nu \alpha . \tau \leq \mu \alpha . \tau \)
% \end{enumerate}

% \subsection*{contributions}
% \begin{enumerate}
%   \item program synthesis such that:
%     \begin{enumerate}
%       \item goal defined by partial programs with missing annotations  
%       \item goal transformed into type specification 
%       \item type specification may contain dynamic type  
%     \end{enumerate}
%   \item algorithmic subsumption allows simple subtyping rule with dynamic type
%     \begin{enumerate}
%       \item subtyping can have a dynamic type on either side without risk of   
%         all terms being accepted by typing rules (i.e. everything typing)
%     \end{enumerate}
%   \item an expressive type system 
%     based on intersection/union, (co)inductive, and quantified types
%     \begin{enumerate}
%       \item without dependent types 
%       \item comparable to prolog 
%       \item allows dynamic type 
%       \item sound modulo absence of dynamic type 
%         or static type union/intersect with dynamic
%       \item types behave either leniently or strict depending on usage as actual type or expected type
%     \end{enumerate}
%   \item full type synthesis with full type propagation (for all rules)
%   \item type unification such that: 
%     \begin{enumerate}
%       \item the principal type of all terms is top
%       \item lenient (but unsound) static type inference
%       \item expanding type info with union and intersection and dynamic type
%     \end{enumerate}
%   \item interleaving type constraint generation and solving with dynamic type 
% \end{enumerate}

% \subsection*{differences}
% in contrast with System F:  
% \begin{enumerate}
%   \item types are not used as arguments to functions 
%   \item universal binders do not represent placeholder for type argument 
% \end{enumerate}

% in contrast with gradual typing:  
% \begin{enumerate}
%   \item infers more static type info 
%   \item stronger soundness claim (i.e. weaker soundness precondition)
%   \item dynamic semantics are irrelevant 
%   \item deterministic subsumption 
%   \item dynamic type built into subtyping 
% \end{enumerate}

% in contrast with HM type inference:  
% \begin{enumerate}
%   \item synthesizes type in addition to constraint solution 
%     due to subtyping
%   \item propagates types
%   \item global top type, leaves types open during unification
%   \item expands and narrows types  
% \end{enumerate}

% in contrast with Roundtrip typing:  
% \begin{enumerate}
%   \item type combinators without dependent types
%   \item prolog-like type language  
%   \item synthesizes types for all rules
%   \item global top type, leaves types open during unification
%   \item expands and narrows types  
%   \item delegates to unification to decompose types 
%   \item delegates to unification to free bound variables 
% \end{enumerate}




% \subsection*{gradual typing}
% How gradually typed inference typically works:
% \begin{enumerate}
%   \item infer either a strict static type or a dynamic type
%   \item let annotations implicitly guide the usage of static vs dynamic checks 
% \end{enumerate}
% There exists work on type inference for gradually typed programs.
% To the best of my knowledge, they are all sound and complete.
% Other gradual type inference systems separate 
% generating constraints from solving constraints.
% Gradual typing systems use the dynamic type \lstinline{(?)} to indicate 
% that dynamic checks should be used.
% Gradual type inference relies on ML types with union extension.
% They do not contain the idea of using intersection and union to keep types open.
% Gradual typing systems separate subtyping from the relation 
% between dynamic to static types to avoid all terms typing via the subsumption rule.


% \subsection*{references}
% \begin{enumerate}
% \item Refinement types for ML by Tim Freeman and Frank Pfenning 
% \item Refinement types as proof irrelevance by William Lovas and Frank Pfenning 
% \item Local type inference by Benjamin C. Pierce and David N. Turner
% \item Liquid types - \url{http://goto.ucsd.edu/~rjhala/papers/liquid_types.pdf}
% \item Program synthesis from polymorphic refinement types by Nadia Polikarpova, Ivan Kuraj, and Armando Solar-Lezama
% \item Example-directed synthesis: a type-theoretic interpretation by Frankle, Osera, Walker, and Zdancewic
% \item Gradual typing for functional languages by Jeremy G. Siek and Walid Taha 
% \item Gradual typing for functional languages by Jeremy G. Siek and Walid Taha 
% \item Gradual typing for objects by Jeremy G. Siek and Walid Taha 
% \item Gradual typing with unification-based inference by Siek and Manish Vachharajani 
% \item Dynamic Type Inference for Gradual HindleyMilner Typing - \url{https://dl.acm.org/doi/pdf/10.1145/3290331}
% \item Principal type schemes for gradual programs - \url{https://www.cs.ubc.ca/~rxg/ptsgp.pdf}
% \item Gradual Liquid Type Inference - \url{https://arxiv.org/pdf/1807.02132.pdf}
% \item Gradual typing with union and intersection types - \url{https://dl.acm.org/doi/pdf/10.1145/3110285}
% \item Gradual typing: a new perspective - unions, intersections, dynamic type, and type inference - \url{https://www.irif.fr/~gc/papers/popl19.pdf}
% \item Gradual refinement types (via abstract interpretation) - \url{https://pleiad.cl/papers/2017/lehmannTanter-popl2017.pdf}
% \item Consistent subtyping for all - \url{https://xnning.github.io/papers/consistent-subtyping-for-all-toplas.pdf}
% \item Polymorphic functions with set-theoretic types, part 1 - \url{https://www.irif.fr/~gc/papers/polydeuces-part1.pdf}
% \item Polymorphic functions with set-theoretic types, part 2 - \url{https://www.irif.fr/~gc/papers/polydeuces-part2.pdf}
% \item Revisiting occurrence typing - \url{https://arxiv.org/pdf/1907.05590.pdf} 
% \item An ideal model for recursive polymorphic types; MacQueen, Plotkin, Sethi; Metric/Contraction/Banach fixed point theorem
% \item Bottom-up synthesis of recursive functional programs using angelic execution - Anders Miltner et al


% \end{enumerate}


\end{document}

% Observations:
% language of types
  % a type is a set of objects
  % a type may be viewed as proposition that may be undecidable 
    % proved by a term
% language of constraints
  % A constraint may be viewed as a decidable proposition 
  % A constraint is simply a subtyping relation over types
    % allowing economical reuse of types 
  % A fully assigned subtyping constraint is a verifiable statement
% Freeing variables happens in subtyping/unification due to subtyping asymmetry  
  % free variable in subtyping connects to free variable associated with term 
  % if expected type has free variable.
% widening and narrowing in type inference
  % exactness param chosen during inference 
    % exactness flag is justified by dual purpose of type system
      % 1. catch errors (exactly according to spec)
      % 2. describe behavior of program abstractly
  % annotations are exact 
  % everything else is non-exact;
    % allowing union and intersection with fresh variables
% comparison of relational types with dependent types

  % dependent types
    % inductive LL : Nat -> Type where
    % | nil : LL 0 
    % | cons : {n : Nat} -> LL n -> LL (n + 1) 

    % F   (n : Nat) -> LL n
    % P   (n : Nat)  LL n

    % variable introduction is coupled with type construction/compounding
    % this is convenient since a type may dependent on a term that's not included in itself


  % relational types 
    % P  
    % (0^@  nil^@) | 
    % ( N L :: N  L  P => 1^N  cons^L) 

    % translating from dependent to relational
    %  {n : Nat}  LL n  LL (n + 1) 
    %  {n : Nat} {l: List} :: (l : LL n)  {(n + 1, cons l)}  
    % ( N L :: N  L  P => 1^N  cons^L) 

    % -- OR -- 

    % F  
    % (nil^@ -> 0^@) ; 
    % ( L N :: F  L -> N => cons^L -> 1^N) 

    % translating from dependent to relational
    %  {n : Nat} -> LL n -> LL (n + 1) 
    %  {n : Nat} {l: List} :: (l : LL n) -> {for cons l => n + 1}  
    % ( L N :: F  L -> N => cons^L -> 1^N) 


    % variable introduction is decoupled from type construction 
    % the use of a variable in a type is separate from introducing the variable
    % this is convenient since any term that a type depends on exists as a subpart
    % of a term in that type
    % Thus, dependencies may be inferred from terms.

    % My intuition is that the symmetrical relations 
    % and the decoupling of binder introduction from type combination 
    % and consistent treatment of type dependency and type membership 
    % provides an easier mental model to work with
  % closed parameter 
    % indicates if a constraint is closed vs open 
    % variables are fully determined in closed unification 
    % variables are are open to future information in open unification 


% claim: SOTA: type systems for dynamically typed languages do not have type-directed synthesis methods. 
% identify problems for synthesis evaluation
% translate Liquid type benchmarks to this relational type language. 

% Aim.cen/Aim.adj is safe when the free variables may be chosen (i.e. choosable).
% we use Aim.cen when we only care about checking for safety.
% we use Aim.adj when we want to find the most lenient model possible, 
% amenable to safe term compositions in the unexplored parts of the program. 
% Aim.max and Aim.min is necessary when the variables are fixed but unknown; they may not be chosen. 

% for dynamically typed languages, system F subtyping is too restrictive
% we need to compare types that have varying degrees of variable generalization 
% additionally, the subtyping constraints in quantified types are more general than system F
% variables are not restricted to be alone on the left side of subtyping. 
% this generality allows for concise descriptions of inductive function types.

% Remy's ML-calc uses quantified constraint for a similar goal, but technically quite different.
% Remy's ML-calc makes a distinction between subtyping and instantiating relation of universal
% relational types merges the notion of instantiation with subtyping
% relational types generalizes second-order quantification to subsume first-order use-cases. 

% note that Remy' constraint uses existential because the subtyping is inside
%  X :: C(X)  X  T === ( X :: C(X) . X)  T

% synquid has a symmetrical rule using implication for subtyping constraint types
% in Synquid is subtyping depends only on the constraints 
% in our setting subtyping can depend on base types too
% the asymmetrical rules can handle all permutations 
% Synquid lacks decomposition of predicates
% Relational types allows decomposition like functional/logic programming, thus is more natural to use.


% subtyping constraints may be thought of as decidable propositions of the metalanguage 
% equivalent to deciding if a proof satisfies a proposition (of the object language)
% types may be thought of as possibly undecidable propositions of the object language
% the advantage of using subtyping as the only metalanguage predicate is operating on types
% is that types can be reused across both the object language and metalanguage propositions.

% it would have been possible to define a first-order constraint language, as is the case in Synquid,
% but that would not allow reusing information across types and constraints.
% by adding constraints to the second-order quantification of types, 
% a single quantification mechanism serves two distinct purpose
% 1. to precise define the contents of a type. (typically the purpose of first-order quantification)
% 2. to allow specialization of type based on usage (typically the purpose of second-order quantification) 


% there are two distinct purposes of polymorphic quantification over types
  % 1. parametric - ignoring a sub part of a type (2nd order) 
  % 2. constrained - defining a type based on constraints (1st or 2nd order)

% there are two distinct forms of checking polymorphic composition 
  % 1. instantiation a quantified variable supports both parametric and constrained polymorphism
  % 2. subtyping of quantified type over the same variables   

% RT uses second order univ/exists quantifiers subsume both constraint types and polymorphic types
% RT's subtyping subsumes both instantiation and refinement  
% liquid's refinement type is an intersection of a base type and a constraint type. 
  % that is, the resulting type is a refinement of the base type. 


% RT's subtyping subsumes both System F polymorphic subtyping with Synquid/Remy's polymorphic instantiation  
% RT's subtyping subsumes both Synquid's refinement subtyping and existential instantiation
% RT's existential generalizes subpart irrelevance and subpart refinement 


% type-checking vs model-checking
  % downward propagation vs conflict driven clause learning 
    % downward propagation teaches provides types that avoid failing search space. 
    % SAT uses conflict driven clause learning to avoid failing branches  
  % compositional typing vs counter-example guidance 
    % refines the context/assumptions 
  % unification vs boolean constraint propagation
    % determines assignment for variables 


% learning inductive invariant by counter-example guided vs downward propagation 
% counter-example method 
  % notice that return type can't be satisfied 
  % use proof of unsat to construct new invariant
  % update premise with invariant (formula over parameters of recursive function)
  % repeat
% propagation method
  % infer loop parameters from downward prop and unification with adjustment 

% comparison to model checking
  % same: we compute the inductive invariant
  % different: but we don't compute the fixed point
    % we merely represent the fixed point with a mu/nu binder.
      % since we don't necessarily have finite states
    % then we check that the inductive invariant subtypes the closed-form type. 
  % union/intersection adjustment is a compositional version of 
    % transition systems' (widening,expansion)/(narrowing,contraction)
      % the latter of which is wrt inductive invariants (IH)
    % if the type of a location is adjustable 
      % then the operational semantics can take a step with any value at that location

% -- learning inductive invariant:
% -- conjecture: downward propagation prunes search space just like counter-example-driven refinement
%     swap: (x0 : nat * y0 : nat) -> (x' : nat * y' : nat) 
%     -- pre condition: 
%     -- x0 >= y0
%     -- t = x0 - y0

%     -- post condition:
%     -- y' = x0 /\ x' = y0  
%     fun swap (x0, y0) =

%         -- invariant
%         -- t >= 0 /\ x = x0 - t /\ y = y0 + t  
%         -- type inference infers strongest post condition of premise here
%         fun loop (x, y, t) =
%             if (t > 0) then
%                 loop (x - 1, y + 1, t - 1)
%             else 
%                 (x, y)

%         -- type inference finds pre condition that strengthens loop's post-condition invariant  
%         loop (x0, y0, x0 - y0)


% /-
% first order quantification

%  NL .
%   {(0, [])}  
%    (n, l) : NL . 
%     (n + 1,  () :: l)  

%  N2L .
%   {0 => []}  
%    n -> l : N2L .  WRONG
%     {n + 1 => () :: l }

%  N2L .
%   0 -> nil*unit  
%    N2L  N -> L .    
%     N + 1 => unit :: L

% --- 
% by second order quantification with subtyping rather than first order with membership,
% we avoid mapping between terms and types in unification procedure.
% We also enable the succient coinductive definitions of functions.

% -/


% /-
% translating Liquid types into relational types

% List with len where
% [] : {v  List | len v = 0} | 
% () :: (xs : List) : {v  List | len v = (len xs) + 1} | 

% n : Nat -> {v  List | len v = n}

% ...

%  N . N  Nat => N -> ( L . 
%   (N  L)  ( N'  L' .  (0  []) | (N' + 1  () :: L'))  =>
%   L
% )

% ...

%  N -> L .
%   0 -> []  
%   N + 1 -> () :: L  


% -/

% comparison of typing systems
  % bidirectional type checking 
    % full program required 
    % some rules require type annotations: type checking rules
    % some rules don't have type annotations: type inference rules 
  % bidirectional program checking 
    % full type required
    % some types also have program examples: program checking rules
    % some types don't have program examples: program synthesis rules 
  % generalized type checking 
    % all rules handle both type checking and type inference
      % propagate types down and up
  % generalized program checking 
    % all rules handle both program checking and program synthesis 
      % propagate programs down and up

% novel contributions 
  % 1. outcome: synthesis from context (without annotations) 
    % sota: bidirectional/roundtrip typing using annotations 
    % contribution: both up and down propagation for every syntax rule
      % propagating types (downward/upward) 
      % A synthesis algorithm capable of generating local constraints for incomplete programs. 
  % 2. outcome: inference of expressive types
    % sota: refinement types require base type 
    % contribution: relational types
      % relating types (inductive/coinductive) 
      % A type level language capable of expressing (co)inductive relations without the complexity of dependent types or propositional syntax.  
  % 3. outcome: safe but lenient type inference without prescription
    % sota: datatypes/ML languages prescribe upper bound 
    % contribution: adjusting types with union and intersection
      % A unification algorithm capable of preserving the flexibility of dynamically typed programming. 

% additional observations 
  % outcome: subtyping is first-class
    % sota: separate constraints, type schemes 
      % separate constraints, type schemes, and types
      % separate constraint semantics, instantiation/generalization, subtyping
    % contribution: 
      % the subtyping semantics is sufficiently expressive
      % subtyping subsumes constraint semantics and instantiation/generalization
      %e.g. union and intersection, asymmetrical quantification subtyping
      %partial instantiation in generalized polymorphic subtyping
      % subtyping encodes instantiation: ((ALL X . T) <: T')
      % e.g. 
        % g(f : int -> int)
        % h : All X . X -> X
        % g(h) is accepted by specializing h in subtyping

% automatic partial instantiation 
  % NOTE: this seems like a significant innovation in eager inference. 
  % specializes arguments not just applicator
  % specializes type of polymorphic arguments!!!
    % g(f : All X . T)
    %: h : All X . S
    % g(h)
    % specializes h
  % when expected type is also polymorphic 
  % with general constraints (rather than just upper bound)
  % generalization of subtyping
  % compare to instantiation of other systems
    % Cardelli's system F<: does not have instantiation
    % Pierce's local type inference (section 3) does not have partial instantiation
    % synquid does not have partial instantiation or polymorphic subtyping 
    % system F does not have instantiation or generalized constraints

% relational type's type inference and unification with union type
  % generates sets of typing environments 
  % represented with functions instead of inference rules 
  % this is difficult to represent with inference rules 

% relational type's inference and synthesis 
  % type inference for each term case and an arbitrary type
  % program synthesis for for hole term and each type case.

% sequent calculus rules 
  % enable generating derivation
  % the essence is its using left and right rules (relative to the turnstile)
  % left rules have type/prop form on lhs of |-
  % left rules correspond to elimination rules of natural deduction
  % it's not essential that the sequents have multiple consequents

% synthesis rules
  % union on left should result in a cases function applied to an argument
  % intersection on Right should result in either a function or a record
  % thus, can reduce union on left to intersection on right.
  % first-class pattern matching with beta-normal form heuristic
    % could require function to be let-bound 

% use of negation
  % could negation of T be encoded as T -> bot?
  % that is,
    % T1 -> T2 /\ NOT T3 = % T1 -> T2 /\ T3 -> bot

% enumeration: enumerating combinations from a set
  % data-guided
    % unsound guidance from data constructors found in types 
  % relation-guided
    % using relation between data in types
    % shown by Frankle to be worse than broader data-guidance 
  % context-guided 
    % samples from context are combined
    % polymorphic sampling
      % not supported in Frankle's sequent calculus

% inductive generalization
  % inductive generalization normalized as finding a subtype
    % either infer type from term
    % or if hole with expected type
      % enumerate possibilities for hole 
      % choose one
      % infer type
  % generalization adds information
  % thus decreasing information loss when finding types for holes in deduction phase 

% propagation down of subtype/generalized type
  % will be sound (no information loss) 
    % whereas propagation of examples/supertype would lose information
    % less refined search space
    % less strict type checking for the hole
  % providing better guidance to search for term

% best-first search
  % need priority queue to determine which hypothesis to try next after failed hypothesis 
    % with DFS, we wouldn't be able to determine which depth's solution to retry.
  % to avoid redundant traversals of expressions, holes are identified by variable and a hole type-environment.
    % when hypothesis is generated, then it's substituted in, and removed from hole type-env.
  % Feser's algorithm and Frankle's synchronous rules are BFS


% -- synthesize procedure
%   -- best-first search
%   -- alternate between infer (deduce) and enumerate (induce)
%   -- infer produces a Contract 
%   -- enumerate produces a Hypothesis



% semantics (non-deterministic)
  % syntax-directed with non-deterministic subsumption 
  % some elim and intro rules are encoded as various combinations of subsumption with application 
    % e.g. disjunction/cases elim/intro, conjunction elim/intro

% future work: specification of reactive programs
  % non-termination programs. no output, just side-effects or internal state.


% TODO:
% modify to full program synthesis
  % see if data structure transformers can be emulated using refinement type inference 
  % does angelic synthesis relate to this?
% find way to integrate SMT solvers 
% write paper 
  % [x] 0. introduction 
  % [ ] 1. motivating example / overview 
  % - 2. problem statement 
  % - 3. overall synthesis/inference algorithm/rules 
    % include how type information propagates
    % abstract away relation type details
    % includes propagation of types
  % - 4. unification / subtyping / relational typing
    % including induction over intersection and implication types
% find decision procedure for relational types (subtyping over induction on compound types)
  % terminate if one side is compound with all variables and other is inductive? 
  % Banach fixed-point theorem?
  % contraction maps?
  % metric spaces?
% determine if negation/relative complement is needed to improve program synthesis 
  % see anti-specification in Anders' paper
  % https://courses.cs.washington.edu/courses/cse507/14au/sched.html
  % https://www.cs.utexas.edu/~bornholt/post/synthesis-explained.html
  % https://people.csail.mit.edu/asolar/SynthesisCourse/Lecture1.htm
% implement proof of soundness
% implement translation from surface syntax to nameless syntax 
% consider methods of ensuring beta-normal forms
  % splitting off elim forms than can't refer to intro forms to prevent non-beta-normal forms
  % normal form syntax use let-binding (similar to ANF or CPS or SSA)


% comparison of transition systems vs compositional systems 
  % widening/narrowing
    % composition: type adjustment according to variable
    % transitions: widening/narrowing operator between steps
  % mutation 
    % transitions are necessary, composition insufficient 
  % abstract interpretation
    % useful for transitions, superfluous for composition 

% motivation of abstract interpretation
  % where it's valuable
    % abstract interpretation is motivated by data-flow
    % data-flow is motivated non-compositional termination 
    % notes:
      % for transition systems that widen/narrow with each step,
        % abstraction/concretizing enables leveraging transitions of the dynamic semantics
        % to infer transitions of static analysis
      % therefore enables method for construction of data-flow/small-step static semantics 
      % small-step requires keep track of types for every sub-expression in the program
        % the abstract value is the top level expression with 
          %\Gamma environment mapping every sub-expression to a type 
      % when is small-step necessary? tracking side-effects.
  % where it's just over-engineering
    % static rules are sufficient for natural deduction
    % natural deduction is sufficient without side effects
    % notes:
      % for natural deduction, 
        % abstraction/concretizing is equivalent to the static relation
        % the static relation has no transitions to be inferred
      % abstract interpretation just seems like over engineering for natural deduction systems
      % definition abstraction is the same as defining a big-step static semantics 
      % defining abstraction/concretizing and proving a galois connection
        % is in effect the same as proving soundness 

  % analysis techniques
    % compositional (structural termination) (directed dependence) 
      % type system
    %flow (monotonic termination) (mutual dependence)
      % constraint-based 
        % define constraints and abstraction 
        % prove constraints sound wrt abstraction
      % state machine 
        % define abstract transitions in terms of abstraction 
        % proving abstract transitions sound is trivial 

  % %%%%%%%%%%%%%
  % %% here are some over-engineered definitions
  % %%%%

  % \begin{mathpar}

  % \inferrule { 
  % } {
  %   \left< E \right> = \text{reduce} \wedge\ \{\left< \bullet \vdash e \right>\ |\ e \in E \}
  % } 

  % \inferrule { 
  % } {
  %   \left< \llbracket e \rrbracket \right>
  %   =
  %   \left< \bullet \vdash e \right>
  % } 

  % \inferrule { 
  % } {
  %   \left< \llbracket e \rrbracket \right> \leq \tau
  %   \equiv
  %   \llbracket e \rrbracket \subseteq \lfloor \tau \rfloor
  % } 

  %   \inferrule { 
  %   } {
  %     \left< e \right> \leq \tau
  %     \equiv
  %     e \in \lfloor \tau \rfloor
  %   } 
  % \end{mathpar}

