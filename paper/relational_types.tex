% \documentclass{article}
% \documentclass[]{acmart}
\documentclass[sigplan,screen]{acmart}
\usepackage{mathpartir}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{stmaryrd}
\usepackage{listings}

\lstset{
    identifierstyle=\color{violet},
    % textcolor=blue,
    % keywordstyle=\color{blue},
    keywordstyle=\text,
    basicstyle=\ttfamily,
    mathescape=true,
    showspaces=false,
    morekeywords={let, fix}
}
\usepackage[utf8]{inputenc}
% \usepackage[T1]{fontenc}


\title{Programming with relational types}
\author{Thomas Logan}
\date{October 2022}

\begin{document}

\maketitle

\section{Introduction}
% context: dynamically typed languages   
Some of Today's most popular languages such as JavaScript and Python are considered to be \textbf{dynamically typed}.
One of the hallmarks of such languages, is that they do not require specifications 
that can be verified statically. By not requiring static bounds, dynamically typed languages
enable vast combinations of terms and high reusability of code. 
Although it's not required, many programmers find that
static checks, such as \textbf{linters} and more advanced \textbf{static analysis} tools, 
enable them to find bugs, understand code, and write code more efficiently and reliably. 

In addition to writing programs, programmers can also annotate programs with specifications to
aid static verification. Writing specifications and programs can be tedious and burdensome.  
It addition to verifying correction, static tools can aid programmers by automatically synthesizes
parts of programs or specification implied by the context. Thus, the programmer can simply write
either a partial specification or partial program and allow the synthesis tool to fill in the rest.   

\begin{lstlisting}[language=Python]
def foo(x):
    if isinstance(x, int):
        return x + 1 
    elif isinstance(x, str): 
        return x + "abc"
\end{lstlisting}

% motivation: Specification 
Much of the work on synthesizing specifications from programs has been based on \textbf{ML type inference}.
In contrast to dynamically typed languages, \textbf{ML languages} require that static bounds are prescribed 
in its programs via its \textbf{datatype} mechanism. The design of ML's datatype mechanism is clever, 
such that these static bound prescriptions are only needed at the definitions of types and can be 
inferred when the data of types are used. When a piece of data is seen, an upper static bound 
may be inferred and propagated around the syntax tree to check correct composition of the program.

\begin{lstlisting}[language=ML]
datatype int_or_str = 
    Int of int | 
    Str of string

fun foo(Int x) = x + 1
  | foo(Str x) = x ^ "abc"
\end{lstlisting}

In addition, to intrinsically associating certain terms with upper bounds, many languages require
type annotations that restrict the values used in place of variables or parameters.


% motivation: subtyping 
Since dynamically typed languages do not require prescribed static bounds, 
type inference (or specification synthesis, in more general terms) must balance 
restricting the permissible combinations and reusability in programs with 
catching errors that could result in crashes at runtime.
The flexibility of combinations implies that for the same data, 
the tightest static bounds may differ depending on the context.
Thus, \textbf{subtyping} or a similarly flexible 
static notion is necessary to avoid overly restricting combinations.

% motivation: expressive types 
Mainstream type systems typically merely allow constructing simple types 
by grouping objects together based on their structures or names.
However, to have genuine confidence in the correctness of programs, specifications
need to express relations between data. There are a number of rather esoteric systems that
enable stating and proving propositions that relate objects to each other, 
including ACL2, Twelf, Coq, Lean, HOL, Isabelle, Liquid Haskell, and Synquid.  
Some of these use dependent types to encompass both simple types and propositions, 
and some rely on new syntactic categories for propositions. 

Liquid Haskell and the related Synquid both provide a way to define relations
along with subtyping, by extending ML datatypes with predicate clauses. 

\begin{lstlisting}[keywords={termination, measure, data, where}]
termination measure len :: List $\beta$ $\rightarrow$ Nat 
data List $\beta$ where
  Nil :: {v: List $\beta$ | len v = 0}
  Cons :: $\beta$ $\rightarrow$ xs: List $\beta$ $\rightarrow$ 
    {v: List $\beta$ | len v = len xs + 1}

\end{lstlisting}

However, as discussed above, the ML datatype mechanism breaks our definition of dynamically typed,
as it demands prescribing static bounds with data, so this would not work for our problem wholesale.
Other systems, like Lean or Isabelle, have similar problems with the additional issue of lacking subtyping.
Finally, all of these are rather complex, either by requiring syntactic classes of propositions predicates, 
in addition to types, or complicating the static semantics of types by allowing them 
to be dependent on programs.



% motivation: Programming 
With expressive types, using types to guide the user's programming or automatic program synthesis 
becomes a more realistic endeavor, as there may be enough information in the specification to narrow the field
and guide the generation of useful programs. Lean and Synquid\cite{} (Based on Liquid Haskell) 
are two examples of systems that decompose and propagate type specifications 
to incomplete sections or holes in programs. 
In the case of Lean, users can use this local type specification to help them construct programs and proofs,
while in Synquid this local information is leveraged to efficiently synthesize programs. 

% solution 
This paper introduces the \textbf{relational type system} to provide expressive specifications 
and synthesis capabilities for dynamically typed languages. 
The contributions of the relational type system include:
\begin{enumerate}
  \item A synthesis algorithm capable of generating local constraints for incomplete programs. 
  \item A unification algorithm capable of preserving the flexibility of dynamically typed programming. 
  \item A type level language capable of expressing (co)inductive relations without the complexity of dependent types or propositional syntax.  
\end{enumerate}

% half baked idea: by removing terms from type language,  
% terms may be enhanced with side-effects/concurrency etc,
% without complicating the type system.

% summary 

In section 2, we illustrate the problem and our solution with examples.
In section 3, we define the problem and the syntax, semantics, typing, and subtyping of our language.
In section 4, we present the synthesis and unification algorithms.
In section 5, we evaluate the problem and its solution. 
In section 6, we discuss related work of the past and possible future directions. 

\section{Overview}

This work introduces three cohesive strategies towards making
dynamically typed programs easier to write with fewer errors.  
\begin{enumerate}
  \item propagating types (downward/upward) 
  \item adjusting types (wider/narrower) 
  \item relating types (recursive/corecursive) 
\end{enumerate}
We introduce a programming language with a specification language to indicate static bounds. 
As is common these days, the static bounds are represented in a language of types.

\subsection{Propagating types}
Writing type annotations can be burdensome, so the first step 
towards making static checks feasible is to infer types from terms.

\begin{lstlisting}
cons;(hello;(),cons;(world;(),nil;())) : 

cons*(hello*unit $\times$ 
cons*(world*unit $\times$ 
nil*unit
))
\end{lstlisting}

\noindent The example above illustrates a type inferred from a term.
The part left of the colon is the term and the part right of the colon is the type.
The unit term is represented as \lstinline{()}, and it belongs to type \lstinline{unit}. 
A tagged term is constructed from a literal sequence of characters and a term separated
by a semicolon. A tagged term is constructed from a literal sequence of characters
and a type separated by a star.
So the type of \lstinline{hello;()} is \lstinline{hello*unit}.

The reason for inferring types is the check for errors statically or 
provide hints on how to complete missing parts of a program. To this end,
types propagate back up the syntax tree and down siblings' trees in order
to facilitate type checking and type hinting.
Depending on a programming languages requirements of static specification, 
whether types are propagated up or down may vary. 
In the case dynamically typed programs, no static specification or type annotations
are required, so types are propagated in both directions for every syntax rule
of the language.


\subsection{Propagating upward}
Since annotations are not required, it is important to propagate types up to check
that a term fits its context.
For example, a function abstraction is not required to be annotated 
with either an input type or an output type. 
\noindent By propagating up the input type we can check the composition of the application.
By propagating up the type of the body, we can check the result of the function application 
with its surrounding context. 

\begin{lstlisting}
let f = ($\lambda$ x $\Rightarrow$ 
  let g : nat -> str = $\hdots$
  hello ; (g x)
) 
let y : world * str = f 4
\end{lstlisting}

The type of \lstinline{f} is inferred to be \lstinline{nat $\rightarrow$ hello*str}, 
by propagating up the types inferred for its parameter and body.
The application is satisfactory since applied to the term \lstinline{4}, 
but it fails when checked against the function application's context,
which expects \lstinline{world*str}.
\begin{lstlisting}
hello*str $\leq$ world*str
\end{lstlisting}

\subsection{Propagating downward}
By propagating down and decomposing types, 
it is possible to guide the completion of programs with type hints.
To maintain the spirit of dynamic types, type annotations must remain optional.
Previous work has demonstrated the utility of downward propagating types 
in theorem proving systems, local type checking, 
and synthesis of ML-family programs.

For example, in a program that extracts 
the first element of a pair of a particular type, 
it's possible to detect an error before knowing the second element.

\begin{lstlisting}
$\lambda$ n : nat $\Rightarrow$
  let first = ($\lambda$ (x,y) : (str $\times$ str) $\Rightarrow$ x) .
  first (n, _) 
\end{lstlisting}

\noindent The  applications' argument type \lstinline{(nat $\times$ ?)} 
is propagated and decomposed such that the subtyping constraint 
\lstinline{nat $\subseteq$ str} is decided. 

\subsection{Adjusting types}

In a dynamically typed language, since types are not necessarily prescribed
for terms of particular constructions (as they are in ML datatypes), 
the optimal type for a term will depend on how terms and parameters are used in context. 
When inferring a type that may be associated with various terms throughout a program,  
The optimal type may depend on widening a type as new use cases are discovered,
or narrowing a type as new restrictions are discovered. 

\subsection{Adjusting wider}

In parametric types where a generic input type must be the same as a generic output type,
The dynamic nature of terms is seemingly at odds with inferring types.

In the case of a function with generic types, 
the types can be specialized based on the terms that are witnessed as inputs. 

Since there's no particular upper bound type associated with 
a term other than top ($\top$), 
The parameter type must accommodate types of unforeseen arguments, 
while the return type should be widened with each successive
argument's type.
widening is achieved with the introduction of the union type operator ($\vee$).

\begin{lstlisting}
($\lambda$ pair : $\forall$ $\alpha$ . $\alpha$ $\rightarrow$ $\alpha$ $\rightarrow$ ($\alpha$ $\times$ $\alpha$) $\Rightarrow$ 
($\lambda$ n : int $\Rightarrow$ ($\lambda$ s : str $\Rightarrow$ 
  pair n s
)))
\end{lstlisting}

Let \lstinline{?} stand for a fresh type variable.
Once \lstinline{pair} is applied to an integer its generic type is specialized to 
\lstinline{(int $\vee$ ?)}, 
in which union with the dynamic type behaves like the top type $\top$, 
accommodating receiving a string as a the subsequent input.
Thus, the generic type is specialized to 
\newline
\lstinline{(int $\vee$ str $\vee$ ?)}.
The type variable always passes type checking, 
thus behaving like bottom for term types
and behaving like top for parameter types.
As such, the parameters' union types behave like top,
and the type variable simply falls away in the union of the result type. 
The result type for \lstinline{(pair n s)} ends up as 
\newline
\lstinline{(int $\vee$ string) $\times$ (int $\vee$ string)}. 

\subsection{Adjusting narrower}

In functions where a parameter has an unknown type and that parameter is 
internally used as an argument to an application, the dynamically typed 
nature of terms adds some complications to type inference.

The argument type must be amenable to parameter types 
of unforeseen compositions,
while the external parameter type should be narrowed 
to the smallest type necessary for internal compositions to
succeed.

\begin{lstlisting}
($\lambda$ i2n : int $\rightarrow$ nat $\Rightarrow$ 
($\lambda$ s2n : str $\rightarrow$ nat $\Rightarrow$ 
  $\lambda$ x $\Rightarrow$ (i2n x, s2n x)
))

\end{lstlisting}

Once \lstinline{i2n} is applied to \lstinline{x}, 
the type for \lstinline{x} is specialized to \lstinline{(int $\wedge$ ?)}, 
in which intersection with the dynamic type behaves like the bottom type $\bot$,
availing itself to be used in subsequent applications. 
Thus, the dynamic type is inferred to be \lstinline{(int $\wedge$ str $\wedge$ ?)}.

The type variable always passes type checking, 
thus behaving like bottom for term types
and behaving like top for parameter types.
As such, the intersections of argument types behave like bottom,
and the type variable simply falls away in the intersection type of a parameter.
The external parameter type for ends up as \lstinline{(int $\wedge$ str)}. 


\subsection{Relating types}
In order to thoroughly catch errors and guide programming, 
the specification language must be able to relations
between values. Rather than adding a second syntactic layer 
of predicates and propositions to our specification language,
we build on the notions of type variables, union, and 
intersection operators already present in the system, 
yielding a novel system of relational types.

The key insight is to allow (co)recursion to occur through subtyping
constraints specified in quantified types. 
That is, least (or greatest) fixed points are allowed to occur
in the subtyping constraints of quantified types.


\subsection{Relating recursively}

\hfill \\
For example, types can also specify a pair of a list and its length.

\begin{lstlisting}[]
let measurement : $\mu$ (nat $\times$ list) .
  zero*unit $\times$ nil*unit $\vee$
  succ*nat $\times$ cons*(? $\times$ list)
\end{lstlisting} 

\hfill

\noindent This is syntactic sugar for:

\begin{lstlisting}[]
let measurement : 
$\exists$ $\alpha$ . $\mu$ nat_and_list .
  zero*unit $\times$ nil*unit $\vee$ 
  $\exists$ nat list :: 
    (nat $\times$ list) $\leq$ nat_and_list .
    succ*nat $\times$ cons*($\alpha$ $\times$ list)
\end{lstlisting}

\subsection{Relating corecursively}

\noindent Correspondingly, the types are expressive enough to precisely specify
a function that takes a natural number \lstinline{n} 
and an element, and returns a list of \lstinline{n} elements.

\begin{lstlisting}[]
let replicate : 
$\forall$ $\alpha$ . $\alpha$ $\rightarrow$ $\nu$ (nat $\rightarrow$ list) .
  zero*unit $\rightarrow$ nil*unit $\wedge$
  succ*nat $\rightarrow$ cons*($\alpha$ $\times$ list)
\end{lstlisting}



\hfill

\noindent This is syntactic sugar for:

\begin{lstlisting}[]
let replicate : 
$\forall$ $\alpha$ . $\alpha$ $\rightarrow$ $\nu$ nat_to_list .
  zero*unit $\rightarrow$ nil*unit $\wedge$
  $\forall$ nat list :: 
    nat_to_list $\leq$ (nat $\rightarrow$ list) .
    succ*nat $\rightarrow$ cons*($\alpha$ $\times$ list)
\end{lstlisting}

\hfill

\noindent The type of \lstinline{replicate} is co-recursive rather than recursive. 
When expanded to the type with a universal type and constraint, 
the universally typed variables appear on the right hand side 
of the subtyping constraint, while the co-recursive variable
appears on the left hand side. This is consistent with the notion
that a intersection of types is a subtype of any one of its parts.

\hfill

\noindent Semantically, the type of \lstinline{replicate} is similar to the definition of 
\lstinline{replicate} in Synquid \cite{}    

\begin{lstlisting}[keywords={termination, measure, data, where}]
replicate :: n:Nat $\rightarrow$ x:$\alpha$ $\rightarrow$ 
  {v: List $\alpha$ | len v = n}

\end{lstlisting}

\hfill

\noindent The term for \lstinline{replicate} could be represented by a recursive function built using \lstinline{fix} 

\begin{lstlisting}[]
let replicate = 
$\lambda$ x $\Rightarrow$ fix ($\lambda$ self $\Rightarrow$ $\lambda$ [
  (zero;() $\Rightarrow$ nil;()),
  (succ;n $\Rightarrow$ cons;(x, self n))
]) 
\end{lstlisting}


\section{Language specification}
\begin{enumerate}
  \item english statement 
\end{enumerate}
\subsection{Syntax}


\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
      t 
      &{} ::=
      \begin{array}[t]{@{} l}
        \_ 
        \ |\ 
        () 
        \ |\ 
        x
        \ |\ 
        l;t 
        \ |\ 
        \omega\ \widebar{l \approx t}
        \ |\ 
        \lambda\ \widebar{p : \tau \Rightarrow t} 
        \ |\ 
        t/l
        \ |\ 
        t\ t
        \ |\ 
        \text{let } x : \tau = t\ \text{in } t
        \ |\ 
        \text{fix } t
      \end{array}
      \\
      p 
      &{} ::=
      \begin{array}[t]{@{} l}
        x 
        \ |\ 
        () 
        \ |\ 
        l;p
        \ |\ 
        \omega\ \widebar{l \approx p}
      \end{array}
      \\
      \tau
      &{} ::=
      \begin{array}[t]{@{} l}
        \text{unit} 
        \ |\ 
        \alpha 
        \ |\ 
        \bot 
        \ |\ 
        \top 
        \ |\ 
        l*\tau 
        \ |\ 
        l\sim\tau 
        \ |\ 
        \tau\rightarrow\tau 
        \ |\ 
        \exists \widebar{\alpha} :: \tau \leq \tau \ .\ \tau 
        \ |\ 
        \forall \widebar{\alpha} :: \tau \leq \tau \ .\ \tau 
        \ |\ 
        \mu \alpha.\tau 
        \ |\ 
        \nu \alpha.\tau 
        \ |\ 
        \tau \vee \tau
        \ |\ 
        \tau \wedge \tau
      \end{array}
      \\
      E 
      &{} ::=
      []
      \ |\ 
      l;E 
      \ |\ 
      \omega\ \widebar{l \approx E}
      \ |\ 
      E/l
      \ |\ 
      E\ t
      \ |\ 
      v\ E
      \ |\ 
      \text{let } x : \tau = E\ \text{in } t
      \ |\ 
      \text{fix } E 
      \\
      v 
      &{} ::=
      \begin{array}[t]{@{} l}
        () 
        \ |\ 
        l;v
        \ |\ 
        \omega\ \widebar{l \approx v}
        \ |\ 
        \lambda\ \widebar{p : \tau \Rightarrow t} 
      \end{array}
    \end{array}
  \]
  \caption{Syntax}
\end{figure*}






\begin{enumerate}
  \item rules 
\end{enumerate}

\subsection{Operational semantics}
\begin{figure*}[h]
  \begin{mathpar}

    \inferrule[PopPush] { 
      t \longrightarrow t' 
    } {
      E[t] \longrightarrow E[t']  
    }

    \inferrule[Proj] {
    } {
      (\omega\ \widebar{l_i \approx v_i})/l_j \longrightarrow v_j
    } 

    \inferrule[App] { 
    } {
      (\lambda\ \widebar{p : \tau \Rightarrow t})\ v 
      \longrightarrow 
      (\text{match } v\ \widebar{p : \tau \Rightarrow t})
    } 

    \inferrule[Let] { 
    } {
      \text{let}\ x : \tau = v \text{ in } t
      \longrightarrow 
      t[x \mapsto v]
    } 

    \inferrule[Fix] { 
    } {
      \text{fix}\ \lambda [x:\tau \Rightarrow t]
      \longrightarrow 
      t[x \mapsto \text{fix}\ \lambda [x:\tau \Rightarrow t]]
    } 

  \end{mathpar}
  \caption{Operational semantics}
\end{figure*}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
      \text{match}\ v\ ((p : \tau \Rightarrow t) :: cs)
      &{} =
      \begin{cases}
        t[H]
        &\text{if }
        \text{unify}\ v\ p = H 
        \\
        
        \text{match}\ v\ cs
        &\text{otherwise}
      \end{cases}
    \end{array}
  \]
  \[
    \begin{array}{l @{} l}
      \text{unify}\ v\ x 
      &{} =
      \cdot, x \mapsto v
      \\
      \text{unify}\ ()\ () 
      &{} =
      \cdot
      \\
      \text{unify}\ l;v\ l;p 
      &{} =
      \text{unify}\ v\ p
      \\
      \text{unify}\ (\omega\ \widebar{l \approx v})\ (\omega\ \widebar{l \approx p}) 
      &{} =
      \text{reduce } ; \widebar{\text{unify}\ v\ p}
    \end{array}
  \]
  \caption{Pattern matching}
\end{figure*}


\subsection{Typing}

\begin{figure*}[h]
  \begin{mathpar}
    \inferrule[Hole] { 
    } {
      \Gamma \vdash \_ : \tau
    } 

    \inferrule[Unit] { 
    } {
      \Gamma \vdash () : \text{unit} 
    } 

    \inferrule[Var] { 
      (x \mapsto \tau) \in \Gamma
    } {
      \Gamma \vdash x : \tau  
    } 

    \\\\

    \inferrule[Tag] { 
      \Gamma \vdash t : \tau
    } {
      \Gamma \vdash l;t : l*\tau  
    }

    \inferrule[Record] { 
      \bigwedge_{i} 
      \Gamma \vdash t_i : \tau_i
    } {
      \Gamma \vdash \omega\ (\widebar{l_i \approx t_i}) : (\text{reduce} \wedge \widebar{l_i\sim\tau_i})  
    } 

    \inferrule[Function] {
      \bigwedge_{i} 
      \Gamma_1 \vdash p_i : \tau_i
      \ \wedge\
      \Gamma;\Gamma_1 \vdash t_i : \tau'_i
    } {
      \Gamma \vdash \lambda\ (\widebar{p_i : \tau_i\Rightarrow t_i}) 
      : (\text{reduce} \wedge \widebar{\tau_i \rightarrow \tau'_i })  
    } 

    \\\\

    \inferrule[Proj] {
      \Gamma \vdash t : l\sim\tau 
    } {
      \Gamma \vdash t/l : \tau 
    } 

    \inferrule[App] { 
      \Gamma \vdash t_1 : \tau_1 \rightarrow \tau
      \\
      \Gamma \vdash t_2 : \tau_1
    } {
      \Gamma \vdash (t_1\ t_2) : \tau 
    } 

    \\\\

    \inferrule[Let] { 
      \Gamma \vdash t_1 : \tau_1  
      \\
      \cdot \vdash 
      \tau_1
      \leq 
      (\exists \widebar{\alpha} :: \tau_3 \leq \tau_4 \ .\ \tau_5)
      \\\\
      \Gamma,x \mapsto (\forall \widebar{\alpha} :: \tau_3 \leq \tau_4 \ .\ \tau_5) 
        \vdash t_2 : \tau_2
    } {
      \Gamma \vdash 
        (\text{let}\ x : \tau_1 = t_1 \text{ in } t_2) 
        : \tau_2
    } 

    \inferrule[Fix] { 
      \Gamma \vdash t : \tau \rightarrow \tau 
    } {
      \Gamma \vdash \text{fix}\ t : \tau 
    } 

    \inferrule[Subsump] { 
      \Gamma \vdash t : \tau'
      \\
      \cdot \vdash \tau' \leq \tau
      \
    } {
      \Gamma \vdash 
        t : \tau
    } 
  \end{mathpar}
  \caption{Typing}
\end{figure*}


\subsection{Subtyping}

\begin{figure*}[h]
  \begin{mathpar}
    \inferrule[refl] {
    } {
       \Delta \vdash \tau \leq \tau
    }

    \inferrule[bottom] {
    } {
      \Delta \vdash \bot \leq \tau
    }

    \inferrule[top] {
    } {
      \Delta \vdash \tau \leq \top
    } 
    \\\\

    \inferrule[tag] {
      \Delta \vdash \tau_1 \leq \tau_2
    } {
      \Delta \vdash 
        l*\tau_1 \leq l*\tau_2
    } 

    \inferrule[field] {
      \Delta \vdash 
        \tau_1 \leq \tau_2
    } {
      \Delta \vdash 
        l\sim\tau_1 \leq l\sim\tau_2
    } 

    \inferrule[case] {
      \Delta \vdash \tau_3 \leq \tau_1 
      \\
      \Delta \vdash 
        \tau_2 \leq \tau_4
    } {
      \Delta \vdash 
        \tau_1 \rightarrow \tau_2 \leq \tau_3 \rightarrow \tau_4
    } 

    \\\\

    \inferrule[exis-lhs] { 
      \Delta;\Delta_1 \vdash \tau_1 \leq \tau_2
      \\
      \forall \Delta_1'\ .\ \Delta_1' < \Delta_1 \longrightarrow \Delta;\Delta_1' \not\vdash \tau_1 \leq \tau_2
      \\
      \Delta;\Delta_1 \vdash \tau_3 \leq \tau_4
      \\\\
      \Delta;\Delta_2 \vdash \tau_1 \leq \tau_2
      \\
      \forall \Delta_2'\ .\ \Delta_2 < \Delta_2' \longrightarrow \Delta;\Delta_2' \not\vdash \tau_1 \leq \tau_2
      \\
      \Delta;\Delta_2 \vdash \tau_3 \leq \tau_4
      \\\\
      \text{freevars } \Delta \cap \widebar{\alpha_i} = \emptyset 
      \\
      \text{dom}(\Delta_1) \subseteq \widebar{\alpha_i}
      \\
      \text{dom}(\Delta_2) \subseteq \widebar{\alpha_i}
    } { 
      \Delta \vdash 
        (\exists \widebar{\alpha_i} :: \tau_1 \leq \tau_2\ .\ \tau_3)
        \leq 
        \tau_4
    }

    \inferrule[exis-rhs] { 
      \Delta;\Delta_1 \vdash \tau_1 \leq \tau_4
      \\
      \text{freevars } \Delta \cap \widebar{\alpha} = \emptyset 
      \\\\
      \Delta;\Delta_1 \vdash 
        \tau_2 \leq \tau_3
    } { 
      \Delta \vdash 
        \tau_1
        \leq 
        (\exists \widebar{\alpha} :: \tau_2 \leq \tau_3\ .\ \tau_4)
    }
    
    \\\\

    \inferrule[univ-rhs] { 
      \Delta;\Delta_1 \vdash \tau_2 \leq \tau_3
      \\
      \forall \Delta_1'\ .\ \Delta_1' < \Delta_1 \longrightarrow \Delta;\Delta_1' \not\vdash \tau_2 \leq \tau_3
      \\
      \Delta;\Delta_1 \vdash \tau_1 \leq \tau_4
      \\\\
      \Delta;\Delta_2 \vdash \tau_2 \leq \tau_3
      \\
      \forall \Delta_2'\ .\ \Delta_2 < \Delta_2' \longrightarrow \Delta;\Delta_2' \not\vdash \tau_2 \leq \tau_3
      \\
      \Delta;\Delta_2 \vdash \tau_1 \leq \tau_4
      \\\\
      \text{freevars } \Delta \cap \widebar{\alpha_i} = \emptyset 
      \\
      \text{dom}(\Delta_1) \subseteq \widebar{\alpha_i}
      \\
      \text{dom}(\Delta_2) \subseteq \widebar{\alpha_i}
    } { 
      \Delta \vdash 
        \tau_1
        \leq 
        (\forall \widebar{\alpha_i} :: \tau_2 \leq \tau_3\ .\ \tau_4)
    }

    \inferrule[univ-lhs] { 
      \Delta;\Delta_1 \vdash \tau_3 \leq \tau_4
      \\
      \text{freevars } \Delta \cap \widebar{\alpha} = \emptyset 
      \\\\
      \Delta;\Delta_1 \vdash 
        \tau_1 \leq \tau_2
    } { 
      \Delta \vdash 
        (\forall \widebar{\alpha} :: \tau_1 \leq \tau_2\ .\ \tau_3)
        \leq 
        \tau_4
    }

    \\\\

    \inferrule[recur-symm] { 
      \Delta \vdash \tau_1[\alpha_1\mapsto\mu\alpha_2.\tau_2] \leq \tau_2[\alpha_2\mapsto\mu\alpha_2.\tau_2]
    } {
      \Delta \vdash \mu \alpha_1 . \tau_1 \leq \mu \alpha_2 . \tau_2
    }

    \inferrule[recur-roll] {
    } {
       \Delta \vdash \tau[\alpha\mapsto\mu \alpha . \tau] \leq\mu \alpha . \tau
    }

    \inferrule[recur-unroll] {
    } {
       \Delta \vdash \mu\alpha.\tau \leq \tau[\alpha\mapsto\mu \alpha . \tau]
    }

    \inferrule[corec-symm] { 
      \Delta \vdash \tau_1[\alpha_1\mapsto\nu\alpha_1.\tau_1] \leq \tau_2[\alpha_2\mapsto\nu\alpha_1.\tau_1]
    } {
      \Delta \vdash \nu \alpha_1 . \tau_1 \leq \nu \alpha_2 . \tau_2
    }

    \inferrule[corec-roll] {
    } {
       \Delta \vdash \tau[\alpha\mapsto\nu \alpha . \tau] \leq\nu \alpha . \tau
    }

    \inferrule[corec-unroll] {
    } {
       \Delta \vdash \nu\alpha.\tau \leq \tau[\alpha\mapsto\nu \alpha . \tau]
    }


    \inferrule[union-left] {
      \Delta \vdash \tau_1 \leq \tau_3
      \\
      \Delta \vdash \tau_2 \leq \tau_3
    } {
      \Delta \vdash \tau_1 \vee \tau_2 \leq \tau_3
    }

    \inferrule[union-rght-left] {
    } {
      \Delta \vdash \tau_1 \leq \tau_1 \vee \tau_2
    }

    \inferrule[union-rght-rght] {
    } {
      \Delta \vdash \tau_2 \leq \tau_1 \vee \tau_2
    }

    \\\\

    \inferrule[inter-right] {
      \Delta \vdash \tau \leq \tau_1
      \\
      \Delta \vdash \tau \leq \tau_2
    } {
      \Delta \vdash \tau \leq \tau_1 \wedge \tau_2
    }

    \inferrule[inter-left-left] {
    } {
      \Delta \vdash \tau_1 \wedge \tau_2 \leq \tau_1
    }

    \inferrule[inter-left-rght] {
    } {
      \Delta \vdash \tau_1 \wedge \tau_2 \leq \tau_2
    }
  \end{mathpar}
  \caption{Subtyping}
\end{figure*}

\begin{enumerate}
  \item typing and subtyping rules 
  \item soundness proof 
\end{enumerate}

\section{Language algorithms}
\begin{enumerate}
  \item english statement 
\end{enumerate}
\subsection{Program synthesis}
\subsection{Type inference}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      \_ : \tau
      &{} =
      \{\cdot.\tau\}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      () : \tau
      &{} =
      \begin{array}[t]{@{} l}
        \{\Delta_1.\text{unit}\ |
        \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \text{unit} \leq \tau
        \}
      \end{array}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      x : \tau
      &{} =
      \begin{cases}  
        \{\Delta_1.\tau_1\ |
        \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau
        \}
        &\text{if } \Gamma(x) = \tau_1
        \\
        \emptyset
        &\text{otherwise}
      \end{cases}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      l ; t : \tau
      &{} =
      \begin{array}[t]{@{} l}
        \text{let } \alpha = \text{typevar}() 
        \\
        \{\Delta_1;\Delta_2\ .\ l ; \tau_1 \ |
        \\
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash l ; \alpha \leq \tau
        \\
        \ \ \ \ (\Delta_2.\tau_1) \in \text{infer } \iota\ \Delta;\Delta_1\ \Gamma \vdash t : \alpha
        \\
        \}
      \end{array}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      \omega\ \widebar{l_i \approx t_i} : \tau
      &{} =
      \begin{array}[t]{@{} l}
        \text{let } \widebar{\alpha_i} = \widebar{\text{typevar}()}
        \\
        \text{let } \tau' = \text{reduce} \wedge \widebar{l_i \sim \alpha_i}
        \\
        \text{reduce} * \{
        \text{infer } \iota\ \Delta;\Delta_1\ \Gamma \vdash t_i : \alpha_i\ |\ 
        \\
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta\ \vdash \tau' \leq \tau
        \\
        \}
        \\
      \end{array}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      \lambda\ \widebar{p_i : \tau_i \Rightarrow t_i} : \tau
      &{} =
      \begin{array}[t]{@{} l}
        \text{let } \widebar{\alpha_i} = \widebar{\text{typevar}()}
        \\
        \text{let } \tau' = \text{reduce} \wedge 
        \widebar{\tau_i \rightarrow \alpha_i }
        \\
        \text{reduce} * \{
        \text{infer } \iota\ \Delta;\Delta_1;\Delta_2\ \Gamma;\Gamma_1 \vdash t_i : \alpha_i\ |\ 
        \\
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta\ \vdash \tau' \leq \tau
        \\
        \ \ \ \ \Gamma_1 \in \{\text{patenv } p_i\}
        \\
        \ \ \ \ \Delta_2.\tau' \in \text{infer } \blacksquare\ \Delta;\Delta_1\ \Gamma;\Gamma_1\ \vdash p_i : \tau_i
        \\
        \}
        \\
      \end{array}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      t/l : \tau
      &{} =
      \begin{array}[t]{@{} l}
        \text{let } \alpha = \text{typevar}()
        \\
        \{ \Delta_1;\Delta_2\ .\ \alpha \ |\
        \\
        \ \ \ \ \Delta_1.\tau_1 \in \text{infer } \iota\ \Delta\ \Gamma \vdash t : l \sim \tau 
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_1 \leq l \sim \alpha
        \\
        \}
      \end{array}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      (t_1\ t_2) : \tau
      &{} =
      \begin{array}[t]{@{} l}
        \text{let } \alpha_1 = \text{typevar}()
        \\
        \text{let } \alpha_2 = \text{typevar}()
        \\
        \{ \Delta_1;\Delta_2;\Delta_3\ .\ \alpha_1 \ |\
        \\
        \ \ \ \ \Delta_1.\tau_1 \in \text{infer } \iota\ \Delta\ \Gamma \vdash t_1 : (\alpha_2 \rightarrow \tau) 
        \\
        \ \ \ \ \Delta_2.\tau_2 \in \text{infer } \iota\ \Delta;\Delta_1\ \Gamma \vdash t_2 : \alpha_2
        \\
        \ \ \ \ \Delta_3 \in \text{unify } \iota\ \Delta;\Delta_1;\Delta_2 \vdash 
        \tau_1 \leq (\tau_2 \rightarrow \alpha_1)
        \\
        \}
      \end{array}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      (\text{let}\ x : \tau_1 = t_1 \text{ in } t_2) : \tau_2
      &{} =
      \begin{array}[t]{@{} l}
        \{ \Delta_2\ .\ \tau_2' \ |\ 
        \\
        \ \ \ \ \Delta_1.\tau_1' \in \text{infer } \iota\ \Delta;\Delta_1\ \Gamma \vdash t_1 : \tau_1
        \\ 
        \ \ \ \ \tau_1'' \in \{\tau_1'[\Delta_1]\}
        \\ 
        \ \ \ \ \widebar{\alpha} \in \{\text{freevars}\ \tau_1''\}
        \\ 
        \ \ \ \ \Delta_2.\tau_2' \in \Delta\ \Gamma,x \mapsto \forall \widebar{\alpha} . \tau_1''
          \vdash t_2 : \tau_2 
        \\
        \} 
      \end{array}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      \text{fix } t : \tau      
      &{} =
      \begin{array}[t]{@{} l}
        \text{let } \alpha_1 = \text{typevar}()
        \\
        \text{let } \alpha_2 = \text{typevar}()
        \\
        \{ \Delta_1;\Delta_2\ .\ \nu\ \alpha_4 \ . \forall\ \widebar{\alpha} ::
          \alpha_4 \leq \tau_2\ .\ \tau_3
          \ |\ 
        \\
        \ \ \ \ \Delta_1.\tau_1 \in
        \text{infer } \blacksquare\ \Delta\ \Gamma \vdash t : \tau \rightarrow \tau
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \blacksquare\ \Delta;\Delta_1 \vdash 
        \tau_1 \leq \alpha_1 \rightarrow \alpha_2 
        \\
        \ \ \ \ \tau_2 \in \{\alpha_1[\Delta;\Delta_1;\Delta_2]\}
        \\ 
        \ \ \ \ \tau_3 \in \{\alpha_2[\Delta;\Delta_1;\Delta_2]\} 
        \\
        \ \ \ \ \widebar{\alpha} \in \{ \text{freevars}\ \tau_2 \}
        \\
        \} 
      \end{array}
    \end{array}
  \]
  \caption{Type inference}
\end{figure*}


\begin{enumerate}
  \item definition 
  \item lemmas and proofs 
\end{enumerate}

\subsection{Subtype unification}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}

      \text{unify } \blacksquare\ \Delta \vdash \alpha \leq \tau	
      &{} =
      \begin{cases}  
        \{ \cdot,\alpha \mapsto \nu\alpha.\tau \}
        & \text{if } 
        \alpha \not\in \text{dom}(\Delta) \ \wedge\
        \alpha \in \text{freevars}(\tau[\Delta])
        \\
        \{ \cdot,\alpha \mapsto \tau \}
        & \text{if } 
        \alpha \not\in \text{dom}(\Delta) \ \wedge\
        \alpha \notin \text{freevars}(\tau[\Delta])
        \\
        \text{unify } \blacksquare\ \Delta \vdash \tau_1 \leq \tau
        &\text{if }
        \Delta(\alpha) = \tau_1
      \end{cases}
      \\

      \text{unify } \square\ \Delta \vdash \alpha \leq \tau	
      &{} =
      \begin{cases}  
        \{ \cdot,\alpha \mapsto (\nu\alpha.\tau \wedge \beta) \}
        & \text{if } 
        \alpha \not\in \text{dom}(\Delta) \ \wedge\
        \alpha \in \text{freevars}(\tau[\Delta]) \ \wedge\ 
        \text{fresh } \beta
        \\
        \{ \cdot,\alpha \mapsto \tau \wedge \beta \}
        & \text{if } 
        \alpha \not\in \text{dom}(\Delta) \ \wedge\
        \alpha \notin \text{freevars}(\tau[\Delta]) \ \wedge\ 
        \text{fresh } \beta
        \\
        \text{unify } \square\ \Delta \vdash \tau_1 \leq \tau
        &\text{if }
        \Delta(\alpha) = \tau
      \end{cases}
      \\
      \text{unify } \blacksquare\ \Delta \vdash \tau \leq \alpha 	
      &{} =
      \begin{cases}  
        \{ \cdot,\alpha \mapsto \mu\alpha.\tau \}
        & \text{if } 
        \alpha \not\in \text{dom}(\Delta) \ \wedge\
        \alpha \in \text{freevars}(\tau[\Delta])
        \\
        \{ \cdot,\alpha \mapsto \tau \}
        & \text{if } 
        \alpha \not\in \text{dom}(\Delta) \ \wedge\
        \alpha \notin \text{freevars}(\tau[\Delta])
        \\
        \text{unify } \blacksquare\ \Delta \vdash \tau \leq \tau_1
        &\text{if }
        \Delta(\alpha) = \tau_1
      \end{cases}
      \\
      \text{unify } \square\ \Delta \vdash \tau \leq \alpha	
      &{} =
      \begin{cases}  
        \{ \cdot,\alpha \mapsto (\mu\alpha.\tau \vee \beta) \}
        & \text{if } 
        \alpha \not\in \text{dom}(\Delta) \ \wedge\
        \alpha \in \text{freevars}(\tau[\Delta]) \ \wedge\ 
        \text{fresh } \beta
        \\
        \{ \cdot,\alpha \mapsto \tau \vee \beta \}
        & \text{if } 
        \alpha \not\in \text{dom}(\Delta) \ \wedge\
        \alpha \notin \text{freevars}(\tau[\Delta]) \ \wedge\ 
        \text{fresh } \beta
        \\
        \text{unify } \square\ \Delta \vdash \tau \leq \tau_1
        &\text{if }
        \Delta(\alpha) = \tau
      \end{cases}
      \\
      \text{unify } \iota\ \Delta \vdash
      (\exists \widebar{\alpha_i} :: \tau_1 \leq \tau_2\ .\ \tau_3)
      \leq 
      \tau_4
      &{} = 
      \begin{array}[t]{@{} l}
        \text{let } \tau_1, \tau_2, \tau_3 = 
        \text{refresh } \widebar{\alpha_i}\ \tau_1,\ 
        \text{refresh } \widebar{\alpha_i}\ \tau_2,\ 
        \text{refresh } \widebar{\alpha_i}\ \tau_3
        \\
        \text{let } \Delta_1 = \text{reduce}\ , \widebar{\alpha_i \mapsto \top}
        \\
        \{\Delta_1;\Delta_2;\Delta_3\ |
        \\ 
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_2
        \\
        \ \ \ \ \Delta_3 \in \text{unify } \iota\ \Delta;\Delta_1;\Delta_2 \vdash \tau_3 \leq \tau_4
        \\
        \}
      \end{array}
      \\
      \text{unify } \iota\ \Delta \vdash
      \tau_1
      \leq 
      (\exists \widebar{\alpha} :: \tau_2 \leq \tau_3\ .\ \tau_4)
      &{} = 
      \begin{array}[t]{@{} l}
        \text{let } \tau_2, \tau_3, \tau_4 = 
        \text{refresh } \widebar{\alpha}\ \tau_2,\ 
        \text{refresh } \widebar{\alpha}\ \tau_3,\ 
        \text{refresh } \widebar{\alpha}\ \tau_4
        \\
        \{\Delta_1;\Delta_2\ |
        \\ 
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_4
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_2 \leq \tau_3
        \\
        \}
      \end{array}
      \\
      \text{unify } \iota\ \Delta \vdash
      \tau_1
      \leq 
      (\forall \widebar{\alpha_i} :: \tau_2 \leq \tau_3\ .\ \tau_4)
      &{} = 
      \begin{array}[t]{@{} l}
        \text{let } \tau_2, \tau_3, \tau_4 = 
        \text{refresh } \widebar{\alpha_i}\ \tau_2,\ 
        \text{refresh } \widebar{\alpha_i}\ \tau_3,\ 
        \text{refresh } \widebar{\alpha_i}\ \tau_4
        \\
        \text{let } \Delta_1 = \text{reduce}\ , \widebar{\alpha_i \mapsto \bot}
        \\
        \{\Delta_1;\Delta_2;\Delta_3\ |
        \\ 
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta \vdash \tau_2 \leq \tau_3
        \\
        \ \ \ \ \Delta_3 \in \text{unify } \iota\ \Delta;\Delta_1;\Delta_2 \vdash \tau_1 \leq \tau_4
        \\ 
        \}
      \end{array}
      \\
      \text{unify } \iota\ \Delta \vdash
      (\forall \widebar{\alpha} :: \tau_1 \leq \tau_2\ .\ \tau_3)
      \leq 
      \tau_4
      &{} = 
      \begin{array}[t]{@{} l}
        \text{let } \tau_1, \tau_2, \tau_3 = 
        \text{refresh } \widebar{\alpha}\ \tau_1,\ 
        \text{refresh } \widebar{\alpha}\ \tau_2,\ 
        \text{refresh } \widebar{\alpha}\ \tau_3
        \\
        \{\Delta_1;\Delta_2\ |
        \\ 
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_3 \leq \tau_4
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_1 \leq \tau_2
        \\
        \}
      \end{array}

    \end{array}
  \]
  \caption{Subtype unification: part 1}
\end{figure*}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
      \text{unify } \iota\ \Delta \vdash \bot \leq \_	
      &{} = 
      \{\cdot\}
      \\
      \text{unify } \iota\ \Delta \vdash \_ \leq \top	
      &{} = 
      \{\cdot\}
      \\
      \text{unify } \iota\ \Delta \vdash \text{unit}  \leq \text{unit}	
      &{} = 
      \{\cdot\}
      \\
      \text{unify } \iota\ \Delta \vdash l*\tau_1 \leq l*\tau_2	
      &{} = 
      \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_2
      \\
      \text{unify } \iota\ \Delta \vdash l\sim\tau_1 \leq l\sim\tau_2	
      &{} = 
      \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_2
      \\
      \text{unify } \iota\ \Delta \vdash \tau_1\rightarrow\tau_2 \leq \tau_3\rightarrow\tau_4	
      &{} = 
      \begin{array}[t]{@{} l}
        \{\Delta_1;\Delta_2\ |
        \\ 
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_3 \leq \tau_1
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_4 \leq \tau_2
        \\
        \}
      \end{array}
      \\
      \text{unify } \iota\ \Delta \vdash
      \mu \alpha . \tau_1 \leq \mu \alpha . \tau_2
      &{} = 
      \Delta \vdash 
      \tau_1[\alpha_1\mapsto\mu\alpha_2.\tau_2] \leq 
      \tau_2[\alpha_2\mapsto\mu\alpha_2.\tau_2]

      \\
      \text{unify } \iota\ \Delta \vdash
      \tau_1 \leq \mu \alpha . \tau_2
      &{} = 
      \begin{cases}  
        \text{unify } \iota\ \Delta \vdash 
        \tau_1 \leq \tau_2[\alpha\mapsto\mu\alpha.\tau_2]	
        &\text{if }
        \text{unrollform } \Delta \vdash \tau_1
        \\
        \emptyset
        &\text{otherwise}
      \end{cases}

      \\
      \text{unify } \iota\ \Delta \vdash
      \nu \alpha_1 . \tau_1 \leq 
      \nu \alpha_2 . \tau_2	
      &{} = 
      \text{unify } \iota\ \Delta \vdash 
      \tau_1[\alpha_1\mapsto\nu\alpha_1.\tau_1] \leq 
      \tau_2[\alpha_2\mapsto\nu\alpha_1.\tau_1]

      \\
      \text{unify } \iota\ \Delta \vdash
      \nu \alpha . \tau_1 \leq 
      \tau_2 \rightarrow \tau_3
      &{} = 
      \begin{cases}
        \text{unify } \iota\ \Delta \vdash
        \tau_1[\alpha\mapsto\nu\alpha.\tau_1]
        \leq 
        \tau_2 \rightarrow \tau_3
        &\text{if }
        \text{unrollform } \Delta \vdash \tau_2
        \\
        \text{unify } \iota\ \Delta \vdash
        \tau_1[\alpha\mapsto\nu\alpha.\tau_1]
        \leq 
        \tau_2 \rightarrow \tau_3
        &\text{if }
        \text{unrollform } \Delta \vdash \tau_3
        \\
        \text{unify } \iota\ \Delta \vdash
        (\text{rw\_func\_type}\ \nu\alpha.\tau_1)
        \leq 
        \tau_2 \rightarrow \tau_3
        &\text{otherwise }
      \end{cases}

      \\
      \text{unify } \iota\ \Delta \vdash
      \tau_1 \vee \tau_2 \leq \tau_3
      &{} = 
      \begin{array}[t]{@{} l}
        \{\Delta_1;\Delta_2\ |
        \\ 
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_3
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_2 \leq \tau_3
        \\
        \}
      \end{array}

      \\
      \text{unify } \iota\ \Delta \vdash
      \tau_1 \leq \tau_2 \vee \tau_3
      &{} = 
      (\text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_2)
      \cup
      (\text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_3)

      \\
      \text{unify } \iota\ \Delta \vdash
      \tau_1 \leq \tau_2 \wedge \tau_3
      &{} = 
      \begin{array}[t]{@{} l}
        \{\Delta_1;\Delta_2\ |
        \\ 
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_2
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_1 \leq \tau_3
        \\
        \}
      \end{array}

      \\
      \text{unify } \iota\ \Delta \vdash
      \tau_1 \wedge \tau_2 \leq \tau_3
      &{} = 
      (\text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_3)
      \cup
      (\text{unify } \iota\ \Delta \vdash \tau_2 \leq \tau_3)

    \end{array}
  \]
  \caption{Subtype unification: part 2}
\end{figure*}

\begin{enumerate}
  \item definition 
  \item lemmas and proofs 
\end{enumerate}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
    \Delta\ ;\ \cdot
    &\ = \Delta 
    \\
    \Delta_1;(\Delta_2,\alpha \mapsto \tau) 
    &\ = (\Delta_1;\Delta_2),\alpha \mapsto \tau
    \end{array}
  \]

  \caption{Appending of environments}
\end{figure*}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
    M_1 * M_2 
    &\ = 
    [\Delta_1 ; \Delta_2 \ |\ 
      \Delta_1 \in M_1
      \ \ \  
      \Delta_2 \in M_2
    ]
    \end{array}
  \]

  \caption{Product of lists environments}
\end{figure*}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
    \text{reduce} \wedge [] 
    &\ = \top
    \\
    \text{reduce} \wedge \tau::\widebar{\tau}
    &\ = \tau\ \wedge (\text{reduce} \wedge \widebar{\tau})
    \end{array}
  \]

  \caption{Reduction of types}
\end{figure*}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
      N_1 * N_2
      &\ = 
      \begin{array}[t]{l}
        [ \Delta_1 ; \Delta_2 . \tau_1 \wedge \tau_2 \ |\ 
          \Delta_1.\tau_1 \in N_1
          \ \ 
          \Delta_2.\tau_2 \in N_2
        ]
      \end{array}
    \end{array}
  \]

  \caption{Product of lists of contextual types}
\end{figure*}

\begin{figure*}[h]
  \[
    \begin{array}{l @{}l}
    \text{reduce} * \{N\}
    & {}= N
    \\
    \text{reduce} * \widebar{N_i}
    & {}= N_j * (\text{reduce} * \widebar{N_i}\setminus\{N_j\})
    \end{array}
  \]

  \caption{Reduction of sets of contextual types}
\end{figure*}




\section{Evaluation}
\begin{enumerate}
  \item experiments 
  \item adequacy of problem 
  \item adequacy of solution 
\end{enumerate}

\section{Related work}
\begin{enumerate}
  \item past work 
  \item future work 
\end{enumerate}

\section{Conclusion}
\begin{enumerate}
  \item restate context with technical terms 
  \item restate problem with technical terms 
  \item restate solution with technical terms 
  \item restate results 
\end{enumerate}

% \section*{Notes}

% \subsection*{dualities}
% \begin{enumerate}
%   \item \(\bot \leq \top \)
%   \item \(\tau_1\ \&\ \tau_2  \leq \tau_1\ |\ \tau_2 \)
%   \item \(\forall \alpha . \tau \leq \exists \alpha . \tau \)
%   \item \(\nu \alpha . \tau \leq \mu \alpha . \tau \)
% \end{enumerate}

% \subsection*{contributions}
% \begin{enumerate}
%   \item program synthesis such that:
%     \begin{enumerate}
%       \item goal defined by partial programs with missing annotations  
%       \item goal transformed into type specification 
%       \item type specification may contain dynamic type  
%     \end{enumerate}
%   \item algorithmic subsumption allows simple subtyping rule with dynamic type
%     \begin{enumerate}
%       \item subtyping can have a dynamic type on either side without risk of   
%         all terms being accepted by typing rules (i.e. everything typing)
%     \end{enumerate}
%   \item an expressive type system 
%     based on intersection, union, recursive, and co-recursive types
%     \begin{enumerate}
%       \item without dependent types 
%       \item comparable to prolog 
%       \item allows dynamic type 
%       \item sound modulo absence of dynamic type 
%         or static type union/intersect with dynamic
%       \item types behave either leniently or strict depending on usage as actual type or expected type
%     \end{enumerate}
%   \item full type synthesis with full type propagation (for all rules)
%   \item type unification such that: 
%     \begin{enumerate}
%       \item the principal type of all terms is top
%       \item lenient (but unsound) static type inference
%       \item expanding type info with union and intersection and dynamic type
%     \end{enumerate}
%   \item interleaving type constraint generation and solving with dynamic type 
% \end{enumerate}

% \subsection*{differences}
% in contrast with System F:  
% \begin{enumerate}
%   \item types are not used as arguments to functions 
%   \item universal binders do not represent placeholder for type argument 
% \end{enumerate}

% in contrast with gradual typing:  
% \begin{enumerate}
%   \item infers more static type info 
%   \item stronger soundness claim (i.e. weaker soundness precondition)
%   \item dynamic semantics are irrelevant 
%   \item deterministic subsumption 
%   \item dynamic type built into subtyping 
% \end{enumerate}

% in contrast with HM type inference:  
% \begin{enumerate}
%   \item synthesizes type in addition to constraint solution 
%     due to subtyping
%   \item propagates types
%   \item global top type, leaves types open during unification
%   \item expands and narrows types  
% \end{enumerate}

% in contrast with Roundtrip typing:  
% \begin{enumerate}
%   \item type combinators without dependent types
%   \item prolog-like type language  
%   \item synthesizes types for all rules
%   \item global top type, leaves types open during unification
%   \item expands and narrows types  
%   \item delegates to unification to decompose types 
%   \item delegates to unification to free bound variables 
% \end{enumerate}




% \subsection*{gradual typing}
% How gradually typed inference typically works:
% \begin{enumerate}
%   \item infer either a strict static type or a dynamic type
%   \item let annotations implicitly guide the usage of static vs dynamic checks 
% \end{enumerate}
% There exists work on type inference for gradually typed programs.
% To the best of my knowledge, they are all sound and complete.
% Other gradual type inference systems separate 
% generating constraints from solving constraints.
% Gradual typing systems use the dynamic type \lstinline{(?)} to indicate 
% that dynamic checks should be used.
% Gradual type inference relies on ML types with union extension.
% They do not contain the idea of using intersection and union to keep types open.
% Gradual typing systems separate subtyping from the relation 
% between dynamic to static types to avoid all terms typing via the subsumption rule.


% \subsection*{references}
% \begin{enumerate}
% \item Refinement types for ML by Tim Freeman and Frank Pfenning 
% \item Refinement types as proof irrelevance by William Lovas and Frank Pfenning 
% \item Local type inference by Benjamin C. Pierce and David N. Turner
% \item Liquid types - \url{http://goto.ucsd.edu/~rjhala/papers/liquid_types.pdf}
% \item Program synthesis from polymorphic refinement types by Nadia Polikarpova, Ivan Kuraj, and Armando Solar-Lezama
% \item Example-directed synthesis: a type-theoretic interpretation by Frankle, Osera, Walker, and Zdancewic
% \item Gradual typing for functional languages by Jeremy G. Siek and Walid Taha 
% \item Gradual typing for functional languages by Jeremy G. Siek and Walid Taha 
% \item Gradual typing for objects by Jeremy G. Siek and Walid Taha 
% \item Gradual typing with unification-based inference by Siek and Manish Vachharajani 
% \item Dynamic Type Inference for Gradual HindleyMilner Typing - \url{https://dl.acm.org/doi/pdf/10.1145/3290331}
% \item Principal type schemes for gradual programs - \url{https://www.cs.ubc.ca/~rxg/ptsgp.pdf}
% \item Gradual Liquid Type Inference - \url{https://arxiv.org/pdf/1807.02132.pdf}
% \item Gradual typing with union and intersection types - \url{https://dl.acm.org/doi/pdf/10.1145/3110285}
% \item Gradual typing: a new perspective - unions, intersections, dynamic type, and type inference - \url{https://www.irif.fr/~gc/papers/popl19.pdf}
% \item Gradual refinement types (via abstract interpretation) - \url{https://pleiad.cl/papers/2017/lehmannTanter-popl2017.pdf}
% \item Consistent subtyping for all - \url{https://xnning.github.io/papers/consistent-subtyping-for-all-toplas.pdf}
% \item Polymorphic functions with set-theoretic types, part 1 - \url{https://www.irif.fr/~gc/papers/polydeuces-part1.pdf}
% \item Polymorphic functions with set-theoretic types, part 2 - \url{https://www.irif.fr/~gc/papers/polydeuces-part2.pdf}
% \item Revisiting occurrence typing - \url{https://arxiv.org/pdf/1907.05590.pdf} 
% \item An ideal model for recursive polymorphic types; MacQueen, Plotkin, Sethi; Metric/Contraction/Banach fixed point theorem
% \item Bottom-up synthesis of recursive functional programs using angelic execution - Anders Miltner et al


% \end{enumerate}


\end{document}

% Observations:
% language of types
  % a type is a set of objects
  % a type may be viewed as proposition that may be undecidable 
    % proved by a term
% language of constraints
  % A constraint may be viewed as a decidable proposition 
  % A constraint is simply a subtyping relation over types
    % allowing economical reuse of types 
  % A fully assigned subtyping constraint is a verifiable statement
% Freeing variables happens in subtyping/unification due to subtyping asymmetry  
  % free variable in subtyping connects to free variable associated with term 
  % if expected type has free variable.
% widening and narrowing in type inference
  % exactness param chosen during inference 
    % exactness flag is justified by dual purpose of type system
      % 1. catch errors (exactly according to spec)
      % 2. describe behavior of program abstractly
  % annotations are exact 
  % everything else is non-exact;
    % allowing union and intersection with fresh variables
% comparison of relational types with dependent types

  % dependent types
    % inductive LL : Nat -> Type where
    % | nil : LL 0 
    % | cons : {n : Nat} -> LL n -> LL (n + 1) 

    % F   (n : Nat) -> LL n
    % P   (n : Nat)  LL n

    % variable introduction is coupled with type construction/compounding
    % this is convenient since a type may dependent on a term that's not included in itself


  % relational types 
    % P  
    % (0^@  nil^@) | 
    % ( N L :: N  L  P => 1^N  cons^L) 

    % translating from dependent to relational
    %  {n : Nat}  LL n  LL (n + 1) 
    %  {n : Nat} {l: List} :: (l : LL n)  {(n + 1, cons l)}  
    % ( N L :: N  L  P => 1^N  cons^L) 

    % -- OR -- 

    % F  
    % (nil^@ -> 0^@) ; 
    % ( L N :: F  L -> N => cons^L -> 1^N) 

    % translating from dependent to relational
    %  {n : Nat} -> LL n -> LL (n + 1) 
    %  {n : Nat} {l: List} :: (l : LL n) -> {for cons l => n + 1}  
    % ( L N :: F  L -> N => cons^L -> 1^N) 


    % variable introduction is decoupled from type construction 
    % the use of a variable in a type is separate from introducing the variable
    % this is convenient since any term that a type depends on exists as a subpart
    % of a term in that type
    % Thus, dependencies may be inferred from terms.

    % My intuition is that the symmetrical relations 
    % and the decoupling of binder introduction from type combination 
    % and consistent treatment of type dependency and type membership 
    % provides an easier mental model to work with
  % closed parameter 
    % indicates if a constraint is closed vs open 
    % variables are fully determined in closed unification 
    % variables are are open to future information in open unification 


% claim: SOTA: type systems for dynamically typed languages do not have type-directed synthesis methods. 
% identify problems for synthesis evaluation
% translate Liquid type benchmarks to this relational type language. 

% Aim.cen/Aim.adj is safe when the free variables may be chosen (i.e. choosable).
% we use Aim.cen when we only care about checking for safety.
% we use Aim.adj when we want to find the most lenient model possible, 
% amenable to safe term compositions in the unexplored parts of the program. 
% Aim.max and Aim.min is necessary when the variables are fixed but unknown; they may not be chosen. 

% for dynamically typed languages, system F subtyping is too restrictive
% we need to compare types that have varying degrees of variable generalization 
% additionally, the subtyping constraints in quantified types are more general than system F
% variables are not restricted to be alone on the left side of subtyping. 
% this generality allows for concise descriptions of recursive function types.

% Remy's ML-calc uses quantified constraint for a similar goal, but technically quite different.
% Remy's ML-calc makes a distinction between subtyping and instantiating relation of universal
% relational types merges the notion of instantiation with subtyping
% relational types generalizes second-order quantification to subsume first-order use-cases. 

% note that Remy' constraint uses existential because the subtyping is inside
%  X :: C(X)  X  T === ( X :: C(X) . X)  T

% synquid has a symmetrical rule using implication for subtyping constraint types
% in Synquid is subtyping depends only on the constraints 
% in our setting subtyping can depend on base types too
% the asymmetrical rules can handle all permutations 


% subtyping constraints may be thought of as decidable propositions of the metalanguage 
% equivalent to deciding if a proof satisfies a proposition (of the object language)
% types may be thought of as possibly undecidable propositions of the object language
% the advantage of using subtyping as the only metalanguage predicate is operating on types
% is that types can be reused across both the object language and metalanguage propositions.

% it would have been possible to define a first-order constraint language, as is the case in Synquid,
% but that would not allow reusing information across types and constraints.
% by adding constraints to the second-order quantification of types, 
% a single quantification mechanism serves two distinct purpose
% 1. to precise define the contents of a type. (typically the purpose of first-order quantification)
% 2. to allow specialization of type based on usage (typically the purpose of second-order quantification) 


% there are two distinct purposes of polymorphic quantification over types
  % 1. parametric - ignoring a sub part of a type (2nd order) 
  % 2. constrained - defining a type based on constraints (1st or 2nd order)

% there are two distinct forms of checking polymorphic composition 
  % 1. instantiation a quantified variable supports both parametric and constrained polymorphism
  % 2. subtyping of quantified type over the same variables   

% RT uses second order univ/exists quantifiers subsume both constraint types and polymorphic types
% RT's subtyping subsumes both instantiation and refinement  
% liquid's refinement type is an intersection of a base type and a constraint type. 
  % that is, the resulting type is a refinement of the base type. 


% RT's subtyping subsumes both System F polymorphic subtyping with Synquid/Remy's polymorphic instantiation  
% RT's subtyping subsumes both Synquid's refinement subtyping and existential instantiation
% RT's existential generalizes subpart irrelevance and subpart refinement 




% /-
% first order quantification

%  NL .
%   {(0, [])}  
%    (n, l) : NL . 
%     (n + 1,  () :: l)  

%  N2L .
%   {0 => []}  
%    n -> l : N2L .  WRONG
%     {n + 1 => () :: l }

%  N2L .
%   0 -> nil*unit  
%    N2L  N -> L .    
%     N + 1 => unit :: L

% --- 
% by second order quantification with subtyping rather than first order with membership,
% we avoid mapping between terms and types in unification procedure.
% We also enable the succient corecursive definitions of functions.

% -/


% /-
% translating Liquid types into relational types

% List with len where
% [] : {v  List | len v = 0} | 
% () :: (xs : List) : {v  List | len v = (len xs) + 1} | 

% n : Nat -> {v  List | len v = n}

% ...

%  N . N  Nat => N -> ( L . 
%   (N  L)  ( N'  L' .  (0  []) | (N' + 1  () :: L'))  =>
%   L
% )

% ...

%  N -> L .
%   0 -> []  
%   N + 1 -> () :: L  


% -/

% comparison of typing systems
  % bidirectional type checking 
    % full program required 
    % some rules require type annotations: type checking rules
    % some rules don't have type annotations: type inference rules 
  % bidirectional program checking 
    % full type required
    % some types also have program examples: program checking rules
    % some types don't have program examples: program synthesis rules 
  % generalized type checking 
    % all rules handle both type checking and type inference
      % propagate types down and up
  % generalized program checking 
    % all rules handle both program checking and program synthesis 
      % propagate programs down and up

% relational type's type inference and unification with union type
  % generates sets of typing environments 
  % represented with functions instead of inference rules 
  % this is difficult to represent with inference rules 

% relational type's inference and synthesis 
  % type inference for each term case and an arbitrary type
  % program synthesis for for hole term and each type case.

% sequent calculus rules 
  % enable generating derivation
  % the essence is its using left and right rules (relative to the turnstile)
  % left rules have type/prop form on lhs of |-
  % left rules correspond to elimination rules of natural deduction
  % it's not essential that the sequents have multiple consequents

% synthesis rules
  % use sequent-calculus style
  % union on left should result in a cases function applied to an argument
  % intersection on Right should result in either a function or a record
  % thus, can reduce union on left to intersection on right.
  % first-class pattern matching with beta-normal form heuristic
    % could require function to be let-bound 

% use of negation
  % could negation of T be encoded as T -> bot?
  % that is,
    % T1 -> T2 /\ NOT T3 = % T1 -> T2 /\ T3 -> bot

% inductive generalization
  % inductive generalization normalized as finding a subtype
  % generalization adds information
  % thus decreasing information loss when finding types for holes in deduction phase 


% TODO:
% modify to full program synthesis
  % see if data structure transformers can be emulated using refinement type inference 
  % does angelic synthesis relate to this?
% find way to integrate SMT solvers 
% write paper 
  % [x] 0. introduction 
  % [ ] 1. motivating example / overview 
  % - 2. problem statement 
  % - 3. overall synthesis/inference algorithm/rules 
    % include how type information propagates
    % abstract away relation type details
    % includes propagation of types
  % - 4. unification / subtyping / relational typing
    % including recursion over intersection and functions
% find decision procedure for relational types (subtyping over induction on compound types)
  % terminate if one side is compound with all variables and other is recursive? 
  % Banach fixed-point theorem?
  % contraction maps?
  % metric spaces?
% determine if negation/relative complement is needed to improve program synthesis 
  % see anti-specification in Anders' paper
  % https://courses.cs.washington.edu/courses/cse507/14au/sched.html
  % https://www.cs.utexas.edu/~bornholt/post/synthesis-explained.html
  % https://people.csail.mit.edu/asolar/SynthesisCourse/Lecture1.htm
% implement proof of soundness
% implement translation from surface syntax to nameless syntax 
% consider methods of ensuring beta-normal forms
  % splitting off elim forms than can't refer to intro forms to prevent non-beta-normal forms
  % normal form syntax use let-binding (similar to ANF or CPS or SSA)
