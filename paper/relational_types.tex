% \documentclass{article}
% \documentclass[]{acmart}
% \documentclass[manuscript]{acmart}
% \documentclass[manuscript,screen,sigplan,review]{acmart}
\documentclass[sigplan]{acmart}
% \documentclass[manuscript]
\usepackage{mathpartir}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{stmaryrd}
\usepackage{listings}
% \usepackage{amsthm}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}{Corollary}[theorem]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\makeatletter % allow us to mention @-commands
\def\arcr{\@arraycr}
\makeatother

\lstset{
    identifierstyle=\color{violet},
    % textcolor=blue,
    % keywordstyle=\color{blue},
    keywordstyle=\text,
    basicstyle=\ttfamily,
    mathescape=true,
    showspaces=false,
    morekeywords={let, fix, in}
}
\usepackage[utf8]{inputenc}
% \usepackage[T1]{fontenc}


%\title{Type-Directed Synthesis for Dynamic Languages}
% \title{Guiding Program Synthesis with Relational Types}
\title{Relational Type Inference}
\author{Thomas Logan}
\date{October 2022}

\begin{document}

\maketitle

\section{Introduction}
% context: dynamically typed languages   
Some of Today's most popular languages such as JavaScript and Python are considered to be \textbf{dynamically typed}.
One of the hallmarks of such languages, is that they do not require specifications 
that can be verified statically. By not requiring static bounds, dynamically typed languages
enable vast combinations of terms and high reusability of code. 
Although it's not required, many programmers find that
static checks, such as \textbf{linters} and more advanced \textbf{static analysis} tools, 
enable them to find bugs, understand code, and write code more efficiently and reliably. 

In addition to writing programs, programmers can also annotate programs with specifications to
aid static verification. Writing specifications and programs can be tedious and burdensome.  
It addition to verifying correction, static tools can aid programmers by automatically synthesizes
parts of programs or specification implied by the context. Thus, the programmer can simply write
either a partial specification or partial program and allow the synthesis tool to fill in the rest.   

\begin{lstlisting}[language=Python]
def foo(x):
    if isinstance(x, int):
        return x + 1 
    elif isinstance(x, str): 
        return x + "abc"
\end{lstlisting}

% motivation: Specification 
Much of the work on synthesizing specifications from programs has been based on \textbf{ML type inference}.
In contrast to dynamically typed languages, \textbf{ML languages} require that static bounds are prescribed 
in its programs via its \textbf{datatype} mechanism. The design of ML's datatype mechanism is clever, 
such that these static bound prescriptions are only needed at the definitions of types and can be 
inferred when the data of types are used. When a piece of data is seen, an upper static bound 
may be inferred and propagated around the syntax tree to check correct composition of the program.

\begin{lstlisting}[language=ML]
datatype int_or_str = 
    Int of int | 
    Str of string

fun foo(Int x) = x + 1
  | foo(Str x) = x ^ "abc"
\end{lstlisting}

In addition, to intrinsically associating certain terms with upper bounds, many languages require
type annotations that restrict the values used in place of variables or parameters.


% motivation: subtyping 
Since dynamically typed languages do not require prescribed static bounds, 
type inference (or specification synthesis, in more general terms) must balance 
restricting the permissible combinations and reusability in programs with 
catching errors that could result in crashes at runtime.
The flexibility of combinations implies that for the same data, 
the tightest static bounds may differ depending on the context.
Thus, \textbf{subtyping} or a similarly flexible 
static notion is necessary to avoid overly restricting combinations.

% motivation: expressive types 
Mainstream type systems typically merely allow constructing simple types 
by grouping objects together based on their structures or names.
However, to have genuine confidence in the correctness of programs, specifications
need to express relations between data. There are a number of rather esoteric systems that
enable stating and proving propositions that relate objects to each other, 
including ACL2, Twelf, Coq, Lean, HOL, Isabelle, Liquid Haskell, and Synquid.  
Some of these use dependent types to encompass both simple types and propositions, 
and some rely on new syntactic categories for propositions. 

Liquid Haskell and the related Synquid both provide a way to define relations
along with subtyping, by extending ML datatypes with predicate clauses. 

\begin{lstlisting}[keywords={termination, measure, data, where}]
termination measure len :: List $\beta$ $\rightarrow$ Nat 
data List $\beta$ where
  Nil :: {v: List $\beta$ | len v = 0}
  Cons :: $\beta$ $\rightarrow$ xs: List $\beta$ $\rightarrow$ 
    {v: List $\beta$ | len v = len xs + 1}

\end{lstlisting}

However, as discussed above, the ML datatype mechanism breaks our definition of dynamically typed,
as it demands prescribing static bounds with data, so this would not work for our problem wholesale.
Other systems, like Lean or Isabelle, have similar problems with the additional issue of lacking subtyping.
Finally, all of these are rather complex, either by requiring syntactic classes of propositions predicates, 
in addition to types, or complicating the static semantics of types by allowing them 
to be dependent on programs.



% motivation: Programming 
With expressive types, using types to guide the user's programming or automatic program synthesis 
becomes a more realistic endeavor, as there may be enough information in the specification to narrow the field
and guide the generation of useful programs. Lean and Synquid\cite{} (Based on Liquid Haskell) 
are two examples of systems that decompose and propagate type specifications 
to incomplete sections or holes in programs. 
In the case of Lean, users can use this local type specification to help them construct programs and proofs,
while in Synquid this local information is leveraged to efficiently synthesize programs. 

% solution 
This paper introduces the \textbf{relational type system} to provide expressive specifications 
and synthesis capabilities for dynamically typed languages. 
The contributions of the relational type system include:
\begin{enumerate}
  \item A synthesis algorithm capable of generating local constraints for incomplete programs. 
  \item A unification algorithm capable of preserving the flexibility of dynamically typed programming. 
  \item A type level language capable of expressing subtyping of (co)inductive relations. 
\end{enumerate}

% half baked idea: by removing terms from type language,  
% terms may be enhanced with side-effects/concurrency etc,
% without complicating the type system.

% summary 

In section 2, we discuss related work. 
In section 3, we illustrate the problem and our solution with examples.
In section 4, we define the problem and the syntax, semantics, typing, and subtyping of our language.
In section 5, we present the synthesis and unification algorithms.
In section 6, we prove the soundness of our analysis. 
In section 7, we discuss possible future directions

\section{Related work}
There has extensive past work dealing with different aspects of our problem,
including expressive subtypes, dynamic types, and type reconstruction.  
\newline 

\noindent
\textbf{Descriptive types}. We define \textit{descriptive types} as 
type systems that allow term constructions to belong to any type that accurately describes them. 
Generally speaking, dynamic types are the most precise description, however,
as their name suggests, that description is determined dynamically (at runtime).

\textit{Gradual types} \cite{} are a set of design principles for controlling which parts of a program
should be enforced statically and which parts should be handled dynamically. 
This allows users to choose between tradeoffs of precise dynamic errors or  
less precise static errors depending on their particular situations.

\textit{Set-theoretic types} \cite{} offer ways to describe programs statically 
with union and intersection type combinators (among other set-related features). 
In contrast to \text{refinement types} \cite{}, where a term constructor is prescribed a particular top type by the datatype mechanism,
there is no prescribed upper bound on the set that a term may belong to. The set that describes
a term can be widened with union, or the type expected by a parameter may be narrowed with intersection. 

In our relational type system, we take a set-theoretic approach.
\newline

\noindent
\textbf{Expressive types}. There are many existing type systems for stating properties beyond 
merely the interface of objects. 

\textit{Dependent types} are probably the best known form of expressive types. 
Systems with dependent types include Twelf \cite{}, ATS (Xi et al), Coq, Lean, and others. By allowing types to depend on terms, 
these systems enable the construction of terms that act as proofs of properties described by types. 
That is, function abstraction corresponds to implication introduction, function application corresponds to modus ponens, and 
datatype constructors correspond to introduction/elimination rules of primitive propositions.

\textit{Predicate subtyping} is an alternative approach, as seen in Liquid types and PVS, 
where a predicate can refine a type to a subtype that accepts a subset of the original set of terms.
In contrast to dependent type systems, 
the inhabitant of a predicate subtype is a witness to the existential interpretation of the predicate, 
rather than a composition of rules that construct the proposition. 
This places a greater burden of proof to be automated by the type system (as in Liquid Haskell) or requires auxiliary ways of providing proofs (as in PVS).
Assuming the predicates are decidable, the witnesses could be viewed as a very simple form of proof.
The advantage of the predicate subtyping approach is that users can avoid the effort of constructing proofs that are computationally irrelevant.
Additionally, they can reuse the same constructions across a hierarchy of types, rather than constructing isomorphisms. 

In our relational type system, we take an approach similar to predicate subtyping, however, our language design does not require
a separate language of predicates. Instead, we reuse the notion of subtyping directly in place of a separate predicate language.
The result is that our declarative type language has a pattern matching flavor akin to Prolog. 
Instead of reasoning in terms of a predefined set of predicates, 
one can reason over types whose meanings are derived from the forms of their terms.
\newline

\noindent
\textbf{Type reconstruction}.

\textit{Hindley-Milner type inference} \cite{} is the standard technique for complete type reconstruction employed
by many systems. The technique can reconstruct the types of parameters 
and terms by constructing constraints over types and solving for type variables. 
The constraints are constructed bottom up. Some systems solve the constraints on the fly  
as they are generated, while other systems separate constraint generation and constraint
solving into two separate phases. 
Liquid types combine Hindley-Milner type inference 
with \textit{predicate abstraction}\cite{} to infer both base types and predicate refinements.

\textit{Bidirectional typing} is approach for reconstructing types locally\cite{}.
Bidirectional typing can provide an incomplete method of reconstruction by leveraging
annotations and propagating their types downward to reconstruct types 
for subparts of the program. 
In other areas where annotations are not required it can partially
reconstruct types by propagating type information up. 
\text{Roundtrip typing} \cite{} is an extension of 
bidirectional typing that enables program synthesis guided by liquid types. 

Our relational type system extends both Hindley-Milner and bidirectional typing, 
such that precise and expressive types may be inferred and errors may be detected locally
without rigid requirements on where annotations must be placed.  
Additionally, the combination of upward and downward propagation of types 
makes type checking more efficient by pruning the search space, 
much like how CDCL and BCP combine to prune the search space in SAT. 

In our setting, we leverage union and intersection in type inference
resulting in a technique we call \textit{type adjustment} that automatically widens and narrows types 
with the goal of increasing precision of the type reconstructions. This increased precision naturally
enables inferring expressive types as well.

\textbf{TODO:} Think about connection between between type adjustment and predicate abstraction/iterative weakening and predicate refinement.
Does RLT's co-inductive type inference with unification correspond to predicate abstraction with fixpoint computation? 
Is the co-inductive type constructed in the fix rule related to the interpolant concept?

The parameter types are the initial condition. 
A parameter type variable in is akin to an abstract premise (predicate abstraction). 
Unification with variable on RHS is an abstract check, where variable assignment 
is necessary condition (dual of counterproof). 
Subsequent calls after substitution are concrete checks that validate assignment 
and generalize by solving for variables on LHS, 
where variable assignment is proof of necessary condition (failure of counterproof).
\newline


\section{Overview}

This work introduces three cohesive strategies towards making
dynamically typed programs easier to write with fewer errors.  
\begin{enumerate}
  \item propagating types (downward/upward) 
  \item adjusting types (wider/narrower) 
  \item constraining types (inductive/coinductive) 
\end{enumerate}
We introduce a programming language with a specification language to indicate static bounds. 
As is common these days, the static bounds are represented in a language of types.

\subsection{Propagated types}
Writing type annotations can be burdensome, so the first step 
towards making static checks feasible is to infer types from terms.

\begin{lstlisting}
cons;(hello;(),cons;(world;(),nil;())) : 

cons*(hello*unit $\times$ 
cons*(world*unit $\times$ 
nil*unit
))
\end{lstlisting}

\noindent The example above illustrates a type inferred from a term.
The part left of the colon is the term and the part right of the colon is the type.
The unit term is represented as \lstinline{()}, and it belongs to type \lstinline{unit}. 
A tagged term is constructed from a literal sequence of characters and a term separated
by a semicolon. A tagged term is constructed from a literal sequence of characters
and a type separated by a star.
So the type of \lstinline{hello;()} is \lstinline{hello*unit}.

The reason for inferring types is the check for errors statically or 
provide hints on how to complete missing parts of a program. To this end,
types propagate back up the syntax tree and down siblings' trees in order
to facilitate type checking and type hinting.
Depending on a programming languages requirements of static specification, 
whether types are propagated up or down may vary. 
In the case dynamically typed programs, no static specification or type annotations
are required, so types are propagated in both directions for every syntax rule
of the language.


\subsection{Propagated up}
Since annotations are not required, it is important to propagate types up to check
that a term fits its context.
For example, a function abstraction is not required to be annotated 
with either an input type or an output type. 
\noindent By propagating up the input type we can check the composition of the application.
By propagating up the type of the body, we can check the result of the function application 
with its surrounding context. 

\begin{lstlisting}
let f = ($\lambda$ x $\Rightarrow$ 
  let g : nat -> str = $\hdots$
  hello ; (g x)
) 
let y : world * str = f 4
\end{lstlisting}

The type of \lstinline{f} is inferred to be \lstinline{nat $\rightarrow$ hello*str}, 
by propagating up the types inferred for its parameter and body.
The application is satisfactory since applied to the term \lstinline{4}, 
but it fails when checked against the function application's context,
which expects \lstinline{world*str}.
\begin{lstlisting}
hello*str $\sqsubseteq$ world*str
\end{lstlisting}

\subsection{Propagated down}
By propagating down and decomposing types, 
it is possible to guide the completion of programs with type hints.
To maintain the spirit of dynamic types, type annotations must remain optional.
Previous work has demonstrated the utility of downward propagating types 
in theorem proving systems, local type checking, 
and synthesis of ML-family programs.

For example, in a program that extracts 
the first element of a pair of a particular type, 
it's possible to detect an error before knowing the second element.

\begin{lstlisting}
$\lambda$ n : nat $\Rightarrow$
  let first = ($\lambda$ (x,y) : (str $\times$ str) $\Rightarrow$ x) .
  first (n, _) 
\end{lstlisting}

\noindent The  applications' argument type \lstinline{(nat $\times$ ?)} 
is propagated and decomposed such that the subtyping constraint 
\lstinline{nat $\subseteq$ str} is decided. 

\subsection{Adjusted types}

In a dynamically typed language, since types are not necessarily prescribed
for terms of particular constructions (as they are in ML datatypes), 
the optimal type for a term will depend on how terms and parameters are used in context. 
When inferring a type that may be associated with various terms throughout a program,  
The optimal type may depend on widening a type as new use cases are discovered,
or narrowing a type as new restrictions are discovered. 

\subsection{Adjusted with widening}

In parametric types where a generic input type must be the same as a generic output type,
The dynamic nature of terms is seemingly at odds with inferring types.

In the case of a function with generic types, 
the types can be specialized based on the terms that are witnessed as inputs. 

Since there's no particular upper bound type associated with 
a term other than top ($\top$), 
The parameter type must accommodate types of unforeseen arguments, 
while the return type should be widened with each successive
argument's type.
widening is achieved with the introduction of the union type operator ($\vee$).

\begin{lstlisting}
($\lambda$ pair : $\forall$ $\alpha$ . $\alpha$ $\rightarrow$ $\alpha$ $\rightarrow$ ($\alpha$ $\times$ $\alpha$) $\Rightarrow$ 
($\lambda$ n : int $\Rightarrow$ ($\lambda$ s : str $\Rightarrow$ 
  pair n s
)))
\end{lstlisting}

Let \lstinline{?} stand for a fresh type variable.
Once \lstinline{pair} is applied to an integer its generic type is specialized to 
\lstinline{(int $\vee$ ?)}, 
in which union with the dynamic type behaves like the top type $\top$, 
accommodating receiving a string as a the subsequent input.
Thus, the generic type is specialized to 
\newline
\lstinline{(int $\vee$ str $\vee$ ?)}.
The type variable always passes type checking, 
thus behaving like bottom for term types
and behaving like top for parameter types.
As such, the parameters' union types behave like top,
and the type variable simply falls away in the union of the result type. 
The result type for \lstinline{(pair n s)} ends up as 
\newline
\lstinline{(int $\vee$ string) $\times$ (int $\vee$ string)}. 

\subsection{Adjusted with narrowing}

In functions where a parameter has an unknown type and that parameter is 
internally used as an argument to an application, the dynamically typed 
nature of terms adds some complications to type inference.

The argument type must be amenable to parameter types 
of unforeseen compositions,
while the external parameter type should be narrowed 
to the smallest type necessary for internal compositions to
succeed.

\begin{lstlisting}
($\lambda$ i2n : int $\rightarrow$ nat $\Rightarrow$ 
($\lambda$ s2n : str $\rightarrow$ nat $\Rightarrow$ 
  $\lambda$ x $\Rightarrow$ (i2n x, s2n x)
))

\end{lstlisting}

Once \lstinline{i2n} is applied to \lstinline{x}, 
the type for \lstinline{x} is specialized to \lstinline{(int $\sqcap$ ?)}, 
in which intersection with the dynamic type behaves like the bottom type $\bot$,
availing itself to be used in subsequent applications. 
Thus, the dynamic type is inferred to be \lstinline{(int $\sqcap$ str $\sqcap$ ?)}.

The type variable always passes type checking, 
thus behaving like bottom for term types
and behaving like top for parameter types.
As such, the intersections of argument types behave like bottom,
and the type variable simply falls away in the intersection type of a parameter.
The external parameter type for ends up as \lstinline{(int $\sqcap$ str)}. 


\subsection{Constrained types}
In order to thoroughly catch errors and guide programming, 
the specification language must be able to describe the semantic relation
between structures. Rather than adding a second syntactic layer 
of predicates and propositions to our specification language,
we build on the notions of type abstraction -  
union/intersection types, second order quantified types, and (co)inductive types 
- already prevalent in type systems, yielding a novel system of relational types.

\hfill \\
Consider the type for a list.

% \begin{lstlisting}[]
% $\mu$ list .
%   nil*unit $\vee$
%   $\exists$ $\alpha$ . cons*($\alpha$ $\times$ list)
% \end{lstlisting} 

\[
\begin{array}[t]{@{} l}
  \exists\ \text{X}\ .\ \mu\ \text{XS}\ .\ 
  \arcr
  \hspace{4mm}\text{nil}*\text{unit}\ \vee
  \arcr
  \hspace{4mm}\text{cons}*(\text{X} \times \text{XS})
\end{array}
\]

\hfill \\
This list type contains three kinds of type abstraction: 
union, existential quantification, and induction.
Using these three forms of type abstraction, we are able to define 
a set of lists of arbitrary length with arbitrary items. 

We abbreviate the inductive part of the list type.
\[
list(\alpha) = 
\begin{array}[t]{@{} l}
  \mu\ \text{XS}\ .\ 
  \arcr
  \hspace{4mm}\text{nil}*\text{unit}\ \vee
  \arcr
  \hspace{4mm}\text{cons}*(\alpha \times \text{XS})
\end{array}
\]

Now suppose we wish to validate a function that expects $list$ to an argument. 
\[
  \begin{array}[]{@{} l}
  \text{let}\ \text{foo} : (\exists\ \text{X}\ .\ list(\text{X})) \rightarrow \text{unit} = \_\ \text{in}
  \arcr
  (\text{foo}\ (\text{cons};((),\text{nil};())))
  \end{array}
\]

This function application generates a subtyping constraint which we decide by unrolling
the the inductive types. The successful trace of the decision algorithm corresponds To
the following derivation. 

\[
  \Delta_l = \oslash, \text{X} \mapsto \text{unit}
\]

\begin{mathpar}
\inferrule* {
  \inferrule* {
    \inferrule* {
      \inferrule* {
        \inferrule* {
          \Delta_l(\text{X}) = \text{unit}
        } { 
          \Delta_l \vdash
          \text{unit}
          \sqsubseteq
          \text{X}
        }
        \\
        \inferrule* {
          \inferrule* {
            \inferrule* {
              \vdots
            } { 
              \Delta_l \vdash
              \text{nil}*\text{unit}
              \sqsubseteq
              \text{nil}*\text{unit}
            }
          } { 
            \Delta_l \vdash
            \text{nil}*\text{unit}
            \sqsubseteq
            \begin{array}[]{@{} l}
              \text{nil}*\text{unit}\ \vee
              \arcr
              \text{cons}*(\text{X} \times list(\text{X}))
            \end{array}
          }
        } { 
          \Delta_l \vdash
          (\text{nil}*\text{unit})
          \sqsubseteq
          list
        }
      } { 
        \Delta_l \vdash
        (\text{unit} \times \text{nil}*\text{unit})
        \sqsubseteq
        (\text{X} \times list(\text{X}))
      }
    } { 
      \Delta_l \vdash
      (\text{cons}*(\text{unit} \times \text{nil}*\text{unit}))
      \sqsubseteq
      \text{cons}*(\text{X} \times list(\text{X}))
    }
  } { 
    \Delta_l \vdash
    (\text{cons}*(\text{unit} \times \text{nil}*\text{unit}))
    \sqsubseteq
    \begin{array}[]{@{} l}
      \text{nil}*\text{unit}\ \vee
      \arcr
      \text{cons}*(\text{X} \times list(\text{X}))
    \end{array}
  }
} { 
  \oslash \vdash
  (\text{cons}*(\text{unit} \times \text{nil}*\text{unit}))
  \sqsubseteq
  \exists\ \text{X}\ .\ list(\text{X})
}
\end{mathpar}

In addition to deciding if a \emph{singleton type}, a type containing exactly one element, 
we can, we can also compare two inductive types. 
Consider the natural numbers and even numbers.
\[
nat = 
\begin{array}[t]{@{} l}
  \mu\ \text{N}\ .\ 
  \text{zero}*\text{unit}\ \vee
  \text{succ}*\text{N}
\end{array}
\]
\[
even = 
\begin{array}[t]{@{} l}
  \mu\ \text{N}\ .\ 
  \text{zero}*\text{unit}\ \vee
  \text{succ}*\text{succ}*\text{N}
\end{array}
\]

We can decide that even numbers are included in the natural numbers, 
by unrolling with the induction hypothesis. 
The successful trace of the decision algorithm corresponds to a subtyping derivation.   

\begin{mathpar}
\inferrule* {
  \inferrule* {
    \inferrule* {
      \inferrule* {
        \vdots
      } { 
        \oslash \vdash
        \text{zero}*\text{unit}
        \sqsubseteq
        \text{zero}*\text{unit}
      }
    } { 
      \oslash \vdash
      \text{zero}*\text{unit}
      \sqsubseteq
      \begin{array}[]{@{} l}
        \text{zero}*\text{unit}\ \vee
        \arcr
        \text{succ}*nat
      \end{array}
    }
    \\
    \inferrule* {
      \inferrule* {
        \inferrule* {
          \inferrule* {
            \inferrule* {
              \vdots
            } { 
              \oslash \vdash
              \text{succ}*nat 
              \sqsubseteq
              \text{succ}*nat 
            }
          } { 
            \oslash \vdash
            \text{succ}*nat 
            \sqsubseteq
            \begin{array}[]{@{} l}
              \text{zero}*\text{unit}\ \vee
              \arcr
              \text{succ}*nat
            \end{array}
          }
        } { 
          \oslash \vdash
          \text{succ}*nat
          \sqsubseteq
          nat
        }
      } { 
        \oslash \vdash
        \text{succ}*\text{succ}*nat
        \sqsubseteq
        \text{succ}*nat
      }
    } { 
      \oslash \vdash
      \text{succ}*\text{succ}*nat
      \sqsubseteq
      \begin{array}[]{@{} l}
        \text{zero}*\text{unit}\ \vee
        \arcr
        \text{succ}*nat
      \end{array}
    }
  } { 
    \oslash \vdash
    \begin{array}[]{@{} l @{}}
      \text{zero}*\text{unit}\ \vee
      \arcr
      \text{succ}*\text{succ}*nat
    \end{array}
    \sqsubseteq
    \begin{array}[]{@{} l}
      \text{zero}*\text{unit}\ \vee
      \arcr
      \text{succ}*nat
    \end{array}
  }
} { 
  \oslash \vdash
  even \sqsubseteq nat
}
\end{mathpar}

Notice that the natural numbers are substituted in for the inductively bound variable  
for both the even number type and the natural number type.
We justify this manipulation by the induction hypothesis $even \sqsubseteq nat$. 


By augmenting quantified types with fairly general constraints, 
we will be able to express relational types, using the same three forms
of type abstraction.  

\hfill

\subsection{Constrained by widening}

The key insight that enables relations to be defined with existing type constructs,
is to constrain bound variables of quantified types using subtyping constraints,
such that those subtyping constraints may refer to (co)inductive variables.
For example, consider the specification of pairs of a list and a number, such that
the number equals the length of its corresponding list.

\[
nat\_and\_list(\alpha) =  
\begin{array}[t]{@{} l}
\mu\ \text{P}\ . 
\\
\hspace{4mm}\text{zero}*\text{unit} \times \text{nil}*\text{unit}\ \vee\ 
\\
\hspace{4mm}\exists\ \text{N}\ \text{XS} :: \text{N} \times \text{XS} \sqsubseteq \text{P}\ .\ 
\\
\hspace{8mm}\text{succ}*\text{N} \times \text{cons}*(\alpha \times \text{XS})
\end{array}
\]

Now suppose we have a function that expects a list and number satisfying a list-number relation.
\[
  \begin{array}[]{@{} l}
  \text{let}\ \text{foo} : (\exists\ \text{X}\ .\ nat\_and\_list(\text{X})) \rightarrow \text{unit} = \lambda\ (\text{n}, \text{l})\ .\ \_\ \text{in}
  \arcr
  (\text{foo}\ (\text{succ};\text{zero};(), \text{cons};((),\text{nil};())))
  \end{array}
\]

\noindent
Applying the function that expects the relation between lists and numbers 
to the argument generates a corresponding subtyping constraint, 
which the system attempts to solve. We define the type environment a type environment abbreviation.
\[
\Delta_{nl} = \oslash, 
  \text{X} \mapsto \text{unit},
  \text{N} \mapsto \text{zero}*\text{unit}, 
  \text{XS} \mapsto \text{nil}*\text{unit}
\]
\noindent
A successful trace of the decision algorithm corresponds to the subtyping derivation in fig. ? .  

\noindent
\begin{figure*}[h]
\begin{mathpar}
\inferrule* {
  \inferrule* { 
    \inferrule* { 
      \inferrule* { 
        \vdots
      } {
        \Delta_{nl} \vdash
        \begin{array}[]{@{} l @{}}
        (\text{succ}*\text{zero}*\text{unit})\ \times 
        \arcr
        (\text{cons}*(\text{unit} \times \text{nil}*\text{unit}))
        \end{array}
        \sqsubseteq
        \begin{array}[]{@{} l @{}}
        \text{succ}*\text{N}\ \times 
        \arcr
        \text{cons}*(\text{X} \times \text{XS})
        \end{array}
      }
      \\
      \inferrule* { 
        \inferrule* { 
          \vdots
        } {
          \Delta_{nl} \vdash
          \text{N} \times \text{XS} \sqsubseteq 
          \text{zero}*\text{unit} \times \text{nil}*\text{unit}
        }
      } {
        \Delta_{nl} \vdash
        \text{N} \times \text{XS} \sqsubseteq nat\_and\_list(\text{X})
      }
    } {
      \oslash, \text{X} \mapsto \text{unit} \vdash
      \begin{array}[]{@{} l @{}}
        (\text{succ}*\text{zero}*\text{unit})\ \times 
        \arcr
        (\text{cons}*(\text{unit} \times \text{nil}*\text{unit}))
      \end{array}
      \sqsubseteq
      \begin{array}[]{@{} l}
        \exists\ \text{N}\ \text{XS} :: (\text{N} \times \text{XS}) \sqsubseteq nat\_and\_list(\text{X}) 
        \arcr
        \hspace{4mm}\text{succ}*\text{N} \times \text{cons}*(\text{X} \times \text{XS})
      \end{array}
      }
  } { 
    \oslash, \text{X} \mapsto \text{unit} \vdash
    \begin{array}[]{@{} l @{}}
      (\text{succ}*\text{zero}*\text{unit})\ \times 
      \arcr
      (\text{cons}*(\text{unit} \times \text{nil}*\text{unit}))
    \end{array}
    \sqsubseteq
    \begin{array}[]{@{} l}
      \text{zero}*\text{unit} \times \text{nil}*\text{unit}\ \vee\ 
      \arcr
      \exists\ \text{N}\ \text{XS} :: (\text{N} \times \text{XS}) \sqsubseteq nat\_and\_list(\text{X})
      \arcr
      \hspace{4mm}\text{succ}*\text{N} \times \text{cons}*(\text{X} \times \text{XS})
    \end{array}
  }
} { 
  \oslash \vdash
  (\text{succ}*\text{zero}*\text{unit}) \times (\text{cons}*(\text{unit} \times \text{nil}*\text{unit}))
  \sqsubseteq
  \exists\ \text{X}\ .\ nat\_and\_list(\text{X})
}
\end{mathpar}
\caption{}
\end{figure*}

We can also specify a relation between even numbers and lists.  

\[
even\_and\_list(\alpha) =  
\begin{array}[t]{@{} l}
  \mu\ \text{P}\ .\ 
  \\
  \hspace{4mm}\text{zero}*\text{unit} \times \text{nil}*\text{unit}\ \vee\ 
  \\
  \hspace{4mm}\exists\ \text{N}\ \text{XS} :: \text{N} \times \text{XS} \sqsubseteq \text{P}\ .\ 
  \\
  \hspace{8mm}\text{succ}*\text{succ}*\text{N}\ \times 
  \\
  \hspace{12mm}\text{cons}*(\alpha \times \text{cons}*(\alpha \times \text{XS}))
\end{array}
\]

We verify that the even relation is included in the natural number relation to lists.  
Shown in fig. ?.

\[
\Delta_{enl} = \oslash,\ 
\begin{array}[t]{@{} l}
  \text{N} \times \text{XS} \mapsto nat\_and\_list(\text{X}),\ 
  \\
  \text{XS'} \mapsto \text{cons}*(\text{X} \times \text{XS}),\ 
  \\
  \text{N'} \mapsto \text{succ}*\text{N}
\end{array}
\]

\begin{figure*}[h]
  
\begin{mathpar}
\inferrule* {
  \inferrule* {
    \vdots
    \\
    \inferrule* {
      \inferrule* {
        \inferrule* {
          \inferrule* {
            \Delta_{enl}(\text{N} \times \text{XS}) = nat\_and\_list(\text{X})
          } {
            \Delta_{enl} \vdash
            \text{N} \times \text{XS} \sqsubseteq nat\_and\_list(\text{X})
          }
        } {
          \vdots
        }
      } {
        \Delta_{enl} \vdash
        \text{succ}*\text{N} \times \text{cons}*\text{XS} \sqsubseteq nat\_and\_list(\text{X})
      }
      \\
      \Delta_{enl}(\text{N'}) = \text{succ}*\text{N}
      \\
      \Delta_{enl}(\text{XS'}) = \text{cons}*(\text{X} \times \text{XS})
    } {
      \Delta_{enl} \vdash
      \text{N'} \times \text{XS'} \sqsubseteq nat\_and\_list(\text{X})
    }
  } {
    \oslash \vdash
    \begin{array}[]{@{} l @{}}
      \text{zero}*\text{unit} \times \text{nil}*\text{unit}\ \vee\ 
      \arcr
      \exists\ \text{N}\ \text{XS} :: \text{N} \times \text{XS} \sqsubseteq nat\_and\_list(\text{X})\ .\ 
      \arcr
      \hspace{4mm}\text{succ}*\text{succ}*\text{N} \times \text{cons}*(\text{X} \times \text{cons}*(\text{X} \times \text{XS}))
    \end{array}
    \sqsubseteq
    \begin{array}[]{@{} l @{} }
      \text{zero}*\text{unit} \times \text{nil}*\text{unit}\ \vee\ 
      \arcr
      \exists\ \text{N}\ \text{XS} :: \text{N} \times \text{XS} \sqsubseteq nat\_and\_list(\text{X})\ .\ 
      \arcr
      \hspace{4mm}\text{succ}*\text{N} \times \text{cons}*(\text{X} \times \text{XS})
    \end{array}
  }
} { 
  \oslash \vdash
  even\_and\_list(\text{X})
  \sqsubseteq
  nat\_and\_list(\text{X})
}
\end{mathpar}
\caption{}
\end{figure*}



\subsection{Constrained by narrowing}
The system of type is also expressive enough to precisely specify
sets of functions, where each function's output depends on its input.

Consider the set of functions, where each function takes as input a natural number $n$
and an element, and returns a list of $n$ elements.

\[
  nat\_to\_list = 
  \begin{array}[t]{@{} l}
    \forall\ \text{X}\ .\ \text{X} \rightarrow \nu\ \text{I}\ .\ 
    \arcr
    \hspace*{4mm}\text{zero}*\text{unit} \rightarrow \text{nil}*\text{unit}\ \sqcap
    \arcr
    \hspace*{4mm}\forall\ \text{N}\ \text{XS} :: \text{I} \sqsubseteq \text{N} \rightarrow \text{XS}\ .\ 
    \arcr
    \hspace*{8mm}\text{succ}*\text{N} \rightarrow \text{cons}*(\text{X} \times \text{XS})
  \end{array}
\]


\noindent The type $nat\_to\_list$ uses three forms of type abstraction: 
universal types, intersection types, and co-inductive types. 
These three forms of type abstraction
are respectively the duals of existential types, union types, and inductive types. 

Universal and co-inductive types are ways to specify the infinite intersection
of types indexed by some variable. Although, it is technically possible to specify
the infinite intersection of arbitrary types, it is only the function types
that can represent meaningful non-empty sets of values across infinite intersections.
Thus, in practice, we are only considered with universal and co-inductive types, when
they compose implication types.
In order to propagate types top-down and also reuse mechanisms for the dual concepts of type abstraction,
the decision algorithm rewrites inductive types into \emph{implication-normal-form}.
We define an abbreviation for the natural numbers.
\[
nat = 
\begin{array}[t]{@{} l}
  \mu\ \text{N}\ .\ 
  \arcr
  \hspace{4mm}\text{zero}*\text{unit}\ \vee
  \arcr
  \hspace{4mm}\exists\ \text{X}\ .\ \text{succ}*\text{N}
\end{array}
\]
Using natural numbers and the relation between numbers and lists,
we redefine set of functions from numbers to lists.
\[
  nat\_to\_list' = 
  \begin{array}[t]{@{} l}
    \forall\ \text{X}\ .\ \text{X} \rightarrow \forall\ \text{N}\ :: \text{N} \sqsubseteq nat\ .\ 
    \arcr
    \hspace*{4mm}\text{N} \rightarrow 
    (\exists\ \text{XS} :: \text{N} \times \text{XS} \sqsubseteq nat\_and\_list\ .\ \text{XS})
  \end{array}
\]


\noindent The term for \lstinline{replicate} could be represented by a recursive function built using \lstinline{fix} 

\begin{lstlisting}[]
let replicate = 
$\lambda$ x $\Rightarrow$ fix ($\lambda$ self $\Rightarrow$ $\lambda$ [
  (zero;() $\Rightarrow$ nil;()),
  (succ;n $\Rightarrow$ cons;(x, self n))
]) 
\end{lstlisting}


\newpage

\section{Language}

% \begin{theorem}(Soundness of type analysis)
% \begin{mathpar}
%   \inferrule {} {
%     \alpha\ \llbracket e \rrbracket^\flat \supseteq \llbracket e \rrbracket^\sharp
%     \longleftrightarrow
%     \llbracket e \rrbracket^\flat \subseteq \gamma\ \llbracket e \rrbracket^\sharp
%   } 
% \end{mathpar}
% \end{theorem}

\begin{theorem}(Progress of typing)
\begin{mathpar}
  \inferrule { 
    \oslash \vdash e : \tau
  } {
    (e = v) \vee 
    e \hookrightarrow e'
  } 
\end{mathpar}
\end{theorem}


\begin{theorem}(Preservation of typing)
\begin{mathpar}
  \inferrule { 
    \oslash \vdash e : \tau
    \\
    e \hookrightarrow e'
  } {
    \oslash \vdash e' : \tau
  } 
\end{mathpar}
\end{theorem}


\begin{figure*}[h]
\[
  \begin{array}{l @{} l}
    e 
    &{} ::=
    \begin{array}[t]{@{} l}
      () 
      \ |\ 
      l \cdot e 
      \ |\ 
      \sigma\ \widebar{l = e}
      \ |\ 
      \lambda\ \widebar{m \Rightarrow e} 
      \ |\ 
      e/l
      \ |\ 
      e\ e 
      \ |\ 
      \text{fix}\ e
      \ |\ 
      \text{let}\ x : \tau = e\ \text{in}\ e
      \ |\ 
      x
    \end{array}
    \\
    m 
    &{} ::=
    \begin{array}[t]{@{} l}
      x 
      \ |\ 
      () 
      \ |\ 
      l \cdot m 
      \ |\ 
      \sigma\ \widebar{l = m}
    \end{array}
    \\
    \tau
    &{} ::=
    \begin{array}[t]{@{} l}
      \text{unit} 
      \ |\ 
      \alpha 
      \ |\ 
      l*\tau 
      \ |\ 
      l:\tau 
      \ |\ 
      \tau\rightarrow\tau 
      \ |\ 
      \left<\exists \widebar{\alpha}\ .\ \tau\ |\ \tau \sqsubseteq \tau\right>
      \ |\ 
      \left<\forall \widebar{\alpha}\ .\ \tau\ |\ \tau \sqsubseteq \tau\right>
      \ |\ 
      \mu \alpha.\tau 
      \ |\ 
      \nu \alpha.\tau 
      \ |\ 
      \tau \vee \tau
      \ |\ 
      \tau \sqcap \tau
    \end{array}
  \end{array}
\]

\caption{Syntax}
\end{figure*}

% \begin{figure*}[h]
% \begin{flalign*}
%   &\boxed{ e \in \llbracket e \rrbracket^\flat}&
% \end{flalign*}
% \begin{mathpar}
%   \inferrule { 
%     e
%     \hookrightarrow^* 
%     e'
%   } {
%     e' \in \llbracket e \rrbracket^\flat
%   } 
% \end{mathpar}
% \caption{Collecting semantics}
% \end{figure*}

% \begin{figure*}
% \begin{flalign*}
%   &\boxed{ \varsigma \in \llbracket e \rrbracket^\flat}&
% \end{flalign*}
% \begin{mathpar}
%   \inferrule { 
%     \left<\circ, \rho, e \right> 
%     \hookrightarrow^* 
%     \varsigma
%   } {
%     \varsigma \in \llbracket e \rrbracket^\flat
%   } 
% \end{mathpar}
% \caption{Collecting semantics}
% \end{figure*}

% \begin{figure*}[h]
% \begin{flalign*}
%   &\boxed{\varsigma \in \gamma\ T}&
% \end{flalign*}
% \begin{mathpar}
%   \inferrule { 
%     \forall\ \tau \in T\ .\ \oslash \vdash e : \tau
%   } {
%     e \in \gamma\ T 
%   } 
% \end{mathpar}
% \caption{Concretization}
% \end{figure*}

% \begin{figure*}[h]
% \begin{flalign*}
%   &\boxed{\tau \in \alpha\ P}&
% \end{flalign*}
% \begin{mathpar}
%   \inferrule { 
%     \exists\ e \in P\ .\ \oslash \vdash e : \tau
%   } {
%     \tau \in \alpha\ P 
%   } 
% \end{mathpar}
% \caption{Abstraction}
% \end{figure*}


% TODO: replace (type variables / unification) (top/bottom and widening/narrowing) 
% abstract out widening/narrowing operators in unification
% we don't have fixed point recursion, but structural recursion terminates as subtyping squeezes.
% i.e. we don't compare current to previous, we simply look at structure of input.
% the structure of input decreases as types widen/narrow
% \begin{figure*}[h]
% \begin{flalign*}
%   &\boxed{\tau \in \llbracket e \rrbracket^\sharp}&
% \end{flalign*}
% \begin{mathpar}
%   \inferrule { 
%     \Delta \cdot \oslash \Vdash e : \tau \sqsubseteq \top
%   } {
%     (\text{pack}\ \Delta\ \tau) \in \llbracket e \rrbracket^\sharp
%   }
% \end{mathpar}
% \caption{Type analysis}
% \end{figure*}
% note: Cousot defines concretization by calling runtime semantics
% this is a bit odd as it could be non-terminating
% he seems to have some magical way to decide termination
% typing rules don't require calling runtime semantics,
% they are purely driven by the ast structure.



\begin{figure*}[h]
\begin{flalign*}
  &\boxed{e \hookrightarrow e}&
\end{flalign*}
\begin{mathpar}
  \inferrule { 
    e \hookrightarrow e' 
  } {
    E[e] \hookrightarrow E[e']  
  }

  \inferrule {
  } {
    (\sigma\ \widebar{l_i = v_i})/l_j \hookrightarrow v_j
  } 

  \inferrule { 
  } {
    (\lambda\ \widebar{m \Rightarrow e})\ v 
    \hookrightarrow 
    (\text{match } v\ \widebar{m \Rightarrow e})
  } 

  \inferrule { 
  } {
    \text{let}\ x : \tau = v\ \text{in}\ e 
    \hookrightarrow 
    t[x \mapsto v]
  } 

  \inferrule { 
  } {
    \text{fix}\ \lambda [x \Rightarrow e]
    \hookrightarrow 
    e[x \mapsto \text{fix}\ \lambda [x \Rightarrow e]]
  } 
\end{mathpar}
\caption{Operational semantics}
\end{figure*}

\begin{figure*}[h]
\begin{flalign*}
  &\boxed{\text{match}\ v\ (\widebar{m \Rightarrow t}) = H}&
\end{flalign*}
\[
  \begin{array}{l @{} l}
    \text{match}\ v\ ((m \Rightarrow t) :: cs)
    &{} =
    \begin{cases}
      t[H]
      &\text{if }
      (\text{unify}\ v\ p) = H 
      \\
      
      \text{match}\ v\ cs
      &\text{otherwise}
    \end{cases}
  \end{array}
\]
\end{figure*}

\begin{figure*}[h]
\begin{flalign*}
  &\boxed{\text{unify}\ v\ p = H}&
\end{flalign*}
\[
  \begin{array}{l @{} l}
    \text{unify}\ v\ x 
    &{} =
    \oslash, x \mapsto v
    \\
    \text{unify}\ ()\ () 
    &{} =
    \oslash
    \\
    \text{unify}\ (l \cdot v)\ (l \cdot p) 
    &{} =
    \text{unify}\ v\ p
    \\
    \text{unify}\ (\sigma\ \widebar{l = v})\ (\sigma\ \widebar{l = p}) 
    &{} =
    \text{reduce}\ ;\ \widebar{\text{unify}\ v\ p}
  \end{array}
\]
\end{figure*}

\begin{figure*}[h]
\[
  \begin{array}{l @{} l}
    v 
    &{} ::=
    \begin{array}[t]{@{} l}
      () 
      \ |\ 
      l \cdot v
      \ |\ 
      \sigma\ \widebar{l = v}
      \ |\ 
      \lambda\ \widebar{m \Rightarrow t} 
    \end{array}
    \\
    E 
    &{} ::=
    []
    \ |\ 
    l \cdot E 
    \ |\ 
    \sigma\ \widebar{l = E}
    \ |\ 
    E/l
    \ |\ 
    E\ e 
    \ |\ 
    v\ E
    \ |\ 
    \text{let } x : \tau = E\ \text{in}\ e 
    \ |\ 
    \text{fix } E 
    \\
    H 
    &{} ::=
    \oslash
    \ |\ 
    H, x \mapsto v
  \end{array}
\]
\caption{Operational structures}
\end{figure*}
  

% \begin{figure*}
% \begin{flalign*}
%   &\boxed{\varsigma \hookrightarrow \varsigma}&
% \end{flalign*}
% \begin{mathpar}

%   \inferrule { 
%     \rho\ x' = \left< \rho', (\sigma\ \widebar{l_i = _i}) \right> 
%   } {
%     \left<\kappa, \rho, x' / l_j \right> 
%     \hookrightarrow 
%     \left< \kappa, \rho', x_j \right>
%   } 

%   \inferrule { 
%     \rho\ x_1 = \left< \rho_1, \lambda\ \widebar{m \Rightarrow e} \right> 
%     \\
%     \rho\ x_2 = \left< \rho_2, w \right>
%     \\
%     \text{match}\ \rho_2\ w\ \rho_1\ (\widebar{m \Rightarrow e}) = \left<\rho', e'\right> 
%   } {
%     \left< \kappa, \rho, x_1\ x_2 \right> 
%     \hookrightarrow 
%     \left< \kappa, \rho', e' \right>
%   } 

%   \inferrule { 
%     \rho\ x = \lambda[x' \Rightarrow e]
%   } {
%     \left< 
%       \left< \rho_\kappa, x_\kappa, e_\kappa \right> :: \kappa, 
%       \rho, 
%       \text{fix}\ x
%     \right> 
%     \hookrightarrow 
%     \left< \kappa, (\rho,x_\kappa \mapsto \text{fix}\ x), e'[x' \mapsto x_\kappa]\right>
%   } 
  
%   \inferrule { 
%   } {
%     \left< \kappa, \rho, \text{let}\ x : \tau = e_1\ \text{in}\ e_2 \right> 
%     \hookrightarrow 
%     \left< \left<\rho, x, e_2\right> :: \kappa, \rho, e_1 \right>
%   } 

%   \inferrule { 
%   } {
%     \left<
%       \left<\rho_\kappa, x_\kappa, e\right> :: \kappa,
%       \rho, 
%       x 
%     \right> 
%     \hookrightarrow 
%     \left<\kappa, (\rho_\kappa, x_\kappa \mapsto (\rho\ x)), e \right>
%   } 

%   \inferrule { 
%     \text{contify}\ e = (x, e', e'')
%   } {
%     \left<\kappa, \rho, e\right> 
%     \hookrightarrow 
%     \left<
%       \left< \rho, x, e'\right> :: \kappa,
%       \rho,
%       e''
%     \right>
%   } 

% \end{mathpar}
% \caption{Small-step semantics}
% \end{figure*}


% \begin{figure*}
% \begin{flalign*}
%   &\boxed{\text{contify}\ e = (x, e, c)}&
% \end{flalign*}
% \[
% \begin{array}{l @{} l}
%   % \text{contify} l \cdot c 
%   % &{} =
%   % c
%   % \\
%   % \text{contify} l \cdot c 
%   % &{} =
%   % c

%       % () 
%       % \ |\ 
%       % l \cdot e 
%       % \ |\ 
%       % \sigma\ \widebar{l = e}
%       % \ |\ 
%       % \lambda\ \widebar{m \Rightarrow e} 
%       % \ |\ 
%       % e/l
%       % \ |\ 
%       % e\ e 
%       % \ |\ 
%       % \text{fix}\ e
%       % \ |\ 
%       % \text{let}\ x : \tau = e\ \text{in}\ e
%       % \ |\ 
%       % x
% \end{array}
% \]

% \caption{Contification}
% \end{figure*}

\begin{figure*}[h]
\begin{flalign*}
  &\boxed{e \hookrightarrow^* e}&
\end{flalign*}
\begin{mathpar}
  \inferrule { 
  } {
    e \hookrightarrow^* e
  } 

  \inferrule { 
    e \hookrightarrow e'
    \\
    e' \hookrightarrow^* e''
  } {
    e \hookrightarrow^* e''
  } 
\end{mathpar}
\caption{Multi-step semantics}
\end{figure*}


% \begin{figure*}
% \begin{flalign*}
%   &\boxed{\varsigma \hookrightarrow^* \varsigma}&
% \end{flalign*}
% \begin{mathpar}
%   \inferrule { 
%   } {
%     \varsigma \hookrightarrow^* \varsigma
%   } 

%   \inferrule { 
%     \varsigma \hookrightarrow \varsigma'
%     \\
%     \varsigma' \hookrightarrow^* \varsigma''
%   } {
%     \varsigma \hookrightarrow^* \varsigma''
%   } 
% \end{mathpar}
% \caption{Multi-step semantics}
% \end{figure*}

% \begin{figure*}
% \[
%   \begin{array}{l @{} l}
%     \kappa 
%     &{} ::=
%     \begin{array}[t]{@{} l}
%       \left< \rho, x, e \right> :: \kappa 
%       \ |\ 
%       \circ
%     \end{array}
%     \\
%     \widebar{\left< \rho, x, e \right>}
%     &{} ::=
%     \begin{array}[t]{@{} l}
%       \left< \rho, x, e \right> ::  \widebar{\left< \rho, x, e \right>}
%       \ |\ 
%       \circ
%     \end{array}
%     \\
%     \rho 
%     &{} ::=
%     \begin{array}[t]{@{} l}
%       \oslash 
%       \ |\ 
%       \rho, x \mapsto \left< \rho, w \right> 
%     \end{array}
%     \\
%     w 
%     &{} ::=
%     \begin{array}[t]{@{} l}
%       () 
%       \ |\ 
%       l \cdot x 
%       \ |\ 
%       \sigma\ \widebar{l = x}
%       \ |\ 
%       \lambda\ \widebar{m \Rightarrow e} 
%     \end{array}
%   \end{array}
% \]
% \caption{Internal state}
% \end{figure*}


% \begin{figure*}
% \begin{flalign*}
%   &\boxed{\Gamma \vdash \varsigma : \tau}&
% \end{flalign*}
% \begin{mathpar}
%   \inferrule { 
%     \Gamma \vdash \rho
%     \\
%     \Gamma \vdash e : \tau
%     \\
%     \kappa \vdash \tau \triangleright \tau' 
%   } {
%     \Gamma \vdash 
%       \left< \kappa, \rho, e \right> 
%     : \tau'
%   } 
% \end{mathpar}
% \caption{State typing}
% \end{figure*}

\begin{figure*}[h]
\begin{flalign*}
  &\boxed{\Gamma \vdash e : \tau}&
\end{flalign*}
\begin{mathpar}
  \inferrule { 
  } {
    \Gamma \vdash () 
    : \text{unit}
  } 

  \inferrule { 
    \Gamma(x) = \tau
  } {
    \Gamma \vdash x
    : \tau 
  } 

  \inferrule { 
    \Gamma \vdash t
    : \tau 
  } {
     \Gamma \vdash (l;t) 
    : l*\tau
  }

  \inferrule { 
    \Gamma \vdash t_i :  \tau_i  
  } {
    \Gamma \vdash (\sigma\ \widebar{l_i = t_i})
    : (\sqcap\ \widebar{l_i : \tau_i})
  } 

  \inferrule {
    \Gamma_i \vdash p_i : \tau_i
    \\
    \Gamma;\Gamma_i \vdash t_i
    : \tau'_i
  } {
    \Gamma \vdash (\lambda\ \widebar{m_i \Rightarrow e_i})
    : (\sqcap\ \widebar{\tau_i \rightarrow \tau'_i })  
  } 

  \inferrule {
    \Gamma \vdash t : (l:\tau)
  } {
    \Gamma \vdash (t/l) : \tau
  } 

  \inferrule { 
    \Gamma \vdash t_1
    : \tau' \rightarrow \tau
    \\
    \Gamma \vdash t_2
    : \tau'
  } {
    \Gamma \vdash (t_1\ t_2)
    \
    : \tau
  } 

  \inferrule { 
    \oslash \vdash 
    \left<\forall \widebar{\alpha}\ .\ \tau_5\ |\ \tau_3 \sqsubseteq \tau_4\right>
    \sqsubseteq \tau_1
    \\
    \Gamma \vdash t_1
    : \tau_1
    \\\\
    \Gamma,x \mapsto \left<\forall \widebar{\alpha}\ .\ \tau_5\ |\ \tau_3 \sqsubseteq \tau_4\right>
      \vdash t_2 
    : \tau_2
  } {
    \Gamma \vdash (\text{let}\ x : \tau_1 = t_1 \text{ in } t_2) 
    : \tau_2
  } 

  \inferrule { 
    \Gamma \vdash t
    : \tau \rightarrow \tau
  } {
    \Gamma \vdash \text{fix}\ t 
    :\tau
  } 

  \inferrule { 
    \Gamma \vdash t 
    : \tau' 
    \\
    \oslash \vdash \tau' \sqsubseteq \tau
  } {
    \Gamma \vdash t
    : \tau
  } 
\end{mathpar}
\caption{Typing}
\end{figure*}

\begin{figure}[h]
\begin{flalign*}
  &\boxed{\Gamma\ x = \tau}&
\end{flalign*}
\[
  \begin{array}{l @{} l}
    (\Gamma, x \mapsto \tau)\ x'
    &{} =
    \begin{cases}
      \tau
      &\text{if } x = x' 
      \\
      \Gamma\ x' 
      &\text{otherwise}
    \end{cases}
  \end{array}
\]
\caption{Type environment find}
\end{figure}

\begin{figure}[h]
\begin{flalign*}
  &\boxed{x \in \text{dom}\ \Gamma}&
\end{flalign*}
\begin{mathpar}
  \inferrule { 
  } {
    x \in \text{dom}\ (\Gamma, x \mapsto \tau)
  } 

  \inferrule { 
    x \neq x'
    \\
    x \in \text{dom}\ \Gamma
  } {
    x \in \text{dom}\ (\Gamma, x' \mapsto \tau')
  } 
\end{mathpar}
\caption{Type environment domain}
\end{figure}

\begin{figure*}[h]
\begin{flalign*}
  &\boxed{\Delta \vdash \tau \sqsubseteq \tau}&
\end{flalign*}

\begin{mathpar}
  \inferrule {
  } {
    \Delta \vdash \text{unit} \sqsubseteq \text{unit}
  }

  \inferrule {
    \Delta \vdash \tau_1
    \sqsubseteq \tau_2
  } {
    \Delta \vdash l*\tau_1
    \sqsubseteq l*\tau_2
  } 

  \inferrule {
    \Delta \vdash \tau_1
    \sqsubseteq \tau_2
  } {
    \Delta \vdash l:\tau_1
    \sqsubseteq l:\tau_2
  } 

  \inferrule {
    \Delta \vdash \tau_3
    \sqsubseteq \tau_1
    \\
    \Delta \vdash \tau_2
    \sqsubseteq \tau_4
  } {
    \Delta \vdash \tau_1 \rightarrow \tau_2
    \sqsubseteq \tau_3 \rightarrow \tau_4
  } 
  \\
  \inferrule {
    \Delta \vdash \tau_1
    \sqsubseteq \tau_3
    \\
    \Delta \vdash \tau_2
    \sqsubseteq \tau_3
  } {
    \Delta \vdash \tau_1 \sqcup \tau_2
    \sqsubseteq \tau_3
  }

  \inferrule {
  } {
    \Delta \vdash \tau_1
    \sqsubseteq \tau_1 \sqcup \tau_2
  }

  \inferrule {
  } {
    \Delta \vdash \tau_2
    \sqsubseteq \tau_1 \sqcup \tau_2
  }
  \\
  \inferrule {
    \Delta \vdash \tau
    \sqsubseteq \tau_1
    \\
    \Delta \vdash \tau
    \sqsubseteq \tau_2
  } {
    \Delta \vdash \tau
    \sqsubseteq \tau_1 \sqcap \tau_2
  }

  \inferrule {
  } {
    \Delta \vdash \tau_1 \sqcap \tau_2
    \sqsubseteq \tau_1
  }

  \inferrule {
  } {
    \Delta \vdash \tau_1 \sqcap \tau_2
    \sqsubseteq \tau_2
  }
\end{mathpar}
\caption{Subtyping: standard rules}
\end{figure*}

\begin{figure*}[h]
\begin{flalign*}
  &\boxed{\Delta \vdash \tau \sqsubseteq \tau}&
\end{flalign*}

\begin{mathpar}
  \inferrule { 
    (\text{freevars}\ \Delta) \cap \widebar{\alpha_i} \subseteq \emptyset 
    \\\\
    \bigwedge\nolimits_{\Delta'}
    (\Delta;\Delta' \vdash \tau_1 \sqsubseteq \tau_2)
    \longrightarrow
    (\Delta;\Delta' \vdash \tau_3 \sqsubseteq \tau_4)
  } { 
    \Delta \vdash \left<\exists \widebar{\alpha_i}\ .\ \tau_3\ |\ \tau_1 \sqsubseteq \tau_2\right>
    \sqsubseteq \tau_4
  }

  \inferrule { 
    (\text{freevars}\ \Delta) \cap \widebar{\alpha_i} \subseteq \emptyset 
    \\\\
    \Delta;\Delta' \vdash \tau_1
    \sqsubseteq \tau_4
    \\
    \Delta;\Delta' \vdash \tau_2
    \sqsubseteq \tau_3
  } { 
    \Delta \vdash \tau_1
    \sqsubseteq \left<\exists \widebar{\alpha_i}\ .\ \tau_4\ |\ \tau_2 \sqsubseteq \tau_3\right>
  }

  \inferrule { 
    (\text{freevars}\ \Delta) \cap \widebar{\alpha_i} \subseteq \emptyset 
    \\\\
    \bigwedge\nolimits_{\Delta'}
    (\Delta;\Delta' \vdash \tau_2 \sqsubseteq \tau_3)
    \longrightarrow
    (\Delta;\Delta' \vdash \tau_1 \sqsubseteq \tau_4)
  } { 
    \Delta \vdash \tau_1
    \sqsubseteq \left<\forall \widebar{\alpha_i}\ .\ \tau_4\ |\ \tau_2 \sqsubseteq \tau_3\right>
  }

  \inferrule { 
    (\text{freevars}\ \Delta) \cap \widebar{\alpha_i} \subseteq \emptyset 
    \\\\
    \Delta;\Delta' \vdash \tau_3
    \sqsubseteq \tau_4
    \\
    \Delta;\Delta' \vdash \tau_1
    \sqsubseteq \tau_2
  } { 
    \Delta \vdash \left<\forall \widebar{\alpha_i}\ .\ \tau_3\ |\ \tau_1 \sqsubseteq \tau_2\right>
    \sqsubseteq \tau_4
  }
  \\
  \inferrule { 
    \Delta \vdash \tau_1[\alpha_1\mapsto\mu\alpha_2.\tau_2]
    \sqsubseteq \tau_2[\alpha_2\mapsto\mu\alpha_2.\tau_2]
  } { 
    \Delta \vdash \mu \alpha_1 . \tau_1
    \sqsubseteq \mu \alpha_2 . \tau_2
  }

  \inferrule {
  } {
    \Delta \vdash \tau[\alpha\mapsto\mu \alpha . \tau]
    \sqsubseteq \mu \alpha . \tau
  }

  \inferrule {
  } {
    \Delta \vdash \mu\alpha.\tau
    \sqsubseteq \tau[\alpha\mapsto\mu \alpha . \tau]
  }

  \inferrule { 
    \Delta \vdash \tau_1[\alpha_1\mapsto\nu\alpha_1.\tau_1] 
    \sqsubseteq \tau_2[\alpha_2\mapsto\nu\alpha_1.\tau_1]
  } {
    \Delta \vdash \nu \alpha_1 . \tau_1 
    \sqsubseteq \nu \alpha_2 . \tau_2
  }

  \inferrule {
  } {
    \Delta \vdash \tau[\alpha\mapsto\nu \alpha . \tau]
    \sqsubseteq \nu \alpha . \tau
  }

  \inferrule {
  } {
    \Delta \vdash \nu\alpha.\tau
    \sqsubseteq \tau[\alpha\mapsto\nu \alpha . \tau]
  }
\end{mathpar}
\caption{Subtyping: extended rules}
\end{figure*}


% \begin{figure*}[h]
% \begin{flalign*}
%   &\boxed{\Delta \vdash \tau \sqsubseteq \tau}&
% \end{flalign*}
% TODO: convert between conjunction of functions to implication normal form
% \begin{mathpar}
%   % this rule is too coarse; we should craft a more precise rule using predicate types
%   % \inferrule {
%   % } {
%   %   \Delta \vdash 
%   %   (\tau_1 \rightarrow \tau_3) \sqcap  (\tau_2 \rightarrow \tau_4)
%   %   \sqsubseteq
%   %   (\tau_1 \sqcup \tau_2) \rightarrow (\tau_3 \sqcap \tau_4)
%   % }
% \end{mathpar}
% \caption{Subtyping: relational types}
% \end{figure*}

% we don't have fixed point recursion, but structural recursion terminates as subtyping squeezes.
% i.e. we don't compare current to previous, we simply look at structure of input.
% the structure of input decreases as types widen/narrow
\begin{figure*}[h]
\begin{flalign*}
  &\boxed{\Delta \cdot \Gamma \Vdash e : \tau}&
\end{flalign*}

\begin{mathpar}
  \inferrule { 
    (\Gamma\ x) = \tau
  } {
    \Delta \cdot \Gamma
    \Vdash x : \tau
  } 

  \inferrule { 
  } {
    \Delta \cdot \Gamma 
    \Vdash () : \text{unit}
  } 

  \inferrule { 
    \Delta \cdot \Gamma
    \Vdash e : \tau
  } {
    \Delta \cdot \Gamma 
    \Vdash (l \cdot e) : (l * \tau)
  } 

  \inferrule { 
    \bigwedge\nolimits_i\ \Delta \cdot \Gamma \Vdash e_i : \tau_i
  } {
    \Delta \cdot \Gamma
    \Vdash \sigma\ \widebar{l_i = e_i}^i : 
    \sqcap_i\ (l_i : \tau_i)
  } 

  \inferrule { 
    \bigwedge\nolimits_i\ \Delta \cdot \Gamma;\Gamma' \Vdash m_i : \tau'_i
    \\
    \bigwedge\nolimits_i\ \Delta \cdot \Gamma;\Gamma' \Vdash e_i : \tau''_i
  } {
    \Delta \cdot \Gamma
    \Vdash
    \lambda\ \widebar{m_i \Rightarrow e_i}^i : 
    \sqcap_i\ (\tau_i' \rightarrow \tau_i'') 
  } 

  \inferrule { 
    \Delta \cdot \Gamma \Vdash e : \tau
    \\
    \Delta \cdot \oslash \Vdash \tau \sqsubseteq (l : \alpha)
  } {
    \Delta \cdot \Gamma \Vdash (e/l) : \alpha
  } 

  \inferrule { 
    \\
    \Delta \cdot \Gamma \Vdash e_1 : \tau_1
    \\
    \Delta \cdot \Gamma \Vdash e_2 : \tau_2
    \\
    \Delta \cdot \oslash \Vdash \tau_1 \sqsubseteq \tau_2 \rightarrow \alpha
    \\
    % need to call unification one more time to liberate existentially quantified variables 
    \Delta \cdot \oslash \Vdash \alpha' \sqsubseteq \alpha
  } {
    \Delta \cdot \Gamma
    \Vdash (e_1\ e_2) : \alpha'
  } 

  \inferrule { 
    \Delta \cdot \Gamma \Vdash e_1 : \tau_1
    \\
    \Delta \cdot (\Gamma, x \mapsto \text{generalize}\ \Delta\ \tau_1)  \Vdash e_2 : \tau_2
    \\
  } {
    \Delta \cdot \Gamma 
    \Vdash 
    (\text{let}\ x : \tau_1 = e_1\ \text{in}\ e_2) : \tau_2
  } 

  \inferrule { 
    \Delta \cdot \Gamma \Vdash e : \tau \rightarrow \tau'
    \\
    \tau' = \sqcap_i \tau_i'
  } {
    \Delta;\Delta' \cdot \Gamma  
    \Vdash \text{fix}\ e :(\nu \alpha\ .\ \sqcap_i (\text{case}\ \alpha\ \tau\ \tau_i')) 
  } 

\end{mathpar}
\caption{Type inference.
  \newline
  Input: $\Delta \cdot \Gamma \Vdash e : \_ $. The input is the type variable environment, typing environment, and the expression.
  \newline
  Output: $\Delta \cdot \_ \Vdash \_ : \tau $. The output is the type variable environment and the result type.
}
\end{figure*}


% we don't have fixed point recursion, but structural recursion terminates as subtyping squeezes.
% i.e. we don't compare current to previous, we simply look at structure of input.
% the structure of input decreases as types widen/narrow
% \begin{figure*}[h]
% \begin{flalign*}
%   &\boxed{\Delta \cdot \Gamma \Vdash e : \tau \sqsubseteq \tau}&
% \end{flalign*}

% \begin{mathpar}
%   \inferrule { 
%     \Delta \cdot \oslash \Vdash (\Gamma\ x) \sqsubseteq \tau
%   } {
%     \Delta \cdot \Gamma
%     \Vdash x : (\Gamma\ x) \sqsubseteq \tau
%   } 

%   \inferrule { 
%     \Delta \cdot \oslash \Vdash \text{unit} \sqsubseteq \tau
%   } {
%     \Delta \cdot \Gamma 
%     \Vdash () : \text{unit} \sqsubseteq \tau
%   } 

%   \inferrule { 
%     \text{fresh}\ \alpha
%     \\
%     \Delta \cdot \oslash \Vdash (l * \alpha) \sqsubseteq \tau
%     \\
%     \Delta;\Delta' \cdot \Gamma
%     \Vdash e : \tau' \sqsubseteq \alpha
%   } {
%     \Delta;\Delta' \cdot \Gamma 
%     \Vdash (l \cdot e) : (l * \tau') \sqsubseteq \tau
%   } 

%   \inferrule { 
%     \text{fresh}\ \alpha_i
%     \\
%     \Delta \cdot \oslash \Vdash (\sqcap\ \widebar{l_i : \alpha_i}) \sqsubseteq \tau
%     \\
%     \Delta;\Delta' \cdot \Gamma
%     \Vdash e_i : \tau_i \sqsubseteq \alpha_i
%   } {
%     \Delta;\Delta' \cdot \Gamma
%     \Vdash (\sigma\ \widebar{l_i = e_i}) : 
%     (\sqcap\ \widebar{l_i : \tau_i}) \sqsubseteq \tau
%   } 

%   \inferrule { 
%     \text{fresh}\ \alpha_i'
%     \\
%     \text{fresh}\ \alpha_i''
%     \\
%     \Delta \cdot \oslash \Vdash (\sqcap\ \widebar{\alpha'_i \rightarrow \alpha''_i}) \sqsubseteq \tau
%     \\
%     \Delta;\Delta' \cdot \Gamma;(\text{patenv}\ m_i) 
%     \Vdash m_i : \tau'_i \sqsubseteq \alpha'_i
%     \\
%     \Delta;\Delta';\Delta'' \cdot \Gamma 
%     \Vdash e_i : \tau''_i \sqsubseteq \alpha''_i
%   } {
%     \Delta;\Delta';\Delta'' \cdot \Gamma
%     \Vdash
%     (\lambda\ \widebar{m_i \Rightarrow e_i}) : 
%     (\sqcap\ \widebar{\tau_i' \rightarrow \tau_i''}) \sqsubseteq 
%     \tau
%   } 

%   \inferrule { 
%     \Delta \cdot \Gamma
%     \Vdash e : \tau' \sqsubseteq (l : \tau)
%     \\
%     \text{fresh}\ \alpha
%     \\
%     \Delta;\Delta' \cdot \oslash \Vdash \tau' \sqsubseteq (l : \alpha)
%   } {
%     \Delta;\Delta' \cdot \Gamma
%     \Vdash (e/l) : \alpha \sqsubseteq \tau
%   } 

%   \inferrule { 
%     \text{fresh}\ \alpha
%     \\
%     \Delta \cdot \Gamma 
%     \Vdash e_1 : \tau_1 \sqsubseteq (\alpha \rightarrow \tau)
%     \\
%     \Delta;\Delta' \cdot \Gamma
%     \Vdash e_2 : \tau_2 \sqsubseteq \alpha
%     \\\\
%     \text{fresh}\ \alpha'
%     \\
%     \Delta;\Delta';\Delta'' \cdot \oslash \Vdash \tau_1 \sqsubseteq \tau_2 \rightarrow \alpha'
%     \\\\
%     \text{fresh}\ \alpha''
%     \\
%     % need to call unification one more time to liberate existentially quantified variables 
%     \Delta;\Delta';\Delta'';\Delta''' \cdot \oslash \Vdash \alpha'' \sqsubseteq \alpha'
%   } {
%     \Delta;\Delta';\Delta'';\Delta''' \cdot \Gamma
%     \Vdash (e_1\ e_2) : \alpha'' \sqsubseteq \tau
%   } 

%   \inferrule { 
%     \Delta \cdot \Gamma 
%     \Vdash e_1 : \tau_1' \sqsubseteq \tau_1
%     \\
%     \Delta;\Delta' \cdot (\Gamma, x \mapsto \text{pack}\ \Delta\ \tau_1')  
%     \Vdash e_2 : \tau_2' \sqsubseteq \tau_2
%     \\
%   } {
%     \Delta;\Delta' \cdot \Gamma 
%     \Vdash 
%     (\text{let}\ x : \tau_1 = e_1\ \text{in}\ e_2) : 
%     \tau_2' \sqsubseteq 
%     \tau_2
%   } 

%   \inferrule { 
%     \text{fresh}\ \alpha_1
%     \\
%     \text{fresh}\ \alpha_2
%     \\
%     \Delta \cdot \Gamma 
%     \Vdash e : \tau' \sqsubseteq \alpha_1 \rightarrow \alpha_2
%     \\\\
%     \alpha_1[\Delta] = \tau_1
%     \\
%     \alpha_2[\Delta] = \tau_2
%     \\
%     \text{split}\ \tau_2 = \widebar{\tau_i'}
%     \\
%     \text{fresh}\ \alpha_3
%     \\\\
%     \Delta;\Delta' \cdot \oslash \Vdash (\nu \alpha_3\ .\ (\sqcap\ \widebar{\text{twist}\ \alpha_3\ \tau_1\ \tau_i'})) \sqsubseteq \tau 
%   } {
%     \Delta;\Delta' \cdot \Gamma  
%     \Vdash \text{fix}\ e :(\nu \alpha_3\ .\ (\sqcap\ \widebar{\text{twist}\ \alpha_3\ \tau_1\ \tau_i'})) 
%     \sqsubseteq \tau
%   } 

% \end{mathpar}
% \caption{Type inference: bidirectional.
%   \newline
%   Input: $\Delta \cdot \Gamma \Vdash e : \_ \sqsubseteq \tau$. The input is the type variable environment, typing environment, the expression, and the expected type.
%   \newline
%   Output: $\Delta \cdot \_ \Vdash \_ : \tau \sqsubseteq \_$. The output is the type variable environment, and the strengthened result type.
% }
% \end{figure*}

\begin{figure*}[h]
\begin{flalign*}
  &\boxed{\text{case}\ \alpha\ \tau_1\ \tau_2}&
\end{flalign*}
\[
\begin{array}{l @{}l}
  \text{case}\ \alpha\ \tau_1\ \tau_2
  & {}=  
  \begin{cases}
    \left<\forall \widebar{\alpha_i}^i\ .\ \tau_2\ |\ \alpha \sqsubseteq \tau_1 \right> 
    &\text{if}\ \bigwedge_i\ \alpha_i \in (\text{freevars}\ \tau_2) \wedge (\bigvee_j\  i = j \wedge \alpha_j \in (\text{freevars}\ \tau_1))
    \\
    \forall \widebar{\alpha_i}^i\ .\ \tau_2 
    &\text{if}\ \bigwedge_i\ \alpha_i \in (\text{freevars}\ \tau_2) 
    \\
    \tau_2 &\text{otherwise}
  \end{cases}
\end{array}
\]
\caption{Co-inductive case construction.
  \newline
  This function constructs a case of a co-inductive function type.  
  \newline
  The input $\alpha$ represents a co-inductive fixed point.  
  \newline
  The input $\tau_1$ represents a function case type ($\cdot \rightarrow \cdot$),
  which is constrained to be weaker than the fixed point. 
  \newline
  The input $\tau_2$ represents the payload/resulting function case type ($\cdot \rightarrow \cdot$).
}
\end{figure*}

% note: type adjustment bears some resemblance 
% to widening/narrowing in abstraction interpretation.
% However, it doesn't share all the responsibilities of AI's operators.
% AI's operators play the role of ensuring monotonicity while preserving some precision.
% RelType adjustment is not used to ensure termination. It is merely to increase precision. 
% RelType adjustment with intersection occurs at output positions 
% RelType adjustment with union occurs at input positions 
% the overall effect is in narrowing the actual type, and widening the expected types.
% the AbsInt notion of narrowing might map to the unification process as a whole.

% note: Cousot's unification is implicit by matching meta-variables for types.
% that is, a polymorphic type is an infinite set of types merged with 
% the set of types that are accepted over program variables .
% here, we distinguish between these sets of types over program variables
% and sets of types over type variables, thus making type variables explicit.

\begin{figure*}[h]
\begin{flalign*}
  &\boxed{\Delta \cdot \Omega \Vdash \tau \sqsubseteq \tau}&
\end{flalign*}
\begin{mathpar}
  \inferrule {
  } {
    \Delta \cdot \Omega \Vdash \text{unit} \sqsubseteq \text{unit}
  }

  \inferrule {
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_2
  } {
    \Delta \cdot \Omega \Vdash l*\tau_1 \sqsubseteq l*\tau_2
  }

  \inferrule {
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_2
  } {
    \Delta \cdot \Omega \Vdash l:\tau_1 \sqsubseteq l:\tau_2
  }

  \inferrule {
    \Delta \cdot \Omega \Vdash \tau_3 \sqsubseteq \tau_1
    \\
    \Delta \cdot \Omega \Vdash \tau_2 \sqsubseteq \tau_4
  } {
    \Delta \cdot 
      \Omega \Vdash \tau_1\rightarrow\tau_2 \sqsubseteq \tau_3\rightarrow\tau_4	
  }
  \\
  \inferrule {
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_3
    \\
    \Delta \cdot \Omega \Vdash \tau_2 \sqsubseteq \tau_3
  } {
    \Delta \cdot \Omega \Vdash \tau_1 \sqcup \tau_2 \sqsubseteq \tau_3
  }

  \inferrule {
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_2
  } {
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_2 \sqcup \tau_3
  }

  \inferrule {
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_3
  } {
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_2 \sqcup \tau_3
  }

  \inferrule {
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_2
    \\
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_3
  } {
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_2 \sqcap \tau_3
  }

  \inferrule {
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_3
  } {
    \Delta \cdot \Omega \Vdash \tau_1 \sqcap \tau_2 \sqsubseteq \tau_3
  }

  \inferrule {
    \Delta \cdot \Omega \Vdash \tau_2 \sqsubseteq \tau_3
  } {
    \Delta \cdot \Omega \Vdash \tau_1 \sqcap \tau_2 \sqsubseteq \tau_3
  }
\end{mathpar}
\caption{Subtype unification: standard rules.
  \newline
  Input: $\Delta \cdot \Omega \Vdash \tau \sqsubseteq \tau$. The input is the type variable environment, the complex environment, the subtype, and the supertype. 
  \newline
  Output: $\Delta \cdot \_ \Vdash \_ \sqsubseteq \_$. The output is the type variable environment. 
}
\end{figure*}

\begin{figure*}[h]
\begin{flalign*}
  &\boxed{\Delta \cdot \Omega \Vdash \tau \sqsubseteq \tau}&
\end{flalign*}

\begin{mathpar}
  \inferrule {
    \bigwedge\nolimits_i\ \alpha_i \not\in (\text{dom}\ \Delta)
    \\
    \Delta;\Delta' \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_2
    \\
    \Delta;\Delta' \cdot \Omega \Vdash \tau_3 \sqsubseteq \tau_4
  } {
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq 
      \left< \exists \widebar{\alpha_i}^i\ .\ \tau_2\ |\ \tau_3 \sqsubseteq \tau_4 \right>
  }

  \inferrule {
    \bigwedge\nolimits_i\ \alpha_i \not\in (\text{dom}\ \Delta)
    \\
    \text{complex}\ \Delta\ \tau_3 = k
    \\
    \Delta;\Delta' \cdot \Omega, \downarrow k \mapsto \tau_4 \Vdash \tau_1 \sqsubseteq \tau_2
    \\
    \bigwedge\nolimits_i\ \alpha_i \not\in (\text{dom}\ \Delta')
  } {
    \Delta \cdot \Omega \Vdash 
      \left< \exists \widebar{\alpha_i}^i\ .\ \tau_1\ |\ \tau_3 \sqsubseteq \tau_4 \right> \sqsubseteq
      \tau_2
  }

  \inferrule {
    \bigwedge\nolimits_i\ \alpha_i \not\in (\text{dom}\ \Delta)
    \\
    \text{complex}\ \Delta\ \tau_3 \neq k
    \\
    \Delta;\Delta' \cdot \Omega \Vdash \tau_3 \sqsubseteq \tau_4
    \\
    \Delta;\Delta' \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_2
    \\
    \bigwedge\nolimits_i\ \alpha_i \not\in (\text{dom}\ \Delta')
  } {
    \Delta \cdot \Omega \Vdash 
      \left< \exists \widebar{\alpha_i}^i\ .\ \tau_1\ |\ \tau_3 \sqsubseteq \tau_4 \right> \sqsubseteq
      \tau_2
  }

  \inferrule {
    \bigwedge\nolimits_i\ \alpha_i \not\in (\text{dom}\ \Delta)
    \\
    \Delta;\Delta' \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_2
    \\
    \Delta;\Delta' \cdot \Omega \Vdash \tau_3 \sqsubseteq \tau_4
  } {
    \Delta \cdot \Omega \Vdash  
      \left< \forall \widebar{\alpha_i}^i\ .\ \tau_1\ |\ \tau_3 \sqsubseteq \tau_4 \right>
      \sqsubseteq \tau_2
  }
  \\
  \inferrule {
    \bigwedge\nolimits_i\ \alpha_i \not\in (\text{dom}\ \Delta)
    \\
    \text{complex}\ \Delta\ \tau_4 = k
    \\
    \Delta;\Delta' \cdot \Omega, \uparrow k \mapsto \tau_3 \Vdash \tau_1 \sqsubseteq \tau_2
    \\
    \bigwedge\nolimits_i\ \alpha_i \not\in (\text{dom}\ \Delta')
  } {
    \Delta \cdot \Omega \Vdash 
      \tau_1
      \sqsubseteq
      \left< \forall \widebar{\alpha_i}^i\ .\ \tau_2\ |\ \tau_3 \sqsubseteq \tau_4 \right>
  }
  \\
  \inferrule {
    \bigwedge\nolimits_i\ \alpha_i \not\in (\text{dom}\ \Delta)
    \\
    \text{complex}\ \Delta\ \tau_4 \neq k
    \\
    \Delta;\Delta' \cdot \Omega \Vdash \tau_3 \sqsubseteq \tau_4
    \\
    \Delta;\Delta' \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_2
    \\
    \bigwedge\nolimits_i\ \alpha_i \not\in (\text{dom}\ \Delta')
  } {
    \Delta \cdot \Omega \Vdash 
      \tau_1
      \sqsubseteq
      \left< \forall \widebar{\alpha_i}^i\ .\ \tau_2\ |\ \tau_3 \sqsubseteq \tau_4 \right>
  }
  \\
  \\
  %%%%%%%%%%%%%%%%%%%%%%%
  \inferrule {
    \alpha \not\in (\text{dom}\ \Delta)
  } {
    (\Delta, \alpha \mapsto \text{rolldn}\ \alpha\ \tau) \cdot \Omega 
    \Vdash \alpha \sqsubseteq \tau
  }

  \inferrule {
    (\Delta\ \alpha) = \tau'
    \\
    \Delta \cdot \Omega \Vdash \tau' \sqsubseteq \tau
  } {
    \Delta \cdot \Omega \Vdash \alpha \sqsubseteq \tau
  }

  \inferrule {
    (\Delta\ \alpha) = \tau'
    \\
    \neg (\Delta;\Delta' \cdot \Omega \Vdash \tau' \sqsubseteq \tau)
  } {
    (\Delta, \alpha \mapsto \text{rolldn}\ \alpha\ (\tau' \sqcap \tau)) 
    \cdot \Omega 
    \Vdash \alpha \sqsubseteq \tau
  }

  \inferrule {
    \alpha \not\in (\text{dom}\ \Delta)
  } {
    (\Delta, \alpha \mapsto \text{rollup}\ \alpha\ \tau) 
    \cdot \Omega \Vdash \tau \sqsubseteq \alpha
  }

  \inferrule {
    (\Delta\ \alpha) = \tau'
    \\
    \Delta \cdot \Omega \Vdash \tau \sqsubseteq \tau'
  } {
    \Delta \cdot \Omega \Vdash \tau \sqsubseteq \alpha
  }

  \inferrule {
    (\Delta\ \alpha) = \tau'
    \\
    \neg (\Delta;\Delta' \cdot \Omega \Vdash \tau \sqsubseteq \tau')
  } {
    (\Delta, \alpha \mapsto \text{rollup}\ \alpha\ (\tau' \sqcup \tau))
    \cdot \Omega \Vdash \tau \sqsubseteq \alpha
  }
  %%%%%%%%%%%%%%%%%%
  \\
  \\
  \inferrule {
    \Delta \cdot \Omega \Vdash 
      \tau_1[\alpha_1\mapsto\mu\alpha_2.\tau_2] % by induction hypothesis
      \sqsubseteq 
      \tau_2[\alpha_2\mapsto\mu\alpha_2.\tau_2]
  } {
    \Delta \cdot \Omega \Vdash \mu \alpha_1 . \tau_1 \sqsubseteq \mu \alpha_2 . \tau_2
  }
  \\
  \inferrule {
    \text{complex}\ \tau_1 = k 
    \\
    \Delta \cdot \Omega \Vdash (\Omega\ \downarrow\ k) \sqsubseteq \mu \alpha . \tau_2
  } {
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq \mu \alpha . \tau_2
  }
  \\
  \inferrule {
    \text{complex}\ \tau_1 \neq k 
    \\
    \text{wellfounded}\ \alpha\ \tau_2
    \\
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq \tau_2[\alpha \mapsto \mu \alpha . \tau_2]
  } {
    \Delta \cdot \Omega \Vdash \tau_1 \sqsubseteq \mu \alpha . \tau_2
  }
  \\
  \inferrule {
    \Delta \cdot \Omega \Vdash 
        \tau_1[\alpha_1\mapsto\nu\alpha_1.\tau_1] 
        \sqsubseteq 
        \tau_2[\alpha_2\mapsto\nu\alpha_1.\tau_1]
        % by co-induction hypothesis
  } {
    \Delta \cdot \Omega \Vdash \nu \alpha_1 . \tau_1 \sqsubseteq \nu \alpha_2 . \tau_2	
  }
  \\
  \inferrule {
    \text{complex}\ \tau_2 = k 
    \\
    \Delta \cdot \Omega \Vdash \nu \alpha . \tau_1 \sqsubseteq (\Omega\ \uparrow\ k) 
  } {
    \Delta \cdot \Omega \Vdash \nu \alpha . \tau_1 \sqsubseteq \tau_2
  }
  % \\
  % \inferrule {
  %   \text{wellroofed}\ \alpha\ \tau_1
  %   \\
  %   \text{complex}\ \tau_2 \neq k 
  %   \\
  %   \Delta \cdot \Omega \Vdash \tau_1[\alpha \mapsto \nu \alpha . \tau_1] \sqsubseteq \tau_2
  % } {
  %   \Delta \cdot \Omega \Vdash \nu \alpha_1 . \tau_1 \sqsubseteq \tau_2
  % }
  \\
  \inferrule {
    \text{complex}\ \tau_2 \neq k 
    \\
    \text{rewrite}\ \nu \alpha . \tau_1 = \tau_1'
    \\
    \Delta \cdot \Omega \Vdash \tau_1' \sqsubseteq \tau_2
  } {
    \Delta \cdot \Omega \Vdash \nu \alpha . \tau_1 \sqsubseteq \tau_2
  }
\end{mathpar}
\caption{Subtype unification: extended rules}
\end{figure*}


\begin{figure*}[h]
\begin{flalign*}
  &\boxed{\text{rolldn}\ \alpha\ \tau = \tau}&
\end{flalign*}
\[
\begin{array}{l @{}l}
  \text{rolldn}\ \alpha\ \tau
  & {}=
  \begin{cases}
    \nu \alpha . \tau 
    &\text{if } \alpha \in (\text{freevars}\ \tau) 
    \\
    \tau &\text{otherwise}
  \end{cases}
\end{array}
\]
\caption{Rolling down}
\end{figure*}

\begin{figure*}[h]
\begin{flalign*}
  &\boxed{\text{rollup}\ \alpha\ \tau = \tau}&
\end{flalign*}
\[
\begin{array}{l @{}l}
  \text{rollup}\ \alpha\ \tau
  & {}=
  \begin{cases}
    \mu \alpha . \tau 
    &\text{if } \alpha \in (\text{freevars}\ \tau) 
    \\
    \tau &\text{otherwise}
  \end{cases}
\end{array}
\]
\caption{Rolling up}
\end{figure*}



% \begin{definition}
% \[
%   \begin{array}{l @{} l}
%   \Delta\ ;\ \oslash
%   &\ = \Delta 
%   \\
%   \Delta_1;(\Delta_2,\alpha \mapsto \tau) 
%   &\ = (\Delta_1;\Delta_2),\alpha \mapsto \tau
%   \end{array}
% \]
% \end{definition}

% \begin{definition}
% \[
%   \begin{array}{l @{} l}
%   M_1 * M_2 
%   &\ = 
%   [\Delta_1 ; \Delta_2 \ |\ 
%     \Delta_1 \in M_1
%     \ \ \  
%     \Delta_2 \in M_2
%   ]
%   \end{array}
% \]
% \end{definition}

% \begin{definition}
% \[
%   \begin{array}{l @{} l}
%   \text{reduce} \sqcap [] 
%   &\ = \top
%   \\
%   \text{reduce} \sqcap \tau::\widebar{\tau}
%   &\ = \tau\ \sqcap (\text{reduce} \sqcap \widebar{\tau})
%   \end{array}
% \]
% \end{definition}

% \begin{definition}
% \[
%   \begin{array}{l @{} l}
%     N_1 * N_2
%     &\ = 
%     \begin{array}[t]{l}
%       [ \Delta_1 ; \Delta_2 . \tau_1 \sqcap \tau_2 \ |\ 
%         \Delta_1.\tau_1 \in N_1
%         \ \ 
%         \Delta_2.\tau_2 \in N_2
%       ]
%     \end{array}
%   \end{array}
% \]
% \end{definition}

% \begin{definition}
% \[
%   \begin{array}{l @{}l}
%   \text{reduce} * \{N\}
%   & {}= N
%   \\
%   \text{reduce} * \widebar{N_i}
%   & {}= N_j * (\text{reduce} * \widebar{N_i}\setminus\{N_j\})
%   \end{array}
% \]
% \end{definition}

% \section{Evaluation}
% \begin{enumerate}
%   \item experiments 
%   \item adequacy of problem 
%   \item adequacy of solution 
% \end{enumerate}

% \section{Related work}
% \begin{enumerate}
%   \item past work 
%   \item future work 
% \end{enumerate}

% \section{Conclusion}
% \begin{enumerate}
%   \item restate context with technical terms 
%   \item restate problem with technical terms 
%   \item restate solution with technical terms 
%   \item restate results 
% \end{enumerate}

% \section*{Notes}

% \subsection*{dualities}
% \begin{enumerate}
%   \item \(\bot \sqsubseteq \top \)
%   \item \(\tau_1\ \&\ \tau_2  \sqsubseteq \tau_1\ |\ \tau_2 \)
%   \item \(\forall \alpha . \tau \sqsubseteq \exists \alpha . \tau \)
%   \item \(\nu \alpha . \tau \sqsubseteq \mu \alpha . \tau \)
% \end{enumerate}

% \subsection*{contributions}
% \begin{enumerate}
%   \item program synthesis such that:
%     \begin{enumerate}
%       \item goal defined by partial programs with missing annotations  
%       \item goal transformed into type specification 
%       \item type specification may contain dynamic type  
%     \end{enumerate}
%   \item algorithmic subsumption allows simple subtyping rule with dynamic type
%     \begin{enumerate}
%       \item subtyping can have a dynamic type on either side without risk of   
%         all terms being accepted by typing rules (i.e. everything typing)
%     \end{enumerate}
%   \item an expressive type system 
%     based on intersection/union, (co)inductive, and quantified types
%     \begin{enumerate}
%       \item without dependent types 
%       \item comparable to prolog 
%       \item allows dynamic type 
%       \item sound modulo absence of dynamic type 
%         or static type union/intersect with dynamic
%       \item types behave either leniently or strict depending on usage as actual type or expected type
%     \end{enumerate}
%   \item full type synthesis with full type propagation (for all rules)
%   \item type unification such that: 
%     \begin{enumerate}
%       \item the principal type of all terms is top
%       \item lenient (but unsound) static type inference
%       \item expanding type info with union and intersection and dynamic type
%     \end{enumerate}
%   \item interleaving type constraint generation and solving with dynamic type 
% \end{enumerate}

% \subsection*{differences}
% in contrast with System F:  
% \begin{enumerate}
%   \item types are not used as arguments to functions 
%   \item universal binders do not represent placeholder for type argument 
% \end{enumerate}

% in contrast with gradual typing:  
% \begin{enumerate}
%   \item infers more static type info 
%   \item stronger soundness claim (i.e. weaker soundness precondition)
%   \item dynamic semantics are irrelevant 
%   \item deterministic subsumption 
%   \item dynamic type built into subtyping 
% \end{enumerate}

% in contrast with HM type inference:  
% \begin{enumerate}
%   \item synthesizes type in addition to constraint solution 
%     due to subtyping
%   \item propagates types
%   \item global top type, leaves types open during unification
%   \item expands and narrows types  
% \end{enumerate}

% in contrast with Roundtrip typing:  
% \begin{enumerate}
%   \item type combinators without dependent types
%   \item prolog-like type language  
%   \item synthesizes types for all rules
%   \item global top type, leaves types open during unification
%   \item expands and narrows types  
%   \item delegates to unification to decompose types 
%   \item delegates to unification to free bound variables 
% \end{enumerate}




% \subsection*{gradual typing}
% How gradually typed inference typically works:
% \begin{enumerate}
%   \item infer either a strict static type or a dynamic type
%   \item let annotations implicitly guide the usage of static vs dynamic checks 
% \end{enumerate}
% There exists work on type inference for gradually typed programs.
% To the best of my knowledge, they are all sound and complete.
% Other gradual type inference systems separate 
% generating constraints from solving constraints.
% Gradual typing systems use the dynamic type \lstinline{(?)} to indicate 
% that dynamic checks should be used.
% Gradual type inference relies on ML types with union extension.
% They do not contain the idea of using intersection and union to keep types open.
% Gradual typing systems separate subtyping from the relation 
% between dynamic to static types to avoid all terms typing via the subsumption rule.

\clearpage

\begin{thebibliography}{}

\bibitem{} Patrick M. Rondon, Ming Kawaguchi, and Ranjit Jhala. Liquid types. In PLDI, 2008.
% \url{http://goto.ucsd.edu/~rjhala/papers/liquid_types.pdf}
\bibitem{} 
Nadia Polikarpova, Ivan Kuraj, and Armando Solar-Lezama. Program synthesis from polymorphic refinement types. In PLDI, 2016.
\bibitem{} Benjamin C. Pierce and David N. Turner. Local type inference. In TOPLAS, 2000.
\bibitem{} Giuseppe Castagna, Tommaso Petrucciani, and Kim Nguyen. Set-theoretic types for polymorphic variants. In ICFP, 2016.
\bibitem{} Giuseppe Castagna and Zhiwu Xu. Set-theoretic foundation of parametric polymorphism and subtyping. In ICFP, 2011.
% \url{https://www.irif.fr/~gc/papers/icfp11.pdf}
% \url{https://www.irif.fr/~gc/papers/set-theoretic-types-2022.pdf}

\bibitem{} Jeremy G. Siek and Walid Taha. Gradual typing for objects. In ECOOP, 2007.
\bibitem{} Tim Freeman and Frank Pfenning. Refinement types for ML. In PLDI, 1991.

% \bibitem{} Refinement types as proof irrelevance by William Lovas and Frank Pfenning 
% \bibitem{} Example-directed synthesis: a type-theoretic interpretation by Frankle, Osera, Walker, and Zdancewic
% \bibitem{} Gradual typing for functional languages by Jeremy G. Siek and Walid Taha 
% \bibitem{} Gradual typing for objects by Jeremy G. Siek and Walid Taha 
% \bibitem{} Gradual typing with unification-based inference by Siek and Manish Vachharajani 
% \bibitem{} Dynamic Type Inference for Gradual HindleyMilner Typing - \url{https://dl.acm.org/doi/pdf/10.1145/3290331}
% \bibitem{} Principal type schemes for gradual programs - \url{https://www.cs.ubc.ca/~rxg/ptsgp.pdf}
% \bibitem{} Gradual Liquid Type Inference - \url{https://arxiv.org/pdf/1807.02132.pdf}
% \bibitem{} Gradual typing with union and intersection types - \url{https://dl.acm.org/doi/pdf/10.1145/3110285}
% \bibitem{} Gradual typing: a new perspective - unions, intersections, dynamic type, and type inference - \url{https://www.irif.fr/~gc/papers/popl19.pdf}
% \bibitem{} Gradual refinement types (via abstract interpretation) - \url{https://pleiad.cl/papers/2017/lehmannTanter-popl2017.pdf}
% \bibitem{} Consistent subtyping for all - \url{https://xnning.github.io/papers/consistent-subtyping-for-all-toplas.pdf}
% \bibitem{} Polymorphic functions with set-theoretic types, part 1 - \url{https://www.irif.fr/~gc/papers/polydeuces-part1.pdf}
% \bibitem{} Polymorphic functions with set-theoretic types, part 2 - \url{https://www.irif.fr/~gc/papers/polydeuces-part2.pdf}
% \bibitem{} Revisiting occurrence typing - \url{https://arxiv.org/pdf/1907.05590.pdf} 
% \bibitem{} An ideal model for recursive polymorphic types; MacQueen, Plotkin, Sethi; Metric/Contraction/Banach fixed point theorem
% \bibitem{} Bottom-up synthesis of recursive functional programs using angelic execution - Anders Miltner et al

\end{thebibliography}



\end{document}

% Observations:
% language of types
  % a type is a set of objects
  % a type may be viewed as proposition that may be undecidable 
    % proved by a term
% language of constraints
  % A constraint may be viewed as a decidable proposition 
  % A constraint is simply a subtyping relation over types
    % allowing economical reuse of types 
  % A fully assigned subtyping constraint is a verifiable statement
% Freeing variables happens in subtyping/unification due to subtyping asymmetry  
  % free variable in subtyping connects to free variable associated with term 
  % if expected type has free variable.
% widening and narrowing in type inference
  % exactness param chosen during inference 
    % exactness flag is justified by dual purpose of type system
      % 1. catch errors (exactly according to spec)
      % 2. describe behavior of program abstractly
  % annotations are exact 
  % everything else is non-exact;
    % allowing union and intersection with fresh variables
% comparison of relational types with dependent types

  % dependent types
    % inductive LL : Nat -> Type where
    % | nil : LL 0 
    % | cons : {n : Nat} -> LL n -> LL (n + 1) 

    % F   (n : Nat) -> LL n
    % P   (n : Nat)  LL n

    % variable introduction is coupled with type construction/compounding
    % this is convenient since a type may dependent on a term that's not included in itself


  % relational types 
    % P  
    % (0^@  nil^@) | 
    % ( N L :: N  L  P => 1^N  cons^L) 

    % translating from dependent to relational
    %  {n : Nat}  LL n  LL (n + 1) 
    %  {n : Nat} {l: List} :: (l : LL n)  {(n + 1, cons l)}  
    % ( N L :: N  L  P => 1^N  cons^L) 

    % -- OR -- 

    % F  
    % (nil^@ -> 0^@) ; 
    % ( L N :: F  L -> N => cons^L -> 1^N) 

    % translating from dependent to relational
    %  {n : Nat} -> LL n -> LL (n + 1) 
    %  {n : Nat} {l: List} :: (l : LL n) -> {for cons l => n + 1}  
    % ( L N :: F  L -> N => cons^L -> 1^N) 


    % variable introduction is decoupled from type construction 
    % the use of a variable in a type is separate from introducing the variable
    % this is convenient since any term that a type depends on exists as a subpart
    % of a term in that type
    % Thus, dependencies may be inferred from terms.

    % My intuition is that the symmetrical relations 
    % and the decoupling of binder introduction from type combination 
    % and consistent treatment of type dependency and type membership 
    % provides an easier mental model to work with
  % closed parameter 
    % indicates if a constraint is closed vs open 
    % variables are fully determined in closed unification 
    % variables are are open to future information in open unification 


% claim: SOTA: type systems for dynamically typed languages do not have type-directed synthesis methods. 
% identify problems for synthesis evaluation
% translate Liquid type benchmarks to this relational type language. 

% Aim.cen/Aim.adj is safe when the free variables may be chosen (i.e. choosable).
% we use Aim.cen when we only care about checking for safety.
% we use Aim.adj when we want to find the most lenient model possible, 
% amenable to safe term compositions in the unexplored parts of the program. 
% Aim.max and Aim.min is necessary when the variables are fixed but unknown; they may not be chosen. 

% for dynamically typed languages, system F subtyping is too restrictive
% we need to compare types that have varying degrees of variable generalization 
% additionally, the subtyping constraints in quantified types are more general than system F
% variables are not restricted to be alone on the left side of subtyping. 
% this generality allows for concise descriptions of inductive function types.

% Remy's ML-calc uses quantified constraint for a similar goal, but technically quite different.
% Remy's ML-calc makes a distinction between subtyping and instantiating relation of universal
% relational types merges the notion of instantiation with subtyping
% relational types generalizes second-order quantification to subsume first-order use-cases. 

% note that Remy' constraint uses existential because the subtyping is inside
%  X :: C(X)  X  T === ( X :: C(X) . X)  T

% synquid has a symmetrical rule using implication for subtyping constraint types
% in Synquid is subtyping depends only on the constraints 
% in our setting subtyping can depend on base types too
% the asymmetrical rules can handle all permutations 
% Synquid lacks decomposition of predicates
% Relational types allows decomposition like functional/logic programming, thus is more natural to use.


% subtyping constraints may be thought of as decidable propositions of the metalanguage 
% equivalent to deciding if a proof satisfies a proposition (of the object language)
% types may be thought of as possibly undecidable propositions of the object language
% the advantage of using subtyping as the only metalanguage predicate is operating on types
% is that types can be reused across both the object language and metalanguage propositions.

% it would have been possible to define a first-order constraint language, as is the case in Synquid,
% but that would not allow reusing information across types and constraints.
% by adding constraints to the second-order quantification of types, 
% a single quantification mechanism serves two distinct purpose
% 1. to precise define the contents of a type. (typically the purpose of first-order quantification)
% 2. to allow specialization of type based on usage (typically the purpose of second-order quantification) 


% there are two distinct purposes of polymorphic quantification over types
  % 1. parametric - ignoring a sub part of a type (2nd order) 
  % 2. constrained - defining a type based on constraints (1st or 2nd order)

% there are two distinct forms of checking polymorphic composition 
  % 1. instantiation a quantified variable supports both parametric and constrained polymorphism
  % 2. subtyping of quantified type over the same variables   

% RT uses second order univ/exists quantifiers subsume both constraint types and polymorphic types
% RT's subtyping subsumes both instantiation and refinement  
% liquid's refinement type is an intersection of a base type and a constraint type. 
  % that is, the resulting type is a refinement of the base type. 


% RT's subtyping subsumes both System F polymorphic subtyping with Synquid/Remy's polymorphic instantiation  
% RT's subtyping subsumes both Synquid's refinement subtyping and existential instantiation
% RT's existential generalizes subpart irrelevance and subpart refinement 


% type-checking vs model-checking
  % downward propagation vs conflict driven clause learning 
    % downward propagation teaches provides types that avoid failing search space. 
    % SAT uses conflict driven clause learning to avoid failing branches  
  % compositional typing vs counter-example guidance 
    % refines the context/assumptions 
  % unification vs boolean constraint propagation
    % determines assignment for variables 


% learning inductive invariant by counter-example guided vs downward propagation 
% counter-example method 
  % notice that return type can't be satisfied 
  % use proof of unsat to construct new invariant
  % update premise with invariant (formula over parameters of recursive function)
  % repeat
% propagation method
  % infer loop parameters from downward prop and unification with adjustment 

% comparison to model checking
  % same: we compute the inductive invariant
  % different: but we don't compute the fixed point
    % we merely represent the fixed point with a mu/nu binder.
      % since we don't necessarily have finite states
    % then we check that the inductive invariant subtypes the closed-form type. 
  % union/intersection adjustment is a compositional version of 
    % transition systems' (widening,expansion)/(narrowing,contraction)
      % the latter of which is wrt inductive invariants (IH)
    % if the type of a location is adjustable 
      % then the operational semantics can take a step with any value at that location

% -- learning inductive invariant:
% -- conjecture: learning inductive invariant via unification works like predicate abstraction and interpolant learning 
%     swap: (x0 : nat * y0 : nat) -> (x' : nat * y' : nat) 
%     -- pre condition: 
%     -- x0 >= y0
%     -- t = x0 - y0

%     -- post condition:
%     -- y' = x0 /\ x' = y0  
%     fun swap (x0, y0) =

%         -- invariant
%         -- t >= 0 /\ x = x0 - t /\ y = y0 + t  
%         -- type inference infers strongest post condition of premise here
%         fun loop (x, y, t) =
%             if (t > 0) then
%                 loop (x - 1, y + 1, t - 1)
%             else 
%                 (x, y)

%         -- type inference finds pre condition that strengthens loop's post-condition invariant  
%         loop (x0, y0, x0 - y0)

% is the construction of a nu-type from the fix rule
% in effect, the same thing as PDR/IC3?
% That is, whatever is learned to strengthen the premise 
% is automatically applied to preceding iterations 
% due to the wrapping type with the co-inductive nu binder

% a proof/implication graph is akin to a program

% a resolution proof/graph is akin to a type annotated program

% resolution/clause learning over proof is akin to 
% propagation up of types over program term, e.g. (fix ...)

% an initial condition is akin to a precondition of the implication type of fix
% a safety condition is akin to a postcondition of the implication type of fix

% an interpolant of a fix's implication is akin to a nu-type:
% a subtype of the postcondition and supertype of the precondition 

% predicate abstractions are akin to types with variables

% initial conditions are akin to parameter types 

% safety coniditions are akin to result types

% abstraction-refinement is akin to  unification 

% goal-abstraction under refined hypothesis (counterproof-generation) is akin to 
% unification before substitution with variables on rhs (necessary conclusion)

% hypothesis-refinement under abstract goal (proof-generation (that counterproof fails)) is akin to 
%unification after substitution with variables on lhs (necessary premise)

% type inference vs program synthesis vs model checking:
% in type inference, the fix rule constructs the interpolant
% in program synthesis, the fix program is learned from the initial and safety conditions
% in model checking, the resolution proof is learned from the initial and safety conditions
  % model checking is harder than type inference because the models are themselves abstract
  % models are just a special syntax for formulas


% /-
% first order quantification

%  NL .
%   {(0, [])}  
%    (n, l) : NL . 
%     (n + 1,  () :: l)  

%  N2L .
%   {0 => []}  
%    n -> l : N2L .  WRONG
%     {n + 1 => () :: l }

%  N2L .
%   0 -> nil*unit  
%    N2L  N -> L .    
%     N + 1 => unit :: L

% --- 
% by second order quantification with subtyping rather than first order with membership,
% we avoid mapping between terms and types in unification procedure.
% We also enable the succient coinductive definitions of functions.

% -/


% /-
% translating Liquid types into relational types

% List with len where
% [] : {v  List | len v = 0} | 
% () :: (xs : List) : {v  List | len v = (len xs) + 1} | 

% n : Nat -> {v  List | len v = n}

% ...

%  N . N  Nat => N -> ( L . 
%   (N  L)  ( N'  L' .  (0  []) | (N' + 1  () :: L'))  =>
%   L
% )

% ...

%  N -> L .
%   0 -> []  
%   N + 1 -> () :: L  


% -/

% comparison of typing systems
  % bidirectional type checking 
    % full program required 
    % some rules require type annotations: type checking rules
    % some rules don't have type annotations: type inference rules 
  % bidirectional program checking 
    % full type required
    % some types also have program examples: program checking rules
    % some types don't have program examples: program synthesis rules 
  % generalized type checking 
    % all rules handle both type checking and type inference
      % propagate types down and up
  % generalized program checking 
    % all rules handle both program checking and program synthesis 
      % propagate programs down and up

% novel contributions 
  % 1. outcome: synthesis from context (without annotations) 
    % sota: bidirectional/roundtrip typing using annotations 
    % contribution: both up and down propagation for every syntax rule
      % propagating types (downward/upward) 
      % A synthesis algorithm capable of generating local constraints for incomplete programs. 
  % 2. outcome: inference of expressive types
    % sota: refinement types require base type 
    % contribution: relational types
      % relating types (inductive/coinductive) 
      % A type level language capable of expressing (co)inductive relations without the complexity of dependent types or propositional syntax.  
  % 3. outcome: safe but lenient type inference without prescription
    % sota: datatypes/ML languages prescribe upper bound 
    % contribution: adjusting types with union and intersection
      % A unification algorithm capable of preserving the flexibility of dynamically typed programming. 

% additional observations 
  % outcome: subtyping is first-class
    % sota: separate constraints, type schemes 
      % separate constraints, type schemes, and types
      % separate constraint semantics, instantiation/generalization, subtyping
    % contribution: 
      % the subtyping semantics is sufficiently expressive
      % subtyping subsumes constraint semantics and instantiation/generalization
      %e.g. union and intersection, asymmetrical quantification subtyping
      %partial instantiation in generalized polymorphic subtyping
      % subtyping encodes instantiation: ((ALL X . T) \sqsubseteq T')
      % e.g. 
        % g(f : int -> int)
        % h : All X . X -> X
        % g(h) is accepted by specializing h in subtyping

% automatic partial instantiation 
  % NOTE: this seems like a significant innovation in eager inference. 
  % specializes arguments not just applicator
  % specializes type of polymorphic arguments!!!
    % g(f : All X . T)
    %: h : All X . S
    % g(h)
    % specializes h
  % when expected type is also polymorphic 
  % with general constraints (rather than just upper bound)
  % generalization of subtyping
  % compare to instantiation of other systems
    % Cardelli's system F\sqsubseteq does not have instantiation
    % Pierce's local type inference (section 3) does not have partial instantiation
    % synquid does not have partial instantiation or polymorphic subtyping 
    % system F does not have instantiation or generalized constraints

% relational type's type inference and unification with union type
  % generates sets of typing environments 
  % represented with functions instead of inference rules 
  % this is difficult to represent with inference rules 

% relational type's inference and synthesis 
  % type inference for each term case and an arbitrary type
  % program synthesis for for hole term and each type case.

% sequent calculus rules 
  % enable generating derivation
  % the essence is its using left and right rules (relative to the turnstile)
  % left rules have type/prop form on lhs of |-
  % left rules correspond to elimination rules of natural deduction
  % it's not essential that the sequents have multiple consequents

% synthesis rules
  % union on left should result in a cases function applied to an argument
  % intersection on Right should result in either a function or a record
  % thus, can reduce union on left to intersection on right.
  % first-class pattern matching with beta-normal form heuristic
    % could require function to be let-bound 

% use of negation
  % could negation of T be encoded as T -> bot?
  % that is,
    % T1 -> T2 /\ NOT T3 = % T1 -> T2 /\ T3 -> bot

% enumeration: enumerating combinations from a set
  % data-guided
    % unsound guidance from data constructors found in types 
  % relation-guided
    % using relation between data in types
    % shown by Frankle to be worse than broader data-guidance 
  % context-guided 
    % samples from context are combined
    % polymorphic sampling
      % not supported in Frankle's sequent calculus

% inductive generalization
  % inductive generalization normalized as finding a subtype
    % either infer type from term
    % or if hole with expected type
      % enumerate possibilities for hole 
      % choose one
      % infer type
  % generalization adds information
  % thus decreasing information loss when finding types for holes in deduction phase 

% propagation down of subtype/generalized type
  % will be sound (no information loss) 
    % whereas propagation of examples/supertype would lose information
    % less refined search space
    % less strict type checking for the hole
  % providing better guidance to search for term

% best-first search
  % need priority queue to determine which hypothesis to try next after failed hypothesis 
    % with DFS, we wouldn't be able to determine which depth's solution to retry.
  % to avoid redundant traversals of expressions, holes are identified by variable and a hole type-environment.
    % when hypothesis is generated, then it's substituted in, and removed from hole type-env.
  % Feser's algorithm and Frankle's synchronous rules are BFS


% -- synthesize procedure
%   -- best-first search
%   -- alternate between infer (deduce) and enumerate (induce)
%   -- infer produces a Contract 
%   -- enumerate produces a Hypothesis



% semantics (non-deterministic)
  % syntax-directed with non-deterministic subsumption 
  % some elim and intro rules are encoded as various combinations of subsumption with application 
    % e.g. disjunction/cases elim/intro, conjunction elim/intro

% future work: specification of reactive programs
  % non-termination programs. no output, just side-effects or internal state.


% TODO:
% modify to full program synthesis
  % see if data structure transformers can be emulated using refinement type inference 
  % does angelic synthesis relate to this?
% find way to integrate SMT solvers 
% write paper 
  % [x] 0. introduction 
  % [ ] 1. motivating example / overview 
  % - 2. problem statement 
  % - 3. overall synthesis/inference algorithm/rules 
    % include how type information propagates
    % abstract away relation type details
    % includes propagation of types
  % - 4. unification / subtyping / relational typing
    % including induction over intersection and implication types
% find decision procedure for relational types (subtyping over induction on compound types)
  % terminate if one side is compound with all variables and other is inductive? 
  % Banach fixed-point theorem?
  % contraction maps?
  % metric spaces?
% determine if negation/relative complement is needed to improve program synthesis 
  % see anti-specification in Anders' paper
  % https://courses.cs.washington.edu/courses/cse507/14au/sched.html
  % https://www.cs.utexas.edu/~bornholt/post/synthesis-explained.html
  % https://people.csail.mit.edu/asolar/SynthesisCourse/Lecture1.htm
% implement proof of soundness
% implement translation from surface syntax to nameless syntax 
% consider methods of ensuring beta-normal forms
  % splitting off elim forms than can't refer to intro forms to prevent non-beta-normal forms
  % normal form syntax use let-binding (similar to ANF or CPS or SSA)