% \documentclass{article}
% \documentclass[]{acmart}
\documentclass[sigplan,screen]{acmart}

\usepackage{mathpartir}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{stmaryrd}
\usepackage{listings}

\lstset{
    identifierstyle=\color{violet},
    % textcolor=blue,
    % keywordstyle=\color{blue},
    keywordstyle=\text,
    basicstyle=\ttfamily,
    mathescape=true,
    showspaces=false,
    morekeywords={let, fix}
}
\usepackage[utf8]{inputenc}
% \usepackage[T1]{fontenc}


\title{Type and program synthesis with relational types}
\author{Thomas Logan}
\date{October 2022}

\begin{document}

\maketitle

\section{Introduction}
% context: dynamically typed languages   
Some of Today's most popular languages such as JavaScript and Python are considered to be \textbf{dynamically typed}.
One of the hallmarks of such languages, is that they do not require specifications 
that can be verified statically. By not requiring static bounds, dynamically typed languages
enable vast combinations of terms and high reusability of code. 
Although it's not required, many programmers find that
static checks, such as \textbf{linters} and more advanced \textbf{static analysis} tools, 
enable them to find bugs, understand code, and write code more efficiently and reliably. 

In addition to writing programs, programmers can also annotate programs with specifications to
aid static verification. Writing specifications and programs can be tedious and burdensome.  
It addition to verifying correction, static tools can aid programmers by automatically synthesizes
parts of programs or specification implied by the context. Thus, the programmer can simply write
either a partial specification or partial program and allow the synthesis tool to fill in the rest.   

\begin{lstlisting}[language=Python]
def foo(x):
    if isinstance(x, int):
        return x + 1 
    elif isinstance(x, str): 
        return x + "abc"
\end{lstlisting}

% motivation: Specification 
Much of the work on synthesizing specifications from programs has been based on \textbf{ML type inference}.
In contrast to dynamically typed languages, \textbf{ML languages} require static bounds are prescribed 
in its programs via its \textbf{datatype} mechanism. The design of ML's datatype mechanism is clever, 
such that these static bound prescriptions are only needed at the definitions of types and can be 
inferred when the data of types are used. When a piece of data is seen an upper static bound 
may be inferred, \text{propagated upward}, and combined with other inferred types.

\begin{lstlisting}[language=ML]
datatype int_or_str = 
    Int of int | 
    Str of string

fun foo(Int x) = x + 1
  | foo(Str x) = x ^ "abc"
\end{lstlisting}

% motivation: subtyping 
Since dynamically typed languages do not require prescribed static bounds, 
type inference (or specification synthesis, in more general terms) must balance 
restricting the permissible combinations and reusability in programs with 
catching errors that could result in crashes at runtime.
The flexibility of combinations implies that for the same data, 
the tightest static bounds may differ depending on the context.
Thus, \textbf{subtyping} or a similarly flexible 
static notion is necessary to avoid overly restricting combinations.

% motivation: expressive types 
Mainstream type systems typically merely allow constructing simple types 
by grouping objects together based on their structures or names.
However, to have genuine confidence in the correctness of programs, specifications
need to express relations between data. There are a number of rather esoteric systems that
enable stating and proving propositions that relate objects to each other, 
including ACL2, Twelf, Coq, Lean, HOL, Isabelle, Liquid Haskell, and Synquid.  
Some of these use dependent types to encompass both simple types and propositions, 
and some rely on new syntactic categories for propositions. 

Liquid Haskell and the related Synquid both provide a way to define relations
along with subtyping, by extending ML datatypes with predicate clauses. 

\begin{lstlisting}[keywords={termination, measure, data, where}]
termination measure len :: List $\beta$ $\rightarrow$ Nat 
data List $\beta$ where
  Nil :: {v: List $\beta$ | len v = 0}
  Cons :: $\beta$ $\rightarrow$ xs: List $\beta$ $\rightarrow$ 
    {v: List $\beta$ | len v = len xs + 1}

\end{lstlisting}

However, as discussed above, the ML datatype mechanism breaks our definition of dynamically typed,
as it demands prescribing static bounds with data, so this would not work for our problem wholesale.
Other systems, like Lean or Isabelle, have similar problems with the additional issue of lacking subtyping.
Finally, all of these are rather complex, either by requiring syntactic classes of propositions predicates, 
in addition to types, or complicating the static semantics of types by allowing them 
to be dependent on programs.



% motivation: Programming 
With expressive types, using types to guide the user's programming or automatic program synthesis 
becomes a more realistic endeavor, as there may be enough information in the specification to narrow the field
and guide the generation useful programs. Lean and Synquid\cite{} (Based on Liquid Haskell) 
are two examples of systems that decompose and propagate type specifications 
to incomplete sections or holes in programs. 
In the case of Lean, users can use this local type specification to help them construct programs and proofs,
while in Synquid this local information is leveraged to efficiently synthesize programs. 

% solution 
This paper introduces the \textbf{relational type system} to provide expressive specifications 
and synthesis capabilities for dynamically typed languages. 
The contributions of the relational type system include:
\begin{enumerate}
  \item A type level language capable of expressing inductive relations without the complexity of dependent types or propositional syntax.  
  \item A synthesis algorithm capable of generating local constraints for incomplete programs. 
  \item A unification algorithm capable of preserving the flexibility of dynamically typed programming. 
\end{enumerate}

% summary 

In section 2, we illustrate the problem and our solution with examples.
In section 3, we define the problem and define the syntax, dynamic semantics, and syntax of our language.
In section 4, we present the synthesis and unification algorithms.
In section 5, we evaluate the problem and its solution. 
In section 6, we discuss related work of the past and possible future directions. 

\section{Old Introduction/Overview}

\begin{enumerate}
  \item example-driven context 
  \item example-driven motivation
  \item example-driven solution  
\end{enumerate}


\textbf{Dynamically typed} languages can make writing programs quick and easy 
because they don't require specifying static bounds on behavior.
Two of the most popular programming languages today, JavaScript and Python, 
are dynamically typed. 
JavaScript is the language of the web, while Python is the most popular choice
for data science and machine learning projects. 
Consider a Python program that operates on strings or integers. 

\begin{lstlisting}[language=Python]
def foo(x):
    if isinstance(x, int):
        return x + 1 
    elif isinstance(x, str): 
        return x + "abc"
\end{lstlisting}

\noindent The dynamically typed program avoids the extra step of associating terms with
static bounds as seen in ML-family languages using the datatype mechanism. 

\begin{lstlisting}[language=ML]
datatype int_or_str = 
    Int of int | 
    Str of string

fun foo(Int x) = x + 1
  | foo(Str x) = x ^ "abc"
\end{lstlisting}


Although dynamically typed languages already offer ease and efficiency for writing programs, 
this facility can be enhanced with \textbf{synthesis of programs} 
from surrounding context. 
This article presents a system that synthesizes terms from context 
in a dynamically typed language.
Synthesis of programs for a dynamically typed language introduces a fundamental tension. 
While dynamically typed programs benefit from a lack of static bounds, program synthesis
must be a terminating procedure driven by static bounds representing the goals of synthesis.   

\textbf{Types} have become the lingua franca of formal specification of static bounds.
Others have shown how various forms of specification, including examples, abstract values, 
pure propositions, and modal propositions, can be encoded as types.
Types have been used successfully for verifying programs, 
guiding program synthesis in ML-family languages, 
and guiding humans in dependently-typed interactive theorem proving. 

Dynamically, two interfaces may have the same correctness result for some inputs,
while differing on other inputs. \textbf{subtyping} is used to decide if a term's 
composition is statically invalid, maintaining semblance to dynamically typed programming,
while also adding safety with static behavior.

By \textbf{downward propagating} and decomposing types, 
it is possible to guide the synthesis of programs.
To maintain the spirit of dynamic types, type annotations must remain optional.
Previous work has demonstrated the utility of downward propagating types 
in theorem proving systems, local type checking, 
and synthesis of ML-family programs.

For example, in a program that extracts 
the first element of a pair of a particular type, 
it's possible to detect an error before knowing the second element.

to detect an error of a pairt of a   
\begin{lstlisting}
$\lambda$ n : nat $\Rightarrow$
  let first = ($\lambda$ (x,y) : (str $\times$ str) $\Rightarrow$ x) .
  first (n, _) 
\end{lstlisting}

\noindent The  applications' argument type \lstinline{(nat $\times$ ?)} 
is propagated and decomposed such that the subtyping constraint 
\lstinline{nat $\subseteq$ str} is decided. 

In order to have fine-grained control over where types are utilized or avoided, 
types may be composed of \textbf{dynamic types}, represented by \lstinline{(?)} to indicate 
that any subterm corresponding to that portion of the type 
will not be subject to static constraints.

If type annotations are not available, then types \textbf{propagated upward} from context. 
The actual type of a term can be inferred in an obvious way.

\begin{lstlisting}

#cons("hello",#cons("world",#nil())) : 
#cons(str $\times$ #cons(str $\times$ #nil$\diamondsuit$))

\end{lstlisting}

To infer expected types, type inference techniques for ML-family languages 
are a good starting point.
ML-family type inference is sound, because an ML term is 
intrinsically associated with a static bound in accordance with ML's datatype mechanism.
Terms in dynamically typed languages are not intrinsically associated with a principal type. 
Type inference for dynamically typed languages cannot be sound without greatly violating the 
liberal reuse of terms afforded by dynamic types. 

Thus, it is necessary to devise a method of type inference that is unsound, 
yet still provides sufficient information to guide efficient program synthesis.
Additionally, despite being unsound, it should be able to prune/reject 
a significant portion of bad programs. 
It may reject good programs, but only if it can infer a static type.

In parametric types where a generic input type must be the same as a generic output type,
The dynamic nature of terms is at odds with inferring types.

\begin{lstlisting}
($\lambda$ pair : $\forall$ $\alpha$ . $\alpha$ $\rightarrow$ $\alpha$ $\rightarrow$ ($\alpha$ $\times$ $\alpha$) $\Rightarrow$ 
($\lambda$ n : int $\Rightarrow$ ($\lambda$ s : str $\Rightarrow$ 
  pair n s
)))
\end{lstlisting}

\noindent These generic types can be specialized based on the terms that are witnessed as inputs. 
Since the principal type of any term in dynamically typed languages is top, 
The parameter type must accommodate types of unforeseen arguments, 
while the return type should be \textbf{widened} but restricted 
to previously seen arguments.
This system tackles the tension in these goals by combining the union combinator  
with the dynamic type. 

Once \lstinline{pair} is applied to an integer its generic type is specialized to 
\lstinline{(int | ?)}, 
in which union with the dynamic type behaves like the top type $\top$, 
accommodating receiving a string as a the subsequent input.
Thus, the generic type is specialized to \lstinline{(int | str | ?)}.
The result type for \lstinline{(pair n s)} ends up as 
\lstinline{(int | string) $\times$ (int | string)}. 
The semantics of union with the dynamic type result in the dynamic type 
falling away for actual types.

In functions where a parameter has an unknown type and that parameter is 
internally used as an argument to an application, the dynamic nature of terms  
adds some complications to type inference.

\begin{lstlisting}
($\lambda$ i2n : int $\rightarrow$ nat $\Rightarrow$ 
($\lambda$ s2n : str $\rightarrow$ nat $\Rightarrow$ 
  $\lambda$ x $\Rightarrow$ (i2n x, s2n x)
))

\end{lstlisting}

The argument type must avail itself to internal parameter types of unforeseen compositions,
while the external parameter type should be \textbf{narrowed} and restricted 
to the internal parameter types of previously seen compositions.
Once \lstinline{i2n} is applied to \lstinline{x}, 
the type for \lstinline{x} is specialized to \lstinline{(int & ?)}, 
in which intersection with the dynamic type behaves like the bottom type $\bot$,
availing itself to be used in subsequent applications. 
Thus, the dynamic type is inferred to be \lstinline{(int & str & ?)}.
The external parameter type for ends up as \lstinline{(int & str)}. 
The semantics of intersection with the dynamic type result in the dynamic type
falling away for expected types.



In order to efficiently guide program synthesis, 
types must be able to \textbf{express} fairly precise information. 
The system presented here offers types with 
expressivity comparable to typical decidable predicate logics. \\
\hfill \\
For example, types can also specify a pair of a list and its length.

\begin{lstlisting}[]
let measurement : $\mu$ (nat $\times$ list) .
  #zero $\diamondsuit$ $\times$ #nil $\diamondsuit$ | 
  #succ nat $\times$ #cons (? $\times$ list)
\end{lstlisting} 

\hfill

\noindent This is syntactic sugar for:

\begin{lstlisting}[]
let measurement : 
$\exists$ $\alpha$ . $\mu$ nat_and_list .
  #zero $\diamondsuit$ $\times$ #nil $\diamondsuit$ | 
  $\exists$ nat list :: 
    (nat $\times$ list) $\leq$ nat_and_list .
    #succ nat $\times$ #cons ($\alpha$ $\times$ list)
\end{lstlisting}

\hfill

\noindent Semantically, the type of measurement is similar to the definition of 
list and length in Synquid \cite{}    

\begin{lstlisting}[keywords={termination, measure, data, where}]
termination measure len :: List $\beta$ $\rightarrow$ Nat 
data List $\beta$ where
  Nil :: {v: List $\beta$ | len v = 0}
  Cons :: $\beta$ $\rightarrow$ xs: List $\beta$ $\rightarrow$ 
    {v: List $\beta$ | len v = len xs + 1}

\end{lstlisting}

\hfill

\noindent Correspondingly, the types are expressive enough to precisely specify
a function that takes a natural number \lstinline{n} 
and an element, and returns a list of \lstinline{n} elements.

\begin{lstlisting}[]
let replicate : 
$\forall$ $\alpha$ . $\alpha$ $\rightarrow$ $\nu$ (nat $\rightarrow$ list) .
  #zero $\diamondsuit$ $\rightarrow$ #nil $\diamondsuit$ & 
  #succ nat $\rightarrow$ #cons ($\alpha$ $\times$ list)
\end{lstlisting}



\hfill

\noindent This is syntactic sugar for:

\begin{lstlisting}[]
let replicate : 
$\forall$ $\alpha$ . $\alpha$ $\rightarrow$ $\nu$ nat_to_list .
  #zero $\diamondsuit$ $\rightarrow$ #nil $\diamondsuit$ & 
  $\forall$ nat list :: 
    nat_to_list $\leq$ (nat $\rightarrow$ list) .
    #succ nat $\rightarrow$ #cons ($\alpha$ $\times$ list)
\end{lstlisting}

\hfill

\noindent The type of \lstinline{replicate} is co-recursive rather than recursive. 
When expanded to the type with a universal type and constraint, 
the universally typed variables appear on the right hand side 
of the subtyping constraint, while the co-recursive variable
appears on the left hand side. This is consistent with the notion
that a intersection of types is a subtype of any one of its parts.

\hfill

\noindent Semantically, the type of \lstinline{replicate} is similar to the definition of 
\lstinline{replicate} in Synquid \cite{}    

\begin{lstlisting}[keywords={termination, measure, data, where}]
replicate :: n:Nat $\rightarrow$ x:$\alpha$ $\rightarrow$ 
  {v: List $\alpha$ | len v = n}

\end{lstlisting}

\hfill

\noindent The term for \lstinline{replicate} could be represented by a recursive function built using \lstinline{fix} 

\begin{lstlisting}[]
let replicate = 
$\lambda$ x $\Rightarrow$ fix ($\lambda$ self $\Rightarrow$
  $\lambda$ #zero () $\Rightarrow$ #nil () ;
  $\lambda$ #succ n $\Rightarrow$ #cons (x, self n)
) 
\end{lstlisting}


\section{Language specification}
\begin{enumerate}
  \item english statement 
\end{enumerate}
\subsection{Syntax}


\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
      t 
      &{} ::=
      \begin{array}[t]{@{} l}
        \_ 
        \ |\ 
        () 
        \ |\ 
        x
        \ |\ 
        l\#t 
        \ |\ 
        \omega\ \widebar{l := t}
        \ |\ 
        \lambda\ \widebar{t : \tau \Rightarrow t :: cs} 
        \ |\ 
        t/l
        \ |\ 
        t\ t
        \ |\ 
        \text{let } x : \tau = t\ \text{in } t
        \ |\ 
        \text{fix } t
      \end{array}
      \\
      \tau
      &{} ::=
      \begin{array}[t]{@{} l}
        \alpha 
        \ |\ 
        \bot 
        \ |\ 
        \top 
        \ |\ 
        l*\tau 
        \ |\ 
        l\sim\tau 
        \ |\ 
        \tau\rightarrow\tau 
        \ |\ 
        \exists \widebar{\alpha} :: \tau \leq \tau \ .\ \tau 
        \ |\ 
        \forall \widebar{\alpha} :: \tau \leq \tau \ .\ \tau 
        \ |\ 
        \mu \alpha.\tau 
        \ |\ 
        \nu \alpha.\tau 
        \ |\ 
        \tau \vee \tau
        \ |\ 
        \tau \wedge \tau
      \end{array}
    \end{array}
  \]
  \caption{Syntax}
\end{figure*}






\begin{enumerate}
  \item rules 
\end{enumerate}

\subsection{Operational semantics}
\begin{enumerate}
  \item rules 
\end{enumerate}

\subsection{Typing}

\begin{figure*}[h]
  \begin{mathpar}
    \inferrule[Hole] { 
    } {
      \Gamma \vdash \_ : \tau
    } 

    \inferrule[Unit] { 
    } {
      \Gamma \vdash () : \diamondsuit
    } 

    \inferrule[Var] { 
      (x \mapsto \tau) \in \Gamma
    } {
      \Gamma \vdash x : \tau  
    } 

    \\\\

    \inferrule[Tag] { 
      \Gamma \vdash t : \tau
    } {
      \Gamma \vdash l\#t : l*\tau  
    }

    \inferrule[Record] { 
      \bigwedge_{l\sim\tau} 
      \bigwedge_{l:=t} 
      \Gamma \vdash t : \tau
    } {
      \Gamma \vdash \omega\ (\widebar{l:=t}) : (\text{reduce} \wedge \widebar{l\sim\tau})  
    } 

    \inferrule[Function] {
      \bigwedge_{(\tau_1 \rightarrow \tau_2)} 
      \bigwedge_{(t_1 : \tau_1 \Rightarrow t_2)} 
      \Gamma_1 \vdash t_1 : \tau_1
      \ \wedge\
      \Gamma;\Gamma_1 \vdash t_2 : \tau_2
    } {
      \Gamma \vdash \lambda\ (\widebar{t_1 : \tau_1\Rightarrow t_2}) : (\text{reduce} \wedge \widebar{\tau_1 \rightarrow \tau_2})  
    } 

    \\\\

    \inferrule[Proj] {
      \Gamma \vdash t : l\sim\tau 
    } {
      \Gamma \vdash t/l : \tau 
    } 

    \inferrule[App] { 
      \Gamma \vdash t_1 : \tau_1 \rightarrow \tau
      \\
      \Gamma \vdash t_2 : \tau_1
    } {
      \Gamma \vdash (t_1\ t_2) : \tau 
    } 

    \\\\

    \inferrule[Let] { 
      \cdot \vdash (\forall \widebar{\alpha} :: \tau_3 \leq \tau_4\ .\ \tau_5) \leq \tau_1
      \\\\
      \Gamma \vdash t_1 : \exists \widebar{\alpha} :: \tau_3 \leq \tau_4\ .\ \tau_5
      \\\\
      \Gamma,x \mapsto (\forall \widebar{\alpha} :: \tau_3 \leq \tau_4\ .\ \tau_5)
        \vdash t_2 : \tau_2
    } {
      \Gamma \vdash 
        (\text{let}\ x : \tau_1 = t_1 \text{ in } t_2) 
        : \tau_2
    } 

    \inferrule[Fix] { 
      \Gamma \vdash t : \tau \rightarrow \tau 
    } {
      \Gamma \vdash \text{fix}\ t : \tau 
    } 

    \inferrule[Subsump] { 
      \Gamma \vdash t : \tau'
      \\
      \cdot \vdash \tau' \leq \tau
      \
    } {
      \Gamma \vdash 
        t : \tau
    } 
  \end{mathpar}
  \caption{Typing}
\end{figure*}


\subsection{Subtyping}

\begin{figure*}[h]
  \begin{mathpar}
    \inferrule[refl] {
    } {
       \Delta \vdash \tau \leq \tau
    }

    \inferrule[bottom] {
    } {
      \Delta \vdash \bot \leq \tau
    }

    \inferrule[top] {
    } {
      \Delta \vdash \tau \leq \top
    } 
    \\\\

    \inferrule[tag] {
      \Delta \vdash \tau_1 \leq \tau_2
    } {
      \Delta \vdash 
        l*\tau_1 \leq l*\tau_2
    } 

    \inferrule[field] {
      \Delta \vdash 
        \tau_1 \leq \tau_2
    } {
      \Delta \vdash 
        l\sim\tau_1 \leq l\sim\tau_2
    } 

    \inferrule[case] {
      \Delta \vdash \tau_3 \leq \tau_1 
      \\
      \Delta \vdash 
        \tau_2 \leq \tau_4
    } {
      \Delta \vdash 
        \tau_1 \rightarrow \tau_2 \leq \tau_3 \rightarrow \tau_4
    } 

    \\\\

    \inferrule[exis-symm] { 
      \Delta;\Delta_1 \vdash \tau_3 \leq \tau_6
      \\
      \Delta;\Delta_1; \vdash \tau_4 \leq \tau_5
      \\\\
      \Delta;\Delta_1 \vdash \tau_4 \leq \tau_1
      \\
      \text{freevars } \Delta \cap \widebar{\alpha_1} = \emptyset 
      \\\\
      \Delta;\Delta_1 \vdash \tau_1 \leq \tau_2
      \\
      \text{freevars } \Delta \cap \widebar{\alpha_2} = \emptyset 
      \\\\
      \Delta;\Delta_1 \vdash \tau_2 \leq \tau_5
    } { 
      \Delta \vdash 
        (\exists \widebar{\alpha_1} :: \tau_1 \leq \tau_2\ .\ \tau_3)
        \leq 
        (\exists \widebar{\alpha_2} :: \tau_4 \leq \tau_5\ .\ \tau_6)
    }

    \inferrule[exis-rhs] { 
      \Delta;\Delta_1 \vdash \tau_1 \leq \tau_4
      \\
      \text{freevars } \Delta \cap \widebar{\alpha} = \emptyset 
      \\\\
      \Delta;\Delta_1 \vdash 
        \tau_2 \leq \tau_3
    } { 
      \Delta \vdash 
        \tau_1
        \leq 
        (\exists \widebar{\alpha} :: \tau_2 \leq \tau_3\ .\ \tau_4)
    }
    
    \\\\

    \inferrule[univ-symm] { 
      \Delta;\Delta_1 \vdash \tau_3 \leq \tau_6
      \\
      \Delta;\Delta_1 \vdash \tau_1 \leq \tau_2
      \\\\
      \Delta;\Delta_1 \vdash \tau_1 \leq \tau_4
      \\
      \text{freevars } \Delta \cap \widebar{\alpha_1} = \emptyset 
      \\\\
      \Delta;\Delta_1 \vdash \tau_4 \leq \tau_5
      \\
      \text{freevars } \Delta \cap \widebar{\alpha_2} = \emptyset 
      \\\\
      \Delta;\Delta_1 \vdash \tau_5 \leq \tau_2
    } { 
      \Delta \vdash 
        (\forall \widebar{\alpha_1} :: \tau_1 \leq \tau_2\ .\ \tau_3)
        \leq 
        (\forall \widebar{\alpha_2} :: \tau_4 \leq \tau_5\ .\ \tau_6)
    }

    \inferrule[univ-lhs] { 
      \Delta;\Delta_1 \vdash \tau_3 \leq \tau_4
      \\
      \text{freevars } \Delta \cap \widebar{\alpha} = \emptyset 
      \\\\
      \Delta;\Delta_1 \vdash 
        \tau_1 \leq \tau_2
    } { 
      \Delta \vdash 
        (\forall \widebar{\alpha} :: \tau_1 \leq \tau_2\ .\ \tau_3)
        \leq 
        \tau_4
    }

    \\\\

    \inferrule[recur-symm] { 
      \Delta \vdash \tau_1[\alpha_1\mapsto\mu\alpha_2.\tau_2] \leq \tau_2[\alpha_2\mapsto\mu\alpha_2.\tau_2]
    } {
      \Delta \vdash \mu \alpha_1 . \tau_1 \leq \mu \alpha_2 . \tau_2
    }

    \inferrule[recur-roll] {
    } {
       \Delta \vdash \tau[\alpha\mapsto\mu \alpha . \tau] \leq\mu \alpha . \tau
    }

    \inferrule[recur-unroll] {
    } {
       \Delta \vdash \mu\alpha.\tau \leq \tau[\alpha\mapsto\mu \alpha . \tau]
    }

    \inferrule[corec-symm] { 
      \Delta \vdash \tau_1[\alpha_1\mapsto\nu\alpha_1.\tau_1] \leq \tau_2[\alpha_2\mapsto\nu\alpha_1.\tau_1]
    } {
      \Delta \vdash \nu \alpha_1 . \tau_1 \leq \nu \alpha_2 . \tau_2
    }

    \inferrule[corec-roll] {
    } {
       \Delta \vdash \tau[\alpha\mapsto\nu \alpha . \tau] \leq\nu \alpha . \tau
    }

    \inferrule[corec-unroll] {
    } {
       \Delta \vdash \nu\alpha.\tau \leq \tau[\alpha\mapsto\nu \alpha . \tau]
    }


    \inferrule[union-left] {
      \Delta \vdash \tau_1 \leq \tau_3
      \\
      \Delta \vdash \tau_2 \leq \tau_3
    } {
      \Delta \vdash \tau_1 \vee \tau_2 \leq \tau_3
    }

    \inferrule[union-rght-left] {
    } {
      \Delta \vdash \tau_1 \leq \tau_1 \vee \tau_2
    }

    \inferrule[union-rght-rght] {
    } {
      \Delta \vdash \tau_2 \leq \tau_1 \vee \tau_2
    }

    \\\\

    \inferrule[inter-right] {
      \Delta \vdash \tau \leq \tau_1
      \\
      \Delta \vdash \tau \leq \tau_2
    } {
      \Delta \vdash \tau \leq \tau_1 \wedge \tau_2
    }

    \inferrule[inter-left-left] {
    } {
      \Delta \vdash \tau_1 \wedge \tau_2 \leq \tau_1
    }

    \inferrule[inter-left-rght] {
    } {
      \Delta \vdash \tau_1 \wedge \tau_2 \leq \tau_2
    }
  \end{mathpar}
  \caption{Subtyping}
\end{figure*}

\begin{enumerate}
  \item typing and subtyping rules 
  \item soundness proof 
\end{enumerate}

\section{Language algorithms}
\begin{enumerate}
  \item english statement 
\end{enumerate}
\subsection{Program synthesis}
\subsection{Type inference}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      \_ : \tau
      &{} =
      \{\cdot.\tau\}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      () : \tau
      &{} =
      \begin{array}[t]{@{} l}
        \{\Delta_1.\diamondsuit\ |
        \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \diamondsuit \leq \tau
        \}
      \end{array}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      x : \tau
      &{} =
      \begin{cases}  
        \{\Delta_1.\tau_1\ |
        \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau
        \}
        &\text{if } \Gamma(x) = \text{some } \tau_1
        \\
        \{\}
        &\text{if } \Gamma(x) = \text{none}
      \end{cases}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      l \# t : \tau
      &{} =
      \begin{array}[t]{@{} l}
        \text{let } \alpha = \text{typevar}() 
        \\
        \{\Delta_1;\Delta_2\ .\ l \# \tau_1 \ |
        \\
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash l \# \alpha \leq \tau
        \\
        \ \ \ \ (\Delta_2.\tau_1) \in \text{infer } \iota\ \Delta;\Delta_1\ \Gamma \vdash t : \alpha
        \\
        \}
      \end{array}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      \omega[ fields ] : \tau
      &{} =
      \begin{array}[t]{@{} l}
        \text{let } fields' = \{(l:=t, \text{typevar}())\ |\ (l:=t) \in fields \}
        \\
        \text{let } \tau_1 = \text{reduce} \wedge \{l \sim \alpha\ |\ (l := t, \alpha) \in fields' \}
        \\


        \text{reduce} * \{
        \text{infer } \iota\ \Delta;\Delta_1\ \Gamma \vdash t : \alpha\ |\ 
        \\
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta\ \vdash \tau_1 \leq \tau
        \\
        \ \ \ \ (l := t, \alpha) \in fields'
        \\
        \}
        \\
      \end{array}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      \lambda[ cases ] : \tau
      &{} =
      \begin{array}[t]{@{} l}
        \text{let } cases' = \{(t_1 : \tau_1 \Rightarrow t_2, \text{typevar}())\ |\ (t_1 : \tau_1 \Rightarrow t_2) \in cases \}
        \\
        \text{let } \tau_3 = \text{reduce} \wedge \{\tau_1 \rightarrow \alpha\ |\ (t_1 : \tau_1 \Rightarrow t_2, \alpha) \in cases' \}
        \\


        \text{reduce} * \{
        \text{infer } \iota\ \Delta;\Delta_1;\Delta_2\ \Gamma;\Gamma_1 \vdash t_2 : \alpha\ |\ 
        \\
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta\ \vdash \tau_3 \leq \tau
        \\
        \ \ \ \ (t_1 : \tau_1 \Rightarrow t_2, \alpha) \in cases'
        \\
        \ \ \ \ \Gamma_1 \in \{\text{patenv } t_1\}
        \\
        \ \ \ \ \Delta_2.\tau_1' \in \text{infer } \blacksquare\ \Delta;\Delta_1\ \Gamma;\Gamma_1\ \vdash t_1 : \tau_1
        \\
        \}
        \\
      \end{array}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      t/l : \tau
      &{} =
      \begin{array}[t]{@{} l}
        % \text{let } \alpha = \text{typevar}()
        % \\
        \{ \Delta_1;\Delta_2\ .\ \tau \ |\
        \\
        \ \ \ \ \Delta_1.\tau_1 \in \text{infer } \iota\ \Delta\ \Gamma \vdash t : l \sim \tau 
        % \\
        % \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_1 \leq l \sim \alpha
        \\
        \}
      \end{array}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      (t_1\ t_2) : \tau
      &{} =
      \begin{array}[t]{@{} l}
        \text{let } \alpha = \text{typevar}()
        \\
        \{ \Delta_1;\Delta_2\ .\ \tau \ |\
        \\
        \ \ \ \ \Delta_1.\tau_1 \in \text{infer } \iota\ \Delta\ \Gamma \vdash t_1 : (\alpha \rightarrow \tau) 
        \\
        \ \ \ \ \Delta_2.\tau_2 \in \text{infer } \iota\ \Delta;\Delta_1\ \Gamma \vdash t_2 : \alpha
        \\
        % \text{let } \alpha_2 = \text{typevar}()
        % \ \ \ \ \Delta_3 \in \text{unify } \iota\ \Delta;\Delta_1;\Delta_2 \vdash \tau_1 \leq \tau_2 \rightarrow \alpha_2
        % \\
        \}
      \end{array}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      (\text{let}\ x : \tau_1 := t_1 \Rightarrow t_2) : \tau_2
      &{} =
      \begin{array}[t]{@{} l}
        \text{let } \alpha_1 := \text{typevar}()
        \\
        \{ \Delta_3\ .\ \tau_2' \ |\ 
        \\
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta\ \vdash \tau_1 \leq \alpha_1
        \\
        \ \ \ \ \Delta_2.\tau_1' \in \text{infer } \iota\ \Delta;\Delta_1\ \Gamma \vdash t_1 : \alpha_1
        \\ 
        \ \ \ \ \tau_1'' \in \{\tau_1'[\Delta_1;\Delta_2]\}
        \\ 
        \ \ \ \ \widebar{\alpha} \in \{\text{freevars}\ \tau_1''\}
        \\ 
        \ \ \ \ \Delta_3.\tau_2' \in \Delta\ \Gamma,x \mapsto \forall \widebar{\alpha} . \tau_1''
          \vdash t_2 : \tau_2 
        \\
        \} 
      \end{array}
      \\

      \text{infer } \iota\ \Delta\ \Gamma \vdash 
      \text{fix } t : \tau      
      &{} =
      \begin{array}[t]{@{} l}
        \text{let } \alpha_1 = \text{typevar}()
        \\
        \text{let } \alpha_2 = \text{typevar}()
        \\
        \{ \Delta_1;\Delta_2\ .\ \nu\ \alpha_4 \ . \forall\ \widebar{\alpha_3} ::
          \alpha_4 \leq \tau_2\ .  \tau_3
          \ |\ 
        \\
        \ \ \ \ \Delta_1.\tau_1 \in
        \text{infer } \blacksquare\ \Delta\ \Gamma \vdash t : \tau \rightarrow \tau
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \blacksquare\ \Delta;\Delta_1 \vdash 
        \tau_1 \leq \alpha_1 \rightarrow \alpha_2 
        \\
        \ \ \ \ \tau_2 \in \{\alpha_1[\Delta;\Delta_1;\Delta_2]\}
        \\ 
        \ \ \ \ \tau_3 \in \{\alpha_2[\Delta;\Delta_1;\Delta_2]\} 
        \\
        \ \ \ \ \widebar{\alpha_3} \in \{ \text{freevars}\ \tau_2 \}
        \\
        \} 
      \end{array}
    \end{array}
  \]
  \caption{Type inference}
\end{figure*}


\begin{enumerate}
  \item definition 
  \item lemmas and proofs 
\end{enumerate}

\subsection{Subtype unification}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
      \text{unify } \iota\ \Delta \vdash \alpha_1 
      \leq 
      (\exists \widebar{\alpha_2} :: \tau_1 \leq \tau_2 \ .\ \tau_3)
      &{} =
      \begin{cases}
        \{ 
          \cdot,\alpha_1 \mapsto 
          \nu\alpha_1.(\forall \widebar{\alpha_2} :: \tau_1 \leq \tau_2 \ .\ \tau_3)
        \}
        & \text{if } 
        \Delta(\alpha_1) = \text{none} \ \wedge\
        \alpha_1 \in \text{freevars}(\tau[\Delta])
        \\
        \{ 
          \cdot,\alpha_1 \mapsto 
          (\forall \widebar{\alpha_2} :: \tau_1 \leq \tau_2 \ .\ \tau_3)
        \}
        & \text{if } 
        \Delta(\alpha_1) = \text{none} \ \wedge\
        \alpha_1 \in \text{freevars}(\tau[\Delta])
        \\
        \text{unify } \iota\ \Delta \vdash 
        \tau_4
        \leq
        (\exists \widebar{\alpha_2} :: \tau_1 \leq \tau_2 \ .\ \tau_3)
        &\text{if }
        \Delta(\alpha_1) = \text{some } \tau_4
      \end{cases}
      \\

      \text{unify } \iota\ \Delta \vdash 
      (\forall \widebar{\alpha_1} :: \tau_1 \leq \tau_2 \ .\ \tau_3)
      \leq 
      \alpha_2
      &{} =
      \begin{cases}  
        \{ 
          \cdot,\alpha_2 \mapsto 
          \mu \alpha_2 . (\exists \widebar{\alpha_1} :: \tau_1 \leq \tau_2 \ .\ \tau_3)
        \}
        & \text{if } 
        \Delta(\alpha_2) = \text{none} \ \wedge\
        \alpha_2 \in \text{freevars}(\tau[\Delta])
        \\
        \{ 
          \cdot,\alpha_2 \mapsto 
          (\exists \widebar{\alpha_1} :: \tau_1 \leq \tau_2 \ .\ \tau_3)
        \}
        & \text{if } 
        \Delta(\alpha_2) = \text{none} \ \wedge\ 
        \alpha_2 \notin \text{freevars}(\tau[\Delta])
        \\
        \text{unify } \iota\ \Delta \vdash 
        (\forall \widebar{\alpha_1} :: \tau_1 \leq \tau_2 \ .\ \tau_3)
        \leq  
        \tau_4
        &\text{if }
        \Delta(\alpha_2) = \text{some } \tau_4
      \end{cases}  
      \\


      \text{unify } \blacksquare\ \Delta \vdash \alpha \leq \tau	
      &{} =
      \begin{cases}  
        \{ \cdot,\alpha \mapsto \nu\alpha.\tau \}
        & \text{if } 
        \Delta(\alpha) = \text{none} \ \wedge\
        \alpha \in \text{freevars}(\tau[\Delta])
        \\
        \{ \cdot,\alpha \mapsto \tau \}
        & \text{if } 
        \Delta(\alpha) = \text{none} \ \wedge\ 
        \alpha \notin \text{freevars}(\tau[\Delta])
        \\
        \text{unify } \blacksquare\ \Delta \vdash \tau_1 \leq \tau
        &\text{if }
        \Delta(\alpha) = \text{some } \tau_1
      \end{cases}
      \\

      \text{unify } \square\ \Delta \vdash \alpha \leq \tau	
      &{} =
      \begin{cases}  
        \{ \cdot,\alpha \mapsto (\nu\alpha.\tau \wedge \beta) \}
        & \text{if } 
        \Delta(\alpha) = \text{none} \ \wedge\ 
        \alpha \in \text{freevars}(\tau[\Delta]) \ \wedge\ 
        \text{fresh } \beta
        \\
        \{ \cdot,\alpha \mapsto \tau \wedge \beta \}
        & \text{if } 
        \Delta(\alpha) = \text{none} \ \wedge\ 
        \alpha \notin \text{freevars}(\tau[\Delta]) \ \wedge\ 
        \text{fresh } \beta
        \\
        \text{unify } \square\ \Delta \vdash \tau_1 \leq \tau
        &\text{if }
        \Delta(\alpha) = \text{some } \tau
      \end{cases}
      \\
      \text{unify } \blacksquare\ \Delta \vdash \tau \leq \alpha 	
      &{} =
      \begin{cases}  
        \{ \cdot,\alpha \mapsto \mu\alpha.\tau \}
        & \text{if } 
        \Delta(\alpha) = \text{none} \ \wedge\
        \alpha \in \text{freevars}(\tau[\Delta])
        \\
        \{ \cdot,\alpha \mapsto \tau \}
        & \text{if } 
        \Delta(\alpha) = \text{none} \ \wedge\ 
        \alpha \notin \text{freevars}(\tau[\Delta])
        \\
        \text{unify } \blacksquare\ \Delta \vdash \tau \leq \tau_1
        &\text{if }
        \Delta(\alpha) = \text{some } \tau_1
      \end{cases}
      \\
      \text{unify } \square\ \Delta \vdash \tau \leq \alpha	
      &{} =
      \begin{cases}  
        \{ \cdot,\alpha \mapsto (\mu\alpha.\tau \vee \beta) \}
        & \text{if } 
        \Delta(\alpha) = \text{none} \ \wedge\ 
        \alpha \in \text{freevars}(\tau[\Delta]) \ \wedge\ 
        \text{fresh } \beta
        \\
        \{ \cdot,\alpha \mapsto \tau \vee \beta \}
        & \text{if } 
        \Delta(\alpha) = \text{none} \ \wedge\ 
        \alpha \notin \text{freevars}(\tau[\Delta]) \ \wedge\ 
        \text{fresh } \beta
        \\
        \text{unify } \square\ \Delta \vdash \tau \leq \tau_1
        &\text{if }
        \Delta(\alpha) = \text{some } \tau
      \end{cases}
      \\
      \text{unify } \iota\ \Delta \vdash \bot \leq \_	
      &{} = 
      \{\cdot\}
      \\
      \text{unify } \iota\ \Delta \vdash \_ \leq \top	
      &{} = 
      \{\cdot\}
      \\
      \text{unify } \iota\ \Delta \vdash \diamondsuit \leq \diamondsuit	
      &{} = 
      \{\cdot\}
      \\
      \text{unify } \iota\ \Delta \vdash l*\tau_1 \leq l*\tau_2	
      &{} = 
      \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_2
      \\
      \text{unify } \iota\ \Delta \vdash l\sim\tau_1 \leq l\sim\tau_2	
      &{} = 
      \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_2
      \\
      \text{unify } \iota\ \Delta \vdash \tau_1\rightarrow\tau_2 \leq \tau_3\rightarrow\tau_4	
      &{} = 
      \begin{array}[t]{@{} l}
        \{\Delta_1;\Delta_2\ |
        \\ 
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_3 \leq \tau_1
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_4 \leq \tau_2
        \\
        \}
      \end{array}

    \end{array}
  \]
  \caption{Subtype unification: part 1}
\end{figure*}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
      \text{unify } \iota\ \Delta \vdash
      (\exists \widebar{\alpha_1} :: \tau_1 \leq \tau_2\ .\ \tau_3)
      \leq 
      (\exists \widebar{\alpha_2} :: \tau_4 \leq \tau_5\ .\ \tau_6)
      &{} = 
      \begin{array}[t]{@{} l}
        \text{let } \tau_1, \tau_2, \tau_3 = 
        \text{refresh } \widebar{\alpha_1}\ \tau_1,\ 
        \text{refresh } \widebar{\alpha_1}\ \tau_2,\ 
        \text{refresh } \widebar{\alpha_1}\ \tau_3
        \\
        \text{let } \tau_4, \tau_5, \tau_6 = 
        \text{refresh } \widebar{\alpha_2}\ \tau_4,\ 
        \text{refresh } \widebar{\alpha_2}\ \tau_5,\ 
        \text{refresh } \widebar{\alpha_2}\ \tau_6
        \\
        \{\Delta_1;\Delta_2;\Delta_3;\Delta_4;\Delta_5\ |
        \\ 
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_3 \leq \tau_6
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_4 \leq \tau_5
        \\
        \ \ \ \ \Delta_3 \in \text{unify } \iota\ \Delta;\Delta_1;\Delta_2 \vdash \tau_4 \leq \tau_1
        \\
        \ \ \ \ \Delta_4 \in \text{unify } \iota\ \Delta;\Delta_1;\Delta_2;\Delta_3 \vdash \tau_1 \leq \tau_2
        \\
        \ \ \ \ \Delta_4 \in \text{unify } \iota\ \Delta;\Delta_1;\Delta_2;\Delta_3;\Delta_4 \vdash \tau_2 \leq \tau_5
        \\
        \}
      \end{array}
      \\
      \text{unify } \iota\ \Delta \vdash
      \tau_1
      \leq 
      (\exists \widebar{\alpha} :: \tau_2 \leq \tau_3\ .\ \tau_4)
      &{} = 
      \begin{array}[t]{@{} l}
        \text{let } \tau_2, \tau_3, \tau_4 = 
        \text{refresh } \widebar{\alpha}\ \tau_2,\ 
        \text{refresh } \widebar{\alpha}\ \tau_3,\ 
        \text{refresh } \widebar{\alpha}\ \tau_4
        \\
        \{\Delta_1;\Delta_2\ |
        \\ 
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_4
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_2 \leq \tau_3
        \\
        \}
      \end{array}
      \\
      \text{unify } \iota\ \Delta \vdash
      (\forall \widebar{\alpha_1} :: \tau_1 \leq \tau_2\ .\ \tau_3)
      \leq 
      (\forall \widebar{\alpha_2} :: \tau_4 \leq \tau_5\ .\ \tau_6)
      &{} = 
      \begin{array}[t]{@{} l}
        \text{let } \tau_1, \tau_2, \tau_3 = 
        \text{refresh } \widebar{\alpha_1}\ \tau_1,\ 
        \text{refresh } \widebar{\alpha_1}\ \tau_2,\ 
        \text{refresh } \widebar{\alpha_1}\ \tau_3
        \\
        \text{let } \tau_4, \tau_5, \tau_6 = 
        \text{refresh } \widebar{\alpha_2}\ \tau_4,\ 
        \text{refresh } \widebar{\alpha_2}\ \tau_5,\ 
        \text{refresh } \widebar{\alpha_2}\ \tau_6
        \\
        \{\Delta_1;\Delta_2;\Delta_3;\Delta_4;\Delta_5\ |
        \\ 
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_3 \leq \tau_6
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_1 \leq \tau_2
        \\ 
        \ \ \ \ \Delta_3 \in \text{unify } \iota\ \Delta;\Delta_1;\Delta_2 \vdash \tau_1 \leq \tau_4
        \\ 
        \ \ \ \ \Delta_4 \in \text{unify } \iota\ \Delta;\Delta_1;\Delta_2;\Delta_3 \vdash \tau_4 \leq \tau_5
        \\ 
        \ \ \ \ \Delta_5 \in \text{unify } \iota\ \Delta;\Delta_1;\Delta_2;\Delta_3;\Delta_4 \vdash \tau_5 \leq \tau_2
        \\
        \}
      \end{array}
      \\
      \text{unify } \iota\ \Delta \vdash
      (\forall \widebar{\alpha} :: \tau_1 \leq \tau_2\ .\ \tau_3)
      \leq 
      \tau_4
      &{} = 
      \begin{array}[t]{@{} l}
        \text{let } \tau_1, \tau_2, \tau_3 = 
        \text{refresh } \widebar{\alpha}\ \tau_1,\ 
        \text{refresh } \widebar{\alpha}\ \tau_2,\ 
        \text{refresh } \widebar{\alpha}\ \tau_3
        \\
        \{\Delta_1;\Delta_2\ |
        \\ 
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_3 \leq \tau_4
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_1 \leq \tau_2
        \\
        \}
      \end{array}
      \\
      \text{unify } \iota\ \Delta \vdash
      \mu \alpha . \tau_1 \leq \mu \alpha . \tau_2
      &{} = 
      \Delta \vdash 
      \tau_1[\alpha_1\mapsto\mu\alpha_2.\tau_2] \leq 
      \tau_2[\alpha_2\mapsto\mu\alpha_2.\tau_2]

      \\
      \text{unify } \iota\ \Delta \vdash
      l * \tau_1 \leq \mu \alpha . \tau_2
      &{} = 
      \Delta \vdash  
      l * \tau_1 \leq\tau_2[\alpha\mapsto\mu\alpha.\tau_2]

      \\
      \text{unify } \iota\ \Delta \vdash
      \tau_1 \leq \mu \alpha . \tau_2
      &{} = 
      \begin{cases}  
        \text{unify } \iota\ \Delta \vdash 
        \tau_1 \leq \tau_2[\alpha\mapsto\mu\alpha.\tau_2]	
        &\text{if }
        \text{recordform } \Delta \vdash \tau_1
        \\
        \{\}
        &\text{otherwise}
      \end{cases}

      \\
      \text{unify } \iota\ \Delta \vdash
      \nu \alpha_1 . \tau_1 \leq 
      \nu \alpha_2 . \tau_2	
      &{} = 
      \text{unify } \iota\ \Delta \vdash 
      \tau_1[\alpha_1\mapsto\nu\alpha_1.\tau_1] \leq 
      \tau_2[\alpha_2\mapsto\nu\alpha_1.\tau_1]

      \\
      \text{unify } \iota\ \Delta \vdash
      \nu \alpha . \tau_1 \leq 
      \tau_2 \rightarrow \tau_3
      &{} = 
      \text{unify } \iota\ \Delta \vdash
      \tau_1[\alpha\mapsto\nu\alpha.\tau_1]
      \leq 
      \tau_2 \rightarrow \tau_3

      \\
      \text{unify } \iota\ \Delta \vdash
      \tau_1 \vee \tau_2 \leq \tau_3
      &{} = 
      \begin{array}[t]{@{} l}
        \{\Delta_1;\Delta_2\ |
        \\ 
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_3
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_2 \leq \tau_3
        \\
        \}
      \end{array}

      \\
      \text{unify } \iota\ \Delta \vdash
      \tau_1 \leq \tau_2 \vee \tau_3
      &{} = 
      (\text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_2)
      \cup
      (\text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_3)

      \\
      \text{unify } \iota\ \Delta \vdash
      \tau_1 \leq \tau_2 \wedge \tau_3
      &{} = 
      \begin{array}[t]{@{} l}
        \{\Delta_1;\Delta_2\ |
        \\ 
        \ \ \ \ \Delta_1 \in \text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_2
        \\
        \ \ \ \ \Delta_2 \in \text{unify } \iota\ \Delta;\Delta_1 \vdash \tau_1 \leq \tau_3
        \\
        \}
      \end{array}

      \\
      \text{unify } \iota\ \Delta \vdash
      \tau_1 \wedge \tau_2 \leq \tau_3
      &{} = 
      (\text{unify } \iota\ \Delta \vdash \tau_1 \leq \tau_3)
      \cup
      (\text{unify } \iota\ \Delta \vdash \tau_2 \leq \tau_3)

    \end{array}
  \]
  \caption{Subtype unification: part 2}
\end{figure*}

\begin{enumerate}
  \item definition 
  \item lemmas and proofs 
\end{enumerate}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
    \Delta\ ;\ \cdot
    &\ = \Delta 
    \\
    \Delta_1;(\Delta_2,\alpha \mapsto \tau) 
    &\ = (\Delta_1;\Delta_2),\alpha \mapsto \tau
    \end{array}
  \]

  \caption{Appending of environments}
\end{figure*}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
    M_1 * M_2 
    &\ = 
    [\Delta_1 ; \Delta_2 \ |\ 
      \Delta_1 \in M_1
      \ \ \  
      \Delta_2 \in M_2
    ]
    \end{array}
  \]

  \caption{Product of lists environments}
\end{figure*}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
    \text{reduce} \wedge [] 
    &\ = \top
    \\
    \text{reduce} \wedge \tau::\widebar{\tau}
    &\ = \tau\ \wedge (\text{reduce} \wedge \widebar{\tau})
    \end{array}
  \]

  \caption{Reduction of types}
\end{figure*}

\begin{figure*}[h]
  \[
    \begin{array}{l @{} l}
      N_1 * N_2
      &\ = 
      \begin{array}[t]{l}
        [ \Delta_1 ; \Delta_2 . \tau_1 \wedge \tau_2 \ |\ 
          \Delta_1.\tau_1 \in N_1
          \ \ 
          \Delta_2.\tau_2 \in N_2
        ]
      \end{array}
    \end{array}
  \]

  \caption{Product of lists of contextual types}
\end{figure*}

\begin{figure*}[h]
  \[
    \begin{array}{l @{}l}
    \text{reduce} * [N]
    & {}= N
    \\
    \text{reduce} * N::\widebar{N}
    & {}= N * (\text{reduce} * \widebar{N})
    \end{array}
  \]

  \caption{Reduction of lists of contextual types}
\end{figure*}




\section{Evaluation}
\begin{enumerate}
  \item experiments 
  \item adequacy of problem 
  \item adequacy of solution 
\end{enumerate}

\section{Related work}
\begin{enumerate}
  \item past work 
  \item future work 
\end{enumerate}

\section{Conclusion}
\begin{enumerate}
  \item restate context with technical terms 
  \item restate problem with technical terms 
  \item restate solution with technical terms 
  \item restate results 
\end{enumerate}

% \section*{Notes}

% \subsection*{dualities}
% \begin{enumerate}
%   \item \(\bot \leq \top \)
%   \item \(\tau_1\ \&\ \tau_2  \leq \tau_1\ |\ \tau_2 \)
%   \item \(\forall \alpha . \tau \leq \exists \alpha . \tau \)
%   \item \(\nu \alpha . \tau \leq \mu \alpha . \tau \)
% \end{enumerate}

% \subsection*{contributions}
% \begin{enumerate}
%   \item program synthesis such that:
%     \begin{enumerate}
%       \item goal defined by partial programs with missing annotations  
%       \item goal transformed into type specification 
%       \item type specification may contain dynamic type  
%     \end{enumerate}
%   \item algorithmic subsumption allows simple subtyping rule with dynamic type
%     \begin{enumerate}
%       \item subtyping can have a dynamic type on either side without risk of   
%         all terms being accepted by typing rules (i.e. everything typing)
%     \end{enumerate}
%   \item an expressive type system 
%     based on intersection, union, recursive, and co-recursive types
%     \begin{enumerate}
%       \item without dependent types 
%       \item comparable to prolog 
%       \item allows dynamic type 
%       \item sound modulo absence of dynamic type 
%         or static type union/intersect with dynamic
%       \item types behave either leniently or strict depending on usage as actual type or expected type
%     \end{enumerate}
%   \item full type synthesis with full type propagation (for all rules)
%   \item type unification such that: 
%     \begin{enumerate}
%       \item the principal type of all terms is top
%       \item lenient (but unsound) static type inference
%       \item expanding type info with union and intersection and dynamic type
%     \end{enumerate}
%   \item interleaving type constraint generation and solving with dynamic type 
% \end{enumerate}

% \subsection*{differences}
% in contrast with System F:  
% \begin{enumerate}
%   \item types are not used as arguments to functions 
%   \item universal binders do not represent placeholder for type argument 
% \end{enumerate}

% in contrast with gradual typing:  
% \begin{enumerate}
%   \item infers more static type info 
%   \item stronger soundness claim (i.e. weaker soundness precondition)
%   \item dynamic semantics are irrelevant 
%   \item deterministic subsumption 
%   \item dynamic type built into subtyping 
% \end{enumerate}

% in contrast with HM type inference:  
% \begin{enumerate}
%   \item synthesizes type in addition to constraint solution 
%     due to subtyping
%   \item propagates types
%   \item global top type, leaves types open during unification
%   \item expands and narrows types  
% \end{enumerate}

% in contrast with Roundtrip typing:  
% \begin{enumerate}
%   \item type combinators without dependent types
%   \item prolog-like type language  
%   \item synthesizes types for all rules
%   \item global top type, leaves types open during unification
%   \item expands and narrows types  
%   \item delegates to unification to decompose types 
%   \item delegates to unification to free bound variables 
% \end{enumerate}




% \subsection*{gradual typing}
% How gradually typed inference typically works:
% \begin{enumerate}
%   \item infer either a strict static type or a dynamic type
%   \item let annotations implicitly guide the usage of static vs dynamic checks 
% \end{enumerate}
% There exists work on type inference for gradually typed programs.
% To the best of my knowledge, they are all sound and complete.
% Other gradual type inference systems separate 
% generating constraints from solving constraints.
% Gradual typing systems use the dynamic type \lstinline{(?)} to indicate 
% that dynamic checks should be used.
% Gradual type inference relies on ML types with union extension.
% They do not contain the idea of using intersection and union to keep types open.
% Gradual typing systems separate subtyping from the relation 
% between dynamic to static types to avoid all terms typing via the subsumption rule.


% \subsection*{references}
% \begin{enumerate}
% \item Refinement types for ML by Tim Freeman and Frank Pfenning 
% \item Refinement types as proof irrelevance by William Lovas and Frank Pfenning 
% \item Local type inference by Benjamin C. Pierce and David N. Turner
% \item Liquid types - \url{http://goto.ucsd.edu/~rjhala/papers/liquid_types.pdf}
% \item Program synthesis from polymorphic refinement types by Nadia Polikarpova, Ivan Kuraj, and Armando Solar-Lezama
% \item Example-directed synthesis: a type-theoretic interpretation by Frankle, Osera, Walker, and Zdancewic
% \item Gradual typing for functional languages by Jeremy G. Siek and Walid Taha 
% \item Gradual typing for functional languages by Jeremy G. Siek and Walid Taha 
% \item Gradual typing for objects by Jeremy G. Siek and Walid Taha 
% \item Gradual typing with unification-based inference by Siek and Manish Vachharajani 
% \item Dynamic Type Inference for Gradual HindleyMilner Typing - \url{https://dl.acm.org/doi/pdf/10.1145/3290331}
% \item Principal type schemes for gradual programs - \url{https://www.cs.ubc.ca/~rxg/ptsgp.pdf}
% \item Gradual Liquid Type Inference - \url{https://arxiv.org/pdf/1807.02132.pdf}
% \item Gradual typing with union and intersection types - \url{https://dl.acm.org/doi/pdf/10.1145/3110285}
% \item Gradual typing: a new perspective - unions, intersections, dynamic type, and type inference - \url{https://www.irif.fr/~gc/papers/popl19.pdf}
% \item Gradual refinement types (via abstract interpretation) - \url{https://pleiad.cl/papers/2017/lehmannTanter-popl2017.pdf}
% \item Consistent subtyping for all - \url{https://xnning.github.io/papers/consistent-subtyping-for-all-toplas.pdf}
% \item Polymorphic functions with set-theoretic types, part 1 - \url{https://www.irif.fr/~gc/papers/polydeuces-part1.pdf}
% \item Polymorphic functions with set-theoretic types, part 2 - \url{https://www.irif.fr/~gc/papers/polydeuces-part2.pdf}
% \item Revisiting occurrence typing - \url{https://arxiv.org/pdf/1907.05590.pdf} 
% \item An ideal model for recursive polymorphic types; MacQueen, Plotkin, Sethi; Metric/Contraction/Banach fixed point theorem
% \item Bottom-up synthesis of recursive functional programs using angelic execution - Anders Miltner et al


% \end{enumerate}



\end{document}

% Observations:
% language of types
  % a type is a set of objects
  % a type may be viewed as proposition that may be undecidable 
    % proved by a term
% language of constraints
  % A constraint may be viewed as a decidable proposition 
  % A constraint is simply a subtyping relation over types
    % allowing economical reuse of types 
  % A fully assigned subtyping constraint is a verifiable statement
% Freeing variables happens in subtyping/unification due to subtyping asymmetry  
  % free variable in subtyping connects to free variable associated with term 
  % if expected type has free variable.
% unification is solving for the greatest fixedpoint
  % it terminates at a failure (bottom of lattice)
  % or it terminates at a variable assignment 
% Abstract interpretations' narrowing operator is embedded 
  % failure (bottom) when two type structures are incompatible
  % recursive types are only compatible with certain forms of compound types
% widening and narrowing in type inference
  % exactness param chosen during inference 
    % exactness flag is justified by dual purpose of type system
      % 1. catch errors (exactly according to spec)
      % 2. describe behavior of program abstractly
  % annotations are exact 
  % everything else is non-exact;
    % allowing union and intersection with fresh variables
% comparison of relational types with dependent types

  % dependent types
    % inductive LL : Nat -> Type where
    % | nil : LL 0 
    % | cons : {n : Nat} -> LL n -> LL (n + 1) 

    % F   (n : Nat) -> LL n
    % P   (n : Nat)  LL n

    % variable introduction is coupled with type construction/compounding
    % this is convenient since a type may dependent on a term that's not included in itself


  % relational types 
    % P  
    % (0^@  nil^@) | 
    % ( N L :: N  L  P => 1^N  cons^L) 

    % translating from dependent to relational
    %  {n : Nat}  LL n  LL (n + 1) 
    %  {n : Nat} {l: List} :: (l : LL n)  {(n + 1, cons l)}  
    % ( N L :: N  L  P => 1^N  cons^L) 

    % -- OR -- 

    % F  
    % (nil^@ -> 0^@) ; 
    % ( L N :: F  L -> N => cons^L -> 1^N) 

    % translating from dependent to relational
    %  {n : Nat} -> LL n -> LL (n + 1) 
    %  {n : Nat} {l: List} :: (l : LL n) -> {for cons l => n + 1}  
    % ( L N :: F  L -> N => cons^L -> 1^N) 


    % variable introduction is decoupled from type construction 
    % the use of a variable in a type is separate from introducing the variable
    % this is convenient since any term that a type depends on exists as a subpart
    % of a term in that type
    % Thus, dependencies may be inferred from terms.

    % My intuition is that the symmetrical relations 
    % and the decoupling of binder introduction from type combination 
    % and consistent treatment of type dependency and type membership 
    % provides an easier mental model to work with
  % closed parameter 
    % indicates if a constraint is closed vs open 
    % variables are fully determined in closed unification 
    % variables are are open to future information in open unification 




% TODO:
% write declarative typing and subtyping rules
  % non-deterministically introduce an environment for subtyping of universal 
  % without unification of bound variables 
  % write subsumption without everything typechecking
    % unassigned variables are not allowed
    % variables must be given a top or bottom type before subtyping check
% write paper 
  % - 0. introduction 
  % - 1. motivating example / overview 
  % - 2. problem statement 
  % - 3. overall synthesis/inference algorithm/rules 
    % include how type information propagates
    % abstract away relation type details
    % includes propagation of types
  % - 4. unification / subtyping / relational typing
    % including recursion over intersection and functions
% write "calculating definitions" as functions
  % must be algorithmic
  % more details; function is more compact
% write "verification definitions" as inference rules
  % may be undecidable 
% find decision procedure for relational types (subtyping over induction on compound types)
  % terminate if one side is compound with all variables and other is recursive? 
  % Banach fixed-point theorem?
  % contraction maps?
  % metric spaces?
% find efficient algorithm to mitigate combinatorial explosion 
  % due to intersection and union
  % SAT and SMT?
% extend type inference to program synthesis 
  % does angelic synthesis work for this?
% determine if negation/relative complement is needed to improve program synthesis 
  % see anti-specification in Anders' paper
  % https://courses.cs.washington.edu/courses/cse507/14au/sched.html
  % https://www.cs.utexas.edu/~bornholt/post/synthesis-explained.html
  % https://people.csail.mit.edu/asolar/SynthesisCourse/Lecture1.htm
% write dynamic semantics 
% implement proof of soundness
% implement translation from surface syntax to nameless syntax 
% implement pretty printer 