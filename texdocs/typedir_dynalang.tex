% \documentclass{article}
% \documentclass[]{acmart}
\documentclass[sigplan,screen]{acmart}

\usepackage{mathpartir}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{listings}
\lstset{
    identifierstyle=\color{violet},
    % textcolor=blue,
    % keywordstyle=\color{blue},
    keywordstyle=\text,
    basicstyle=\ttfamily,
    mathescape=true,
    showspaces=false,
    morekeywords={let, fix}
}
\usepackage[utf8]{inputenc}
% \usepackage[T1]{fontenc}


\title{Type-guided synthesis for dynamically typed languages}
\author{Thomas Logan}
\date{October 2022}

\begin{document}

\maketitle
\section{Introduction}


\textbf{Dynamically typed} languages can make writing programs quick and easy 
because they don't require specifying static bounds on behavior.
Two of the most popular programming languages today, JavaScript and Python, 
are dynamically typed. 
JavaScript is the language of the web, while Python is the most popular choice
for data science and machine learning projects. 
Consider a Python program that operates on strings or integers. 

\begin{lstlisting}[language=Python]
def foo(x):
    if isinstance(x, int):
        return x + 1 
    elif isinstance(x, str): 
        return x + "abc"
\end{lstlisting}

\noindent The dynamically typed program avoids the extra step of associating terms with
static bounds as seen in ML-family languages using the datatype mechanism. 

\begin{lstlisting}[language=ML]
datatype int_or_str = 
    Int of int | 
    Str of string

fun foo(Int x) = x + 1
  | foo(Str x) = x ^ "abc"
\end{lstlisting}


Although dynamically typed languages already offer ease and efficiency for writing programs, 
this facility can be enhanced with \textbf{synthesis of programs} 
from surrounding context. 
This article presents a system that synthesizes terms from context 
in a dynamically typed language.
Synthesis of programs for a dynamically typed language introduces a fundamental tension. 
While dynamically typed programs benefit from a lack of static bounds, program synthesis
must be a terminating procedure driven by static bounds representing the goals of synthesis.   

\textbf{Types} have become the lingua franca of formal specification of static bounds.
Others have shown how various forms of specification, including examples, abstract values, 
pure propositions, and modal propositions, can be encoded as types.
Types have been used successfully for verifying programs, 
guiding program synthesis in ML-family languages, 
and guiding humans in dependently-typed interactive theorem proving. 

Dynamically, two interfaces may have the same correctness result for some inputs,
while differing on other inputs. \textbf{subtyping} is used to decide if a term's 
composition is statically invalid, maintaining semblance to dynamically typed programming,
while also adding safety with static behavior.

By \textbf{downward propagating} and decomposing types, 
it is possible to guide the synthesis of programs.
To maintain the spirit of dynamic types, type annotations must remain optional.
Previous work has demonstrated the utility of downward propagating types 
in theorem proving systems, local type checking, 
and synthesis of ML-family programs.

For example, in a program that extracts 
the first element of a pair of a particular type, 
it's possible to detect an error before knowing the second element.

to detect an error of a pairt of a   
\begin{lstlisting}
$\lambda$ n : nat $\Rightarrow$
  let first = ($\lambda$ (x,y) : (str $\times$ str) $\Rightarrow$ x) .
  first (n, _) 
\end{lstlisting}

\noindent The  applications' argument type \lstinline{(nat $\times$ ?)} 
is propagated and decomposed such that the subtyping constraint 
\lstinline{nat $\subseteq$ str} is decided. 

In order to have fine-grained control over where types are utilized or avoided, 
types may be composed of \textbf{dynamic types}, represented by \lstinline{(?)} to indicate 
that any subterm corresponding to that portion of the type 
will not be subject to static constraints.

If type annotations are not available, then types \textbf{propagated upward} from context. 
The actual type of a term can be inferred in an obvious way.

\begin{lstlisting}

#cons("hello",#cons("world",#nil())) : 
#cons(str $\times$ #cons(str $\times$ #nil$\diamondsuit$))

\end{lstlisting}

To infer expected types, type inference techniques for ML-family languages 
are a good starting point.
ML-family type inference is sound, because an ML term is 
intrinsically associated with a static bound in accordance with ML's datatype mechanism.
Terms in dynamically typed languages are not intrinsically associated with a principal type. 
Type inference for dynamically typed languages cannot be sound without greatly violating the 
liberal reuse of terms afforded by dynamic types. 

Thus, it is necessary to devise a method of type inference that is unsound, 
yet still provides sufficient information to guide efficient program synthesis.
Additionally, despite being unsound, it should be able to prune/reject 
a significant portion of bad programs. 
It may reject good programs, but only if it can infer a static type.

In parametric types where a generic input type must be the same as a generic output type,
The dynamic nature of terms is at odds with inferring types.

\begin{lstlisting}
($\lambda$ pair : $\forall$ $\alpha$ . $\alpha$ $\rightarrow$ $\alpha$ $\rightarrow$ ($\alpha$ $\times$ $\alpha$) $\Rightarrow$ 
($\lambda$ n : int $\Rightarrow$ ($\lambda$ s : str $\Rightarrow$ 
  pair n s
)))
\end{lstlisting}

\noindent These generic types can be specialized based on the terms that are witnessed as inputs. 
Since the principal type of any term in dynamically typed languages is top, 
The parameter type must accommodate types of unforeseen arguments, 
while the return type should be \textbf{widened} but restricted 
to previously seen arguments.
This system tackles the tension in these goals by combining the union combinator  
with the dynamic type. 

Once \lstinline{pair} is applied to an integer its generic type is specialized to 
\lstinline{(int | ?)}, 
in which union with the dynamic type behaves like the top type $\top$, 
accommodating receiving a string as a the subsequent input.
Thus, the generic type is specialized to \lstinline{(int | str | ?)}.
The result type for \lstinline{(pair n s)} ends up as 
\lstinline{(int | string) $\times$ (int | string)}. 
The semantics of union with the dynamic type result in the dynamic type 
falling away for actual types.

In functions where a parameter has an unknown type and that parameter is 
internally used as an argument to an application, the dynamic nature of terms  
adds some complications to type inference.

\begin{lstlisting}
($\lambda$ i2n : int $\rightarrow$ nat $\Rightarrow$ 
($\lambda$ s2n : str $\rightarrow$ nat $\Rightarrow$ 
  $\lambda$ x $\Rightarrow$ (i2n x, s2n x)
))

\end{lstlisting}

The argument type must avail itself to internal parameter types of unforeseen compositions,
while the external parameter type should be \textbf{narrowed} and restricted 
to the internal parameter types of previously seen compositions.
Once \lstinline{i2n} is applied to \lstinline{x}, 
the type for \lstinline{x} is specialized to \lstinline{(int & ?)}, 
in which intersection with the dynamic type behaves like the bottom type $\bot$,
availing itself to be used in subsequent applications. 
Thus, the dynamic type is inferred to be \lstinline{(int & str & ?)}.
The external parameter type for ends up as \lstinline{(int & str)}. 
The semantics of intersection with the dynamic type result in the dynamic type
falling away for expected types.



In order to efficiently guide program synthesis, 
types must be able to \textbf{express} fairly precise information. 
The system presented here offers types with 
expressivity comparable to typical decidable predicate logics. \\
\hfill \\
For example, types can also specify a pair of a list and its length.

\begin{lstlisting}[]
let measurement : $\mu$ (nat $\times$ list) .
  #zero $\diamondsuit$ $\times$ #nil $\diamondsuit$ | 
  #succ nat $\times$ #cons (? $\times$ list)
\end{lstlisting} 

\hfill

\noindent This is syntactic sugar for:

\begin{lstlisting}[]
let measurement : 
$\exists$ $\alpha$ . $\mu$ nat_and_list .
  #zero $\diamondsuit$ $\times$ #nil $\diamondsuit$ | 
  $\exists$ nat list :: 
    (nat $\times$ list) $\leq$ nat_and_list .
    #succ nat $\times$ #cons ($\alpha$ $\times$ list)
\end{lstlisting}

\hfill

\noindent Semantically, the type of measurement is similar to the definition of 
list and length in Synquid \cite{}    

\begin{lstlisting}[keywords={termination, measure, data, where}]
termination measure len :: List $\beta$ $\rightarrow$ Nat 
data List $\beta$ where
  Nil :: {v: List $\beta$ | len v = 0}
  Cons :: $\beta$ $\rightarrow$ xs: List $\beta$ $\rightarrow$ 
    {v: List $\beta$ | len v = len xs + 1}

\end{lstlisting}

\hfill

\noindent Correspondingly, the types are expressive enough to precisely specify
a function that takes a natural number \lstinline{n} 
and an element, and returns a list of \lstinline{n} elements.

\begin{lstlisting}[]
let replicate : 
$\forall$ $\alpha$ . $\alpha$ $\rightarrow$ $\nu$ (nat $\rightarrow$ list) .
  #zero $\diamondsuit$ $\rightarrow$ #nil $\diamondsuit$ & 
  #succ nat $\rightarrow$ #cons ($\alpha$ $\times$ list)
\end{lstlisting}



\hfill

\noindent This is syntactic sugar for:

\begin{lstlisting}[]
let replicate : 
$\forall$ $\alpha$ . $\alpha$ $\rightarrow$ $\nu$ nat_to_list .
  #zero $\diamondsuit$ $\rightarrow$ #nil $\diamondsuit$ & 
  $\forall$ nat list :: 
    nat_to_list $\leq$ (nat $\rightarrow$ list) .
    #succ nat $\rightarrow$ #cons ($\alpha$ $\times$ list)
\end{lstlisting}

\hfill

\noindent The type of \lstinline{replicate} is co-recursive rather than recursive. 
When expanded to the type with a universal type and constraint, 
the universally typed variables appear on the right hand side 
of the subtyping constraint, while the co-recursive variable
appears on the left hand side. This is consistent with the notion
that a intersection of types is a subtype of any one of its parts.

\hfill

\noindent Semantically, the type of \lstinline{replicate} is similar to the definition of 
\lstinline{replicate} in Synquid \cite{}    

\begin{lstlisting}[keywords={termination, measure, data, where}]
replicate :: n:Nat $\rightarrow$ x:$\alpha$ $\rightarrow$ 
  {v: List $\alpha$ | len v = n}

\end{lstlisting}

\hfill

\noindent The term for \lstinline{replicate} could be represented by a recursive function built using \lstinline{fix} 

\begin{lstlisting}[]
let replicate = 
$\lambda$ x $\Rightarrow$ fix ($\lambda$ self $\Rightarrow$
  $\lambda$ #zero () $\Rightarrow$ #nil () ;
  $\lambda$ #succ n $\Rightarrow$ #cons (x, self n)
) 
\end{lstlisting}



\section{Overview}

\section{Technical Details}

\begin{figure}[h]
\begin{mathpar}
\inferrule[equiv]
  {\Delta \vdash \tau' \equiv \tau}
  {\Delta \vdash \tau' \leq \tau	\rightsquigarrow  \cdot } 

\\

\inferrule[tag]
  {\Delta \vdash \tau' \leq \tau \rightsquigarrow \Delta_1 } 
  {\Delta \vdash \#l\ \tau' \leq \#l\ \tau \rightsquigarrow \Delta_1 } 

\inferrule[field]
  {\Delta \vdash \tau' \leq \tau \rightsquigarrow \Delta_1 } 
  {\Delta \vdash .l\ \tau' \leq .l\ \tau \rightsquigarrow \Delta_1 } 


\inferrule[case]
  {
    \Delta \vdash \tau_1' \leq \tau_1 \rightsquigarrow \Delta_1 
    \\
    \Delta \vdash \tau_2' \leq \tau_2 \rightsquigarrow \Delta_2 
  } 
  {\Delta \vdash 
    \tau_1 \rightarrow \tau_2' \leq \tau_1' \rightarrow \tau_2 
    \rightsquigarrow \Delta_1;\Delta_2 
  } 

\end{mathpar}
\caption{Unification subtyping: basic rules}
\end{figure}

\begin{figure}[h]
\begin{mathpar}


\inferrule[var-left]
  {
    \alpha \notin \text{dom}(\Delta) \\ \text{fresh}\ \beta  
    \\\\
    (\text{occurs}\ \alpha\ \tau\ \wedge\ \mu \alpha.\tau = \tau_1)\ \vee\   
    \tau = \tau_1
    % Note: existential rule should execute before this rule to free the bound variables before writing. 
  }
  {\Delta \vdash \alpha \leq \tau	
    \rightsquigarrow  
    \cdot,\alpha \mapsto \tau_1 \ \&\ \beta
  } 

\inferrule[var-rght]
  {  
    \alpha \notin \text{dom}(\Delta) \\ \text{fresh}\ \beta  
    \\\\
    (\text{occurs}\ \alpha\ \tau\ \wedge\ \nu \alpha.\tau = \tau_1)\ \vee\   
    \tau = \tau_1
    % Note: universal rule should execute before this rule to free the bound variables before writing. 
  }
  {\Delta \vdash \tau \leq \alpha \rightsquigarrow  \cdot,\alpha \mapsto \tau_1 \ |\ \beta } 


\inferrule[exis-free]
  { 
    \Delta \vdash \tau' \leq \tau \rightsquigarrow \Delta_1
    \\
    \Delta;\Delta_1 \vdash \tau_1 \leq \tau_2 \rightsquigarrow \Delta_2
    \\
    \text{fresh}\ \widebar{\alpha}
  }
  { 
    \Delta \vdash 
      \tau'
      \leq 
      (\exists \widebar{\alpha} :: \tau_1 \leq \tau_2\ .\ \tau)
      \rightsquigarrow
      \Delta_1;\Delta_2
  }

\inferrule[univ-free]
  { 
    \Delta;\Delta \vdash \tau' \leq \tau \rightsquigarrow \Delta_1
    \\
    \Delta;\Delta_1 \vdash \tau_1 \leq \tau_2 \rightsquigarrow \Delta_2
    \\
    \text{fresh}\ \widebar{\alpha}
  }
  { 
    \Delta \vdash 
      (\forall \widebar{\alpha} :: \tau_1 \leq \tau_2\ .\ \tau')
      \leq 
      \tau
      \rightsquigarrow
      \Delta_1;\Delta_2
  }



\end{mathpar}
\caption{Unification subtyping: variable rules}
\end{figure}



\begin{figure}[h]
\begin{mathpar}


\inferrule[bottom]
  { }
  {\Delta \vdash \bot \leq \tau	\rightsquigarrow  \cdot } 

\inferrule[top]
  { }
  {\Delta \vdash \tau \leq \top	\rightsquigarrow  \cdot } 

\inferrule[dynamic-left]
  { }
  {\Delta \vdash\ ? \leq \tau	\rightsquigarrow  \cdot } 

\inferrule[dynamic-right]
  { }
  {\Delta \vdash \tau \leq\ ?	\rightsquigarrow  \cdot } 

\end{mathpar}
\caption{Unification subtyping: leaf rules}
\end{figure}




\begin{figure}[h]
\begin{mathpar}

\inferrule[recur-symm]
  { 
     \Delta \vdash \tau' \equiv \tau\ \wedge \cdot = \Delta_1\ \vee\ 
     \Delta \vdash \tau'[\alpha/\top] \leq \tau[\alpha/\top] \rightsquigarrow \Delta_1
  }
  {\Delta \vdash \mu \alpha . \tau' \leq \mu \alpha . \tau	\rightsquigarrow  \Delta_1 }

\inferrule[recur-tag]
  {\Delta \vdash  \#l\ \tau_1 \leq \tau[\alpha/\mu \alpha . \tau] \rightsquigarrow \Delta_1}
  {\Delta \vdash \#l\ \tau_1 \leq \mu \alpha . \tau	\rightsquigarrow  \Delta_1 }

\inferrule[recur-record]
  {  
    \Delta\ ? \vdash_{R} (\text{linearize}\ \tau')
    \leq \mu \alpha . \tau	\rightsquigarrow  \Delta_1
  }
  {\Delta \vdash \tau'  
    \leq \mu \alpha . \tau	\rightsquigarrow  \Delta_1 
  }

\inferrule[corec-symm]
  { 
     \Delta \vdash \tau' \equiv \tau\ \wedge \cdot = \Delta_1\ \vee\ 
     \Delta \vdash \tau'[\alpha/\bot] \leq \tau[\alpha/\bot] \rightsquigarrow \Delta_1
  }
  { \Delta \vdash 
    \nu \alpha . \tau' 
    \leq 
    \nu \alpha . \tau	
    \rightsquigarrow \Delta_1 
  }

\inferrule[corec-case]
  { 
    \Delta \vdash
      \forall \beta :: \tau[\alpha/\nu\alpha.\tau]\leq (\beta \rightarrow \tau_2)\ .\ \beta 
      \leq 
      \tau_1
    \rightsquigarrow \Delta_1
    \\\\
    \Delta \vdash
      \forall \beta :: \tau[\alpha/\nu\alpha.\tau]\leq (\tau_1 \rightarrow \beta)\ .\ \beta 
      \leq 
      \tau_2
    \rightsquigarrow \Delta_2
  }
  { \Delta \vdash 
    \nu \alpha . \tau 
    \leq 
    \tau_1 \rightarrow \tau_2	
    \rightsquigarrow  \Delta_1;\Delta_2
  }


\inferrule[recur-record-subrule]
  {  
    \Delta\ \tau_0 \vdash 
      \tau_1 
      \leq 
      \exists \beta ::
      (.l\ \tau_0\ \&\ \beta\ \&\ \tau_2) \leq \tau[\alpha/\mu\alpha.\tau]\ .\ \beta
    \rightsquigarrow \Delta_1
    \\\\
    \Delta\ (\tau_0\ \&\ .l\ \tau_1)\vdash_{R} \tau_2  
    \leq \mu \alpha . \tau	\rightsquigarrow  \Delta_2
  }
  {\Delta\ \tau_0 \vdash_{R} .l\ \tau_1\ \&\ \tau_2  
    \leq \mu \alpha . \tau	\rightsquigarrow  \Delta_1;\Delta_2 
  }

\inferrule[recur-field-subrule]
  {  
    \Delta\ \tau_0 \vdash 
      \tau_1 
      \leq 
      \exists \beta ::
      (.l\ \tau_0\ \&\ \beta) \leq \tau[\alpha/\mu\alpha.\tau]\ .\ \beta
    \rightsquigarrow \Delta_1
  }
  {\Delta\ \tau_0 \vdash_{R} .l\ \tau_1\ 
    \leq \mu \alpha . \tau	\rightsquigarrow  \Delta_1 
  }

\end{mathpar}
\caption{Unification subtyping: recursive rules}
\end{figure}

\begin{figure}[h]
\begin{mathpar}

\inferrule[union-left]
  {
    \Delta \vdash \tau_1 \leq \tau \rightsquigarrow \Delta_1  
    \\
    \Delta;\Delta_1 \vdash \tau_2 \leq \tau \rightsquigarrow \Delta_2  
  }
  {
    \Delta \vdash \tau_1\ |\ \tau_2 \leq \tau
    \rightsquigarrow \Delta_1;\Delta_2
  }

\inferrule[union-right]
  {
    \Delta \vdash \tau \leq \tau_1 \rightsquigarrow \Delta_1\ \wedge\
    \Delta;\Delta_1 \vdash \tau \leq \tau_2 \rightsquigarrow \Delta_2\ \vee\ 
    \\\\
    \Delta \vdash \tau \leq \tau_1 \rightsquigarrow \Delta_1  \wedge\ 
    \cdot = \Delta_2\ \vee\ 
    \\\\
    \Delta \vdash \tau \leq \tau_2 \rightsquigarrow \Delta_2 \wedge\ 
    \cdot = \Delta_1
  }
  {
    \Delta \vdash \tau \leq \tau_1\ |\ \tau_2
    \rightsquigarrow \Delta_1;\Delta_2
  }

\inferrule[inter-right]
  {
    \Delta \vdash \tau \leq \tau_1 \rightsquigarrow \Delta_1  
    \\
    \Delta;\Delta_1 \vdash \tau \leq \tau_2 \rightsquigarrow \Delta_2  
  }
  {
    \Delta \vdash \tau \leq \tau_1\ \&\ \tau_2
    \rightsquigarrow \Delta_1;\Delta_2
  }

\inferrule[inter-left]
  {
    \Delta \vdash \tau_1 \leq \tau \rightsquigarrow \Delta_1\ \wedge\ 
    \Delta;\Delta_1 \vdash \tau_2 \leq \tau \rightsquigarrow \Delta_2\ \vee\  
    \\\\
    \Delta \vdash \tau_1 \leq \tau \rightsquigarrow \Delta_1\ \wedge\ 
    \cdot = \Delta_2\ \vee\ 
    \\\\
    \Delta \vdash \tau_2 \leq \tau \rightsquigarrow \Delta_2\ \wedge\ 
    \cdot = \Delta_1
  }
  {
    \Delta \vdash \tau_1\ \&\ \tau_2 \leq \tau
    \rightsquigarrow \Delta_1;\Delta_2
  }

\end{mathpar}
\caption{Unification subtyping: connective rules}
\end{figure}



\begin{figure}[h]
\begin{mathpar}

\inferrule[Unit]
  { 
    \Delta \vdash \diamondsuit \leq \tau \rightsquigarrow \Delta_1 
  }
  {\Delta\ \Gamma \vdash () : \tau  \rightsquigarrow \Delta_1\ .\ \diamondsuit } 

\inferrule[Var]
  { 
    \Gamma(x) = \tau'
    \\
    \Delta \vdash \tau' \leq \tau \rightsquigarrow \Delta_1
  }
  {\Delta\ \Gamma \vdash x : \tau  
    \rightsquigarrow \Delta_1\ .\ \tau' } 

\inferrule[Tag]
  { 
    \text{fresh}\ \alpha
    \\
    \Delta \vdash \#l\ \alpha \leq \tau \rightsquigarrow \Delta_1
    \\\\
    \Delta;\Delta_1\ \Gamma \vdash t : \alpha 
      \rightsquigarrow \Delta_2\ .\ \tau'
  }
  {\Delta\ \Gamma \vdash \#l\ t : \tau  
    \rightsquigarrow \Delta_1;\Delta_2\ .\ \tau' } 

\inferrule[Field]
  { 
    \text{fresh}\ \alpha
    \\
    \Delta \vdash .l\ \alpha \leq \tau \rightsquigarrow \Delta_1
    \\\\
    \Delta;\Delta_1\ \Gamma \vdash t : \alpha 
      \rightsquigarrow \Delta_2\ .\ \tau'
  }
  {\Delta\ \Gamma \vdash .l\ t : \tau  
    \rightsquigarrow \Delta_1;\Delta_2\ .\ \tau' } 

\inferrule[Record]
  {
    \text{fresh}\ \alpha \\ \text{fresh}\ \beta
    \\
    \Delta \vdash .l\ \alpha\ \&\ \beta \leq \tau 
      \rightsquigarrow \Delta_{\alpha\beta}
    \\
    \Delta;\Delta_{\alpha\beta}\ \Gamma \vdash .l\ t_1 : .l\ \alpha  
      \rightsquigarrow \Delta_1\ .\ \tau_1'
    \\
    \Delta;\Delta_{\alpha\beta}\ \Gamma \vdash t_2 : \beta  
      \rightsquigarrow \Delta_1\ .\ \tau_2'
  }
  {\Delta\ \Gamma \vdash (.l\ t_1;\ t_2) : \tau  
    \rightsquigarrow \Delta_{\alpha\beta};\Delta_1;\Delta_2\ .\ \tau_1'\ \&\ \tau_2' } 

\inferrule[Case]
  { 
    \text{fresh}\ \widebar{\alpha} \\ \text{fresh}\ \beta
    \\
    \Delta\ \Gamma \vdash
      \tau_1[?/\widebar{\alpha}] \rightarrow \beta \leq \tau
      \rightsquigarrow \Delta_1
    \\\\
    \Gamma \vdash_{pat}\ t_1 : \tau_1 \rightsquigarrow \Gamma_1
    \\
    \Delta;\Delta_1\ \Gamma;\Gamma_2 \vdash 
      t_2 : \beta  
      \rightsquigarrow \Delta_2\ .\ \tau_2'
  }
  {\Delta\ \Gamma \vdash 
    (\lambda\ t_1 : \tau_1 \Rightarrow t_2) : \tau  
    \rightsquigarrow \Delta_1;\Delta_2\ .\ \tau_1[?/\widebar{\alpha}] \rightarrow \tau_2'
  } 

\inferrule[Function]
  {
    \text{fresh}\ \alpha \\ \text{fresh}\ \beta
    \\
    \Delta \vdash (\tau_p \rightarrow \alpha)\ \&\ \beta \leq \tau  \rightsquigarrow \Delta_{\alpha\beta}
    \\
    \Delta;\Delta_{\alpha\beta}\ \Gamma \vdash \lambda\ t_p : \tau_p \Rightarrow t_1 : 
      (\tau_p \rightarrow \alpha)  
      \rightsquigarrow \Delta_1\ .\ \tau_1'
    \\
    \Delta;\Delta_{\alpha\beta}\ \Gamma \vdash t_2 : \beta  
      \rightsquigarrow \Delta_1\ .\ \tau_2'
  }
  {\Delta\ \Gamma \vdash (\lambda\ t_p : \tau_p \Rightarrow t_1\ ;\ t_2) : \tau  
    \rightsquigarrow \Delta_{\alpha\beta};\Delta_1;\Delta_2\ .\ \tau_1'\ \&\ \tau_2' } 

\end{mathpar}
\caption{Inference typing: part 1}
\end{figure}

\begin{figure}[h]
\begin{mathpar}

\inferrule[Proj]
  {
    \Delta\ \Gamma \vdash t_1 : .l\ \tau \rightsquigarrow \Delta_1\ .\ \tau_1
    \\
    \text{fresh}\ \alpha
    \\
    \Delta\;\Delta_1 \vdash \tau_1 \leq .l\ \alpha \rightsquigarrow \Delta_2 
  }
  {\Delta\ \Gamma \vdash t_1.l : \tau 
    \rightsquigarrow \Delta_1;\Delta_2\ .\ \alpha} 

\inferrule[App]
  { 
    \Delta\ \Gamma \vdash t_2 : (? \rightarrow \tau) 
      \rightsquigarrow \Delta_1\ .\ \tau_2 
    \\\\
    \text{fresh}\ \alpha \\ \text{fresh}\ \beta
    \\
    \Delta;\Delta_1 \vdash \tau_2 \leq \alpha \rightarrow \beta 
      \rightsquigarrow \Delta_2
    \\\\
    \Delta;\Delta_1;\Delta_2\ \Gamma \vdash t_1 : \alpha 
      \rightsquigarrow \Delta_3\ .\ \tau_1' 
    \\\\
    \Delta;\Delta_1;\Delta_2;\Delta_3 \vdash \tau_2 \leq \tau_1' \rightarrow \tau  
      \rightsquigarrow \Delta_4 
  }
  {\Delta\ \Gamma \vdash t_2\ t_1 : \tau 
    \rightsquigarrow \Delta_1;\Delta_2;\Delta_3;\Delta_4\ .\ \beta} 

\inferrule[Let]
  { 
    \text{fresh}\ \widebar{\alpha}
    \\
    \Delta\ \Gamma \vdash t_1 : \tau_1[?/\widebar{\alpha}] \rightsquigarrow \Delta_1\ .\ \tau_1' 
    \\
    \Delta;\Delta_1\ \Gamma,x \mapsto (\forall \beta :: \beta \leq \tau_1[?/\widebar{\alpha}]\ .\ \beta) 
      \vdash t : \tau \rightsquigarrow \Delta_2\ .\ \tau' 
  }
  {\Delta\ \Gamma \vdash (\text{let}\ x : \tau_1 = t_1\ .\ t) : \tau \rightsquigarrow \Delta_1\Delta_2\ .\ \tau'} 

\inferrule[Fix]
  { 
    \Delta\ \Gamma \vdash t_1 : \tau \rightarrow \tau \rightsquigarrow \Delta_1\ .\ \tau_1' 
    \\
    \text{fresh}\ \alpha
    \\
    \Delta;\Delta_1 \vdash \tau_1' \leq \alpha \rightarrow \alpha \rightsquigarrow \Delta_2 
  }
  {\Delta\ \Gamma \vdash \text{fix}\ t_1 : \tau \rightsquigarrow \Delta_1;\Delta_2\ .\ \alpha} 


\end{mathpar}
\caption{Inference typing: part 2}
\end{figure}



\section{Evaluation}

\section{Related work}

\section*{Notes}

\subsection*{dualities}
\begin{enumerate}
  \item \(\bot \leq \top \)
  \item \(\tau_1\ \&\ \tau_2  \leq \tau_1\ |\ \tau_2 \)
  \item \(\forall \alpha . \tau \leq \exists \alpha . \tau \)
  \item \(\nu \alpha . \tau \leq \mu \alpha . \tau \)
\end{enumerate}

\subsection*{contributions}
\begin{enumerate}
  \item program synthesis such that:
    \begin{enumerate}
      \item goal defined by partial programs with missing annotations  
      \item goal transformed into type specification 
      \item type specification may contain dynamic type  
    \end{enumerate}
  \item algorithmic subsumption allows simple subtyping rule with dynamic type
    \begin{enumerate}
      \item subtyping can have a dynamic type on either side without risk of   
        all terms being accepted by typing rules (i.e. everything typing)
    \end{enumerate}
  \item an expressive type system 
    based on intersection, union, recursive, and co-recursive types
    \begin{enumerate}
      \item without dependent types 
      \item comparable to prolog 
      \item allows dynamic type 
      \item sound modulo absence of dynamic type 
        or static type union/intersect with dynamic
      \item types behave either leniently or strict depending on usage as actual type or expected type
    \end{enumerate}
  \item full type synthesis with full type propagation (for all rules)
  \item type unification such that: 
    \begin{enumerate}
      \item the principal type of all terms is top
      \item lenient (but unsound) static type inference
      \item expanding type info with union and intersection and dynamic type
    \end{enumerate}
  \item interleaving type constraint generation and solving with dynamic type 
\end{enumerate}

\subsection*{differences}
in contrast with gradual typing:  
\begin{enumerate}
  \item infers more static type info 
  \item stronger soundness claim (i.e. weaker soundness precondition)
  \item dynamic semantics are irrelevant 
  \item deterministic subsumption 
  \item dynamic type built into subtyping 
\end{enumerate}

in contrast with HM type inference:  
\begin{enumerate}
  \item synthesizes type in addition to constraint solution 
    due to subtyping
  \item propagates types
  \item global top type, leaves types open during unification
  \item expands and narrows types  
\end{enumerate}

in contrast with Roundtrip typing:  
\begin{enumerate}
  \item type combinators without dependent types
  \item prolog-like type language  
  \item synthesizes types for all rules
  \item global top type, leaves types open during unification
  \item expands and narrows types  
  \item delegates to unification to decompose types 
  \item delegates to unification to free bound variables 
\end{enumerate}




\subsection*{gradual typing}
How gradually typed inference typically works:
\begin{enumerate}
  \item infer either a strict static type or a dynamic type
  \item let annotations implicitly guide the usage of static vs dynamic checks 
\end{enumerate}
There exists work on type inference for gradually typed programs.
To the best of my knowledge, they are all sound and complete.
Other gradual type inference systems separate 
generating constraints from solving constraints.
Gradual typing systems use the dynamic type \lstinline{(?)} to indicate 
that dynamic checks should be used.
Gradual type inference relies on ML types with union extension.
They do not contain the idea of using intersection and union to keep types open.
Gradual typing systems separate subtyping from the relation 
between dynamic to static types to avoid all terms typing via the subsumption rule.


\subsection*{references}
\begin{enumerate}
\item Refinement types for ML by Tim Freeman and Frank Pfenning 
\item Refinement types as proof irrelevance by William Lovas and Frank Pfenning 
\item Local type inference by Benjamin C. Pierce and David N. Turner
\item Liquid types - \url{http://goto.ucsd.edu/~rjhala/papers/liquid_types.pdf}
\item Program synthesis from polymorphic refinement types by Nadia Polikarpova, Ivan Kuraj, and Armando Solar-Lezama
\item Example-directed synthesis: a type-theoretic interpretation by Frankle, Osera, Walker, and Zdancewic
\item Gradual typing for functional languages by Jeremy G. Siek and Walid Taha 
\item Gradual typing for functional languages by Jeremy G. Siek and Walid Taha 
\item Gradual typing for objects by Jeremy G. Siek and Walid Taha 
\item Gradual typing with unification-based inference by Siek and Manish Vachharajani 
\item Dynamic Type Inference for Gradual Hindleyâ€“Milner Typing - \url{https://dl.acm.org/doi/pdf/10.1145/3290331}
\item Principal type schemes for gradual programs - \url{https://www.cs.ubc.ca/~rxg/ptsgp.pdf}
\item Gradual Liquid Type Inference - \url{https://arxiv.org/pdf/1807.02132.pdf}
\item Gradual typing with union and intersection types - \url{https://dl.acm.org/doi/pdf/10.1145/3110285}
\item Gradual typing: a new perspective - unions, intersections, dynamic type, and type inference - \url{https://www.irif.fr/~gc/papers/popl19.pdf}
\item Gradual refinement types (via abstract interpretation) - \url{https://pleiad.cl/papers/2017/lehmannTanter-popl2017.pdf}
\item Consistent subtyping for all - \url{https://xnning.github.io/papers/consistent-subtyping-for-all-toplas.pdf}
\item Polymorphic functions with set-theoretic types, part 1 - \url{https://www.irif.fr/~gc/papers/polydeuces-part1.pdf}
\item Polymorphic functions with set-theoretic types, part 2 - \url{https://www.irif.fr/~gc/papers/polydeuces-part2.pdf}
\item Revisiting occurrence typing - \url{https://arxiv.org/pdf/1907.05590.pdf} 


\end{enumerate}



\end{document}

%% - 0. introduction 
%% - 1. motivating example / overview 
%% - 2. problem statement 
%% - 3. overall synthesis algorithm 
  % include how type information propagates
  % abstract away relation type details
  % includes propagation of types
%% - 4. relational types
  % including dynamic types
  % including recursion over intersection and functions